{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10cf385-93ac-4b03-8532-30efebfb6061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_core.globals import set_llm_cache\n",
    "from langchain_aws import InMemorySemanticCache\n",
    "from langchain_aws import ChatBedrock\n",
    "from langchain_aws.embeddings import BedrockEmbeddings\n",
    "import redis\n",
    "from redis.cluster import RedisCluster as MemoryDB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a34675-5c66-4ea1-9a1c-b5a205302216",
   "metadata": {},
   "source": [
    "## Initialize the ChatBedrock and embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfa25cf-26aa-45f9-9a2a-df1a1606fa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create the Anthropic Model\n",
    "model_kwargs = {\n",
    "    \"temperature\": 0,\n",
    "    \"top_k\": 250,\n",
    "    \"top_p\": 1,\n",
    "    \"stop_sequences\": [\"\\\\n\\\\nHuman:\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2481182f-3432-4e59-a14e-b00f31d0b84f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use the Anthropic Claude model\n",
    "llm = ChatBedrock(\n",
    "    model_id=\"anthropic.claude-3-sonnet-20240229-v1:0\", model_kwargs=model_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba15759-b194-4fd8-a9a6-1be417b47887",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a Titan Embeddings client\n",
    "embeddings = BedrockEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7aec2-8efa-4f2d-bca3-09a148d38efc",
   "metadata": {},
   "source": [
    "## Connect to MemoryDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27319029-fba1-401e-84b1-f63cfcfb1f17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "memorydb_host = os.environ.get(\"MEMORYDB_HOST\", \"localhost\")\n",
    "memorydb_port = os.environ.get(\"MEMORYDB_PORT\", 6379)\n",
    "# print(f\"MemoryDB Url = {memorydb_host}:{memorydb_port}\")\n",
    "rc = MemoryDB(\n",
    "    host=memorydb_host,\n",
    "    port=memorydb_port,\n",
    "    ssl=False,\n",
    "    decode_responses=False,\n",
    "    ssl_cert_reqs=\"none\",\n",
    ")\n",
    "rc.ping()\n",
    "# rc.flushall()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7fe013-f713-4797-ae38-fe7a0f3e32b3",
   "metadata": {},
   "source": [
    "## Submit a query  without setting up cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fe670e-9c9c-4d2f-9c39-29c2279a9512",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = llm.invoke(\"Tell me about mission to moon\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d883259-1b8d-43e9-bd08-c8e6438b0b19",
   "metadata": {},
   "source": [
    "## Enable MemoryDB for durable semantic caching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00da6f-a370-418f-a305-fc2a59f0fc78",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "set_llm_cache(\n",
    "    InMemorySemanticCache(\n",
    "        redis_url=f\"redis://{memorydb_host}:{memorydb_port}/ssl=True&ssl_cert_reqs=none\",\n",
    "        embedding=embeddings,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac943fd-6ffe-4c99-ac5c-e9fbf93b7e44",
   "metadata": {},
   "source": [
    "### Submit a query to the LLM and Re-run the same block to see the improvement in response time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4cc96-69eb-4a47-ab6f-b21d5592d9fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "response = llm.invoke(\"Tell me about mission to moon\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c668188-5658-492d-8fce-bea9063d2cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = llm.invoke(\"Who first invented a telescope\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665d884-08fe-46a8-a6b4-fcf42df44d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "response = llm.invoke(\"Who first invented a car\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d645f3c-d721-490c-a734-8c22158b227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "respone3 = llm.invoke(\"Who  first  a Telescope\")\n",
    "print(respone3.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-aws",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
