{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock Inline Agent Chat Model with LangGraph\n",
    "\n",
    "This notebook demonstrates how to use BedrockInlineAgentsRunnable with LangGraph for a mortgage rate assistant that maintains chat history and context.\n",
    "\n",
    "### Prerequisites:\n",
    "1. AWS credentials configured\n",
    "2. langchain, langgraph, and boto3 packages installed\n",
    "3. langchain-aws package accessible\n",
    "\n",
    "### Step 1: Define the tools for the agent"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool(\"AssetDetail::getAssetValue\")\n",
    "def get_asset_value(asset_holder_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the asset value for an owner id\n",
    "\n",
    "    Args:\n",
    "        asset_holder_id: The asset holder id\n",
    "\n",
    "    Returns:\n",
    "        The asset value for the given asset holder\n",
    "    \"\"\"\n",
    "    return f\"The total asset value for {asset_holder_id} is 100K\"\n",
    "\n",
    "@tool(\"AssetDetail::getMortgageRate\")\n",
    "def get_mortgage_rate(asset_holder_id: str, asset_value: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the mortgage rate based on asset value\n",
    "\n",
    "    Args:\n",
    "        asset_holder_id: The asset holder id\n",
    "        asset_value: The value of the asset\n",
    "\n",
    "    Returns:\n",
    "        The interest rate for the asset holder and asset value\n",
    "    \"\"\"\n",
    "    return f\"The mortgage rate for {asset_holder_id} with asset value of {asset_value} is 8.87%\"\n",
    "\n",
    "tools = [get_asset_value, get_mortgage_rate]\n",
    "tool_map = {tool.name: tool for tool in tools}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the BedrockInlineAgentsRunnable"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from langchain_aws.agents import BedrockInlineAgentsRunnable\n",
    "\n",
    "foundation_model = 'anthropic.claude-3-sonnet-20240229-v1:0'\n",
    "instructions = \"You are an agent who helps with getting the mortgage rate based on the current asset valuation\"\n",
    "\n",
    "inline_agent_config = {\n",
    "    \"foundation_model\": foundation_model,\n",
    "    \"instruction\": instructions,\n",
    "    \"tools\": tools,\n",
    "    \"enable_trace\": False\n",
    "}\n",
    "\n",
    "inline_agent = BedrockInlineAgentsRunnable.create(\n",
    "    region_name=\"us-west-2\",\n",
    "    inline_agent_config=inline_agent_config\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the State for your Graph"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from typing import TypedDict, List, Optional\n",
    "from langchain_core.messages import BaseMessage, HumanMessage, SystemMessage, ToolMessage\n",
    "\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    \"\"\"Defines the state for the Chat Graph\"\"\"\n",
    "    messages: List[BaseMessage]\n",
    "    \"\"\"Chat message history\"\"\"\n",
    "    current_message: str\n",
    "    \"\"\"Current input message\"\"\"\n",
    "    session_id: Optional[str]\n",
    "    \"\"\"Session ID for conversation tracking\"\"\"\n",
    "    tool_response: Optional[str]\n",
    "    \"\"\"Response from tool execution\"\"\"\n",
    "    step_count: int\n",
    "    \"\"\"Step count for internal tracking\"\"\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Define the nodes for your LangGraph"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "from langchain_core.messages.tool import ToolMessage\n",
    "def execute_tools(state: ChatState) -> ChatState:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        tool_call = last_message.tool_calls[0]\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool = tool_map.get(tool_name)\n",
    "        \n",
    "        if tool:\n",
    "            try:\n",
    "                # Execute the function\n",
    "                tool_fn = tool.func\n",
    "                tool_response = tool_fn(**tool_call[\"args\"])\n",
    "                \n",
    "                # Format the response in the expected session state format\n",
    "                action_group_name, function_name = tool_name.split('::') if '::' in tool_name else ('Default', tool_name)\n",
    "                print(f\"Creating tool message for Action Group: {action_group_name} and function: {function_name}\")\n",
    "                tool_message = ToolMessage(\n",
    "                    tool_response,\n",
    "                    tool_call_id = tool_call[\"id\"],\n",
    "                    name= function_name\n",
    "                )\n",
    "                state[\"messages\"] = state[\"messages\"] + [tool_message]\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Debug - Tool execution error: {str(e)}\")\n",
    "                state[\"tool_response\"] = None\n",
    "\n",
    "    state[\"step_count\"] = state.get(\"step_count\", 0) + 1\n",
    "    return state\n",
    "\n",
    "def run_chat(state: ChatState) -> ChatState:\n",
    "    messages = state[\"messages\"]\n",
    "    last_message = messages[-1]\n",
    "    # If there's a tool response, we need to configure the chat model with the session state\n",
    "    if isinstance(last_message, ToolMessage):\n",
    "        # Update the chat model's configuration with the session state\n",
    "        inline_agent.inline_agent_config = {\n",
    "            **inline_agent_config\n",
    "        }\n",
    "        state[\"tool_response\"] = None  # Clear the tool response\n",
    "    else:\n",
    "        # Reset the chat model's configuration to default to remove roc details\n",
    "        inline_agent.inline_agent_config = inline_agent_config\n",
    "        # If no tool response, this is a new message\n",
    "        messages.append(HumanMessage(content=state[\"current_message\"]))\n",
    "    \n",
    "    # Get response from the model \n",
    "    response = inline_agent.invoke(messages)\n",
    "    \n",
    "    # Update state\n",
    "    state[\"messages\"] = messages + [response]\n",
    "    state[\"step_count\"] = state.get(\"step_count\", 0) + 1\n",
    "    \n",
    "    if \"session_id\" in response.additional_kwargs:\n",
    "        state[\"session_id\"] = response.additional_kwargs[\"session_id\"]\n",
    "    \n",
    "    return state"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Define the conditional function for workflow control"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def should_continue(state: ChatState) -> str:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    \n",
    "    # If there's a tool response, always continue to process it\n",
    "    if state[\"tool_response\"] is not None:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # If there are tool calls, continue\n",
    "    if hasattr(last_message, 'tool_calls') and last_message.tool_calls:\n",
    "        return \"continue\"\n",
    "    \n",
    "    # End if no more actions needed\n",
    "    return \"end\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Build and compile the graph"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Create the workflow\n",
    "workflow = StateGraph(ChatState)\n",
    "\n",
    "# Add nodes\n",
    "workflow.add_node(\"inline_agent\", run_chat)\n",
    "workflow.add_node(\"tools\", execute_tools)\n",
    "\n",
    "# Set the entrypoint\n",
    "workflow.add_edge(START, \"inline_agent\")\n",
    "\n",
    "# Add conditional edges\n",
    "workflow.add_conditional_edges(\n",
    "    \"inline_agent\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"continue\": \"tools\",\n",
    "        \"end\": END,\n",
    "    },\n",
    ")\n",
    "\n",
    "# Complete the loop\n",
    "workflow.add_edge(\"tools\", \"inline_agent\")\n",
    "\n",
    "# Compile the graph\n",
    "app = workflow.compile()\n",
    "app"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Test the chat workflow"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Initialize with system message\n",
    "initial_state = {\n",
    "    \"messages\": [SystemMessage(content=instructions)],\n",
    "    \"current_message\": \"What is my mortgage rate for id AVC-1234?\",\n",
    "    \"session_id\": None,\n",
    "    \"tool_response\": None,\n",
    "    \"step_count\": 0\n",
    "}\n",
    "\n",
    "result = app.invoke(initial_state)\n",
    "\n",
    "print(\"Conversation:\")\n",
    "for msg in result[\"messages\"]:\n",
    "    print(f\"\\n{msg.__class__.__name__}: {msg.content}\")\n",
    "    if hasattr(msg, 'tool_calls') and msg.tool_calls:\n",
    "        print(f\"Tool Calls: {msg.tool_calls}\")\n",
    "    if hasattr(msg, 'additional_kwargs') and msg.additional_kwargs:\n",
    "        print(f\"Additional Info: {msg.additional_kwargs}\")\n",
    "\n",
    "print(f\"\\nTotal steps: {result['step_count']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain-aws-v7IMwidO-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
