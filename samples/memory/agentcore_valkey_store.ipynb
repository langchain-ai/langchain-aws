{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AgentCore Valkey Store Usage Example\n",
    "\n",
    "This notebook demonstrates how to use the **ValkeyStore** for long-term memory storage with semantic search capabilities, combined with **AgentCoreValkeySaver** for short-term conversation state management.\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Valkey server** with Search module support:\n",
    "   - **Local testing**: `docker run -d -p 6379:6379 valkey/valkey-bundle:latest`\n",
    "   - ‚ö†Ô∏è Standard `valkey/valkey:latest` does NOT include Search module\n",
    "   - **Production**: Amazon ElastiCache Valkey with Self-Designed cluster (includes Search module)\n",
    "2. **AWS credentials** configured for Bedrock access\n",
    "3. **Required packages** installed:\n",
    "   ```bash\n",
    "   pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\n",
    "   ```\n",
    "   Note: Use quotes around `'langgraph-checkpoint-aws[valkey]'` for zsh shell\n",
    "   ```\n",
    "\n",
    "## üéØ Key Features\n",
    "\n",
    "- üß† **Long-term memory** storage with ValkeyStore\n",
    "- üîç **Semantic search** using vector embeddings\n",
    "- üóÇÔ∏è **Namespace organization** for data isolation\n",
    "- üöÄ **AgentCore-compatible** session management\n",
    "- üîÑ **TTL support** for automatic cleanup\n",
    "- üèä **Connection pooling** for scalability\n",
    "- üìä **Cross-session memory** for personalized interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Verify Package Installation\n",
    "\n",
    "Let's first verify that all required packages are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "required_packages = [\n",
    "    'langchain',\n",
    "    'langchain_aws',\n",
    "    'langchain_core',\n",
    "    'langgraph',\n",
    "    'langgraph_checkpoint_aws',\n",
    "    'valkey'\n",
    "]\n",
    "\n",
    "print(\"üîç Checking installed packages...\\n\")\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package} - NOT INSTALLED\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"\\nPlease install them using:\")\n",
    "    print(\"pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Dependencies\n",
    "\n",
    "First, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Any\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# Note: If you see a Pylance import error below, it's a false positive.\n",
    "# The import works correctly at runtime - the package is properly installed.\n",
    "from langgraph_checkpoint_aws.store.valkey import ValkeyStore, AsyncValkeyStore\n",
    "from langgraph_checkpoint_aws.agentcore.valkey import AgentCoreValkeySaver\n",
    "from valkey import Valkey\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Set up the configuration for Valkey connection, embeddings, and language model:\n",
    "\n",
    "### ValkeyStore Configuration\n",
    "\n",
    "- `VALKEY_ENDPOINT`: Use `localhost:6379` for local testing, or `my-cluster.cache.amazonaws.com:6379` for ElastiCache\n",
    "- `REGION`: AWS region where your resources are located\n",
    "- `MODEL_ID`: Bedrock model ID for the agent\n",
    "- `EMBEDDING_MODEL_ID`: Bedrock embeddings model for semantic search\n",
    "\n",
    "### Namespaces for Memory Organization\n",
    "\n",
    "ValkeyStore uses hierarchical namespaces to organize data:\n",
    "\n",
    "- `(actor_id, session_id)`: Conversation messages (session-specific)\n",
    "- `(\"facts\", actor_id)`: Extracted facts (cross-session)\n",
    "- `(\"preferences\", actor_id)`: User preferences (cross-session)\n",
    "\n",
    "This mirrors AgentCore Memory's namespace structure for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VALKEY_ENDPOINT = \"localhost:6379\"  # Use localhost for local testing\n",
    "REGION = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-premier-v1:0\"\n",
    "EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "print(f\"   - Valkey URL: valkey://{VALKEY_ENDPOINT}\")\n",
    "print(f\"   - Model ID: {MODEL_ID}\")\n",
    "print(f\"   - Embedding Model: {EMBEDDING_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Initialize Valkey Clients\n",
    "\n",
    "Create separate Valkey clients for checkpointing and memory storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó Creating Valkey clients...\")\n",
    "\n",
    "# Create separate clients for checkpoint and store\n",
    "checkpoint_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "store_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Valkey clients created successfully!\")\n",
    "print(f\"   - Checkpoint client: max_connections=20\")\n",
    "print(f\"   - Store client: max_connections=20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Initialize Embeddings\n",
    "\n",
    "Initialize Bedrock embeddings for semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Initializing Bedrock embeddings...\")\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "try:\n",
    "    # Configure boto3 for async concurrency\n",
    "    bedrock_config = Config(\n",
    "        max_pool_connections=50,\n",
    "        retries={'max_attempts': 3, 'mode': 'adaptive'}\n",
    "    )\n",
    "    \n",
    "    embeddings = BedrockEmbeddings(\n",
    "        model_id=EMBEDDING_MODEL_ID,\n",
    "        region_name=REGION\n",
    "    ,\n",
    "        client=boto3.client(\n",
    "            \"bedrock-runtime\",\n",
    "            config=bedrock_config\n",
    "        )\n",
    "    )\n",
    "    print(\"‚úÖ Bedrock embeddings initialized successfully!\")\n",
    "    print(f\"   - Model: {EMBEDDING_MODEL_ID}\")\n",
    "    print(f\"   - Dimensions: 1024 (Titan Embed Text v2)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize embeddings: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Create ValkeyStore with Semantic Search\n",
    "\n",
    "Create the ValkeyStore with vector search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß† Creating ValkeyStore with semantic search...\")\n",
    "# Define shared ValkeyIndexConfig to avoid duplication\n",
    "valkey_index_config = {\n",
    "    \"collection_name\": \"long_term_memory\",\n",
    "    \"dims\": 1024,  # Titan Embed Text v2 dimensions\n",
    "    \"embed\": embeddings,\n",
    "    \"fields\": [\"text\", \"content\"],  # Fields to embed for search\n",
    "    \"timezone\": \"UTC\",\n",
    "    \"index_type\": \"hnsw\",  # High-performance approximate search\n",
    "    \"distance_metric\": \"COSINE\"\n",
    "}\n",
    "\n",
    "valkey_ttl_config = {\"default_ttl\": None}  # No expiration for long-term memory\n",
    "\n",
    "try:\n",
    "    store = ValkeyStore(\n",
    "        client=store_client,\n",
    "        index=valkey_index_config,\n",
    "        ttl=valkey_ttl_config\n",
    "    )\n",
    "    \n",
    "    # Setup the index\n",
    "    store.setup()\n",
    "    \n",
    "    print(\"‚úÖ ValkeyStore created and configured!\")\n",
    "    print(f\"   - Index name: long_term_memory\")\n",
    "    print(f\"   - Vector dimensions: 1024\")\n",
    "    print(f\"   - Index type: HNSW (High-performance)\")\n",
    "    print(f\"   - Distance metric: COSINE\")\n",
    "    print(f\"   - TTL: None (persistent storage)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create ValkeyStore: {e}\")\n",
    "    print(\"Please ensure Valkey server with Search module is running.\")\n",
    "    raise\n",
    "# Create AsyncValkeyStore with same configuration\n",
    "async_store = AsyncValkeyStore(\n",
    "    client=store_client,\n",
    "    index=valkey_index_config,\n",
    "    ttl=valkey_ttl_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AsyncValkeyStore created with same configuration as sync store\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Create AgentCore Valkey Checkpointer\n",
    "\n",
    "Create the checkpointer for short-term conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîÑ Creating AgentCore Valkey checkpointer...\")\n",
    "\n",
    "try:\n",
    "    checkpointer = AgentCoreValkeySaver(\n",
    "        client=checkpoint_client,\n",
    "        ttl=86400  # 24 hour checkpoint retention\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ AgentCore Valkey checkpointer created successfully!\")\n",
    "    print(f\"   - TTL: 86400 seconds (24 hours)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create checkpointer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Initialize Language Model\n",
    "\n",
    "Initialize the Bedrock language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ü§ñ Initializing language model...\")\n",
    "\n",
    "try:\n",
    "    model = init_chat_model(\n",
    "        MODEL_ID,\n",
    "        model_provider=\"bedrock_converse\",\n",
    "        region_name=REGION\n",
    "    )\n",
    "    print(\"‚úÖ Language model initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize model: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Create Agent with Store Integration\n",
    "\n",
    "Create the agent graph with both checkpointer and store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üé® Creating agent graph...\")\n",
    "\n",
    "# Create agent with checkpointer and store\n",
    "graph = create_agent(\n",
    "    model,\n",
    "    tools=[],  # No tools for this example, just conversation\n",
    "    checkpointer=checkpointer,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent graph created successfully!\")\n",
    "print(\"   - Checkpointer: AgentCoreValkeySaver (short-term state)\")\n",
    "print(\"   - Store: ValkeyStore (long-term memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Memory Helper Functions\n",
    "\n",
    "Define helper functions for manual memory management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_message_to_store(store, actor_id, thread_id, message, role):\n",
    "    \"\"\"Save a message to ValkeyStore with proper namespace.\"\"\"\n",
    "    namespace = (actor_id, thread_id)\n",
    "    \n",
    "    # Extract serializable content from message\n",
    "    text_content = message.content if hasattr(message, 'content') else str(message)\n",
    "    \n",
    "    store.put(\n",
    "        namespace,\n",
    "        str(uuid.uuid4()),\n",
    "        value={\n",
    "            'text': text_content,  # Required for vector embedding\n",
    "            'content': text_content,  # For retrieval\n",
    "            'role': role,\n",
    "            'actor_id': actor_id,\n",
    "            'session_id': thread_id,\n",
    "            'message_type': type(message).__name__  # Store type as string\n",
    "        },\n",
    "        index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "    )\n",
    "\n",
    "def get_relevant_context(store, actor_id, query, limit=5):\n",
    "    \"\"\"Search ValkeyStore for relevant user preferences.\"\"\"\n",
    "    preferences_namespace = ('preferences', actor_id)\n",
    "    results = store.search(preferences_namespace, query=query, limit=limit)\n",
    "    return [r.value.get('content', r.value) for r in results]\n",
    "\n",
    "def run_agent(query: str, config: RunnableConfig):\n",
    "    \"\"\"Run agent, print output, and save messages to ValkeyStore.\"\"\"\n",
    "    actor_id = config.get('configurable', {}).get('actor_id', 'default')\n",
    "    thread_id = config.get('configurable', {}).get('thread_id', 'default')\n",
    "    \n",
    "    # Before running agent: search for relevant context\n",
    "    context = get_relevant_context(store, actor_id, query)\n",
    "    if context:\n",
    "        print(f\"üìö Found {len(context)} relevant preferences from past conversations\")\n",
    "    \n",
    "    printed_ids = set()\n",
    "    user_message = None\n",
    "    ai_message = None\n",
    "    \n",
    "    events = graph.stream(\n",
    "        {'messages': [{'role': 'user', 'content': query}]},\n",
    "        config,\n",
    "        stream_mode='values',\n",
    "    )\n",
    "    \n",
    "    for event in events:\n",
    "        if 'messages' in event:\n",
    "            for msg in event['messages']:\n",
    "                if id(msg) not in printed_ids:\n",
    "                    msg.pretty_print()\n",
    "                    printed_ids.add(id(msg))\n",
    "                    \n",
    "                    # Capture messages for saving\n",
    "                    if isinstance(msg, HumanMessage):\n",
    "                        user_message = msg\n",
    "                    elif isinstance(msg, AIMessage):\n",
    "                        ai_message = msg\n",
    "    \n",
    "    # After agent runs: save messages to ValkeyStore\n",
    "    if user_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, user_message, 'user')\n",
    "        print(f\"üíæ Saved user message to ValkeyStore\")\n",
    "    \n",
    "    if ai_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, ai_message, 'assistant')\n",
    "        print(f\"üíæ Saved assistant message to ValkeyStore\")\n",
    "        \n",
    "        # Extract and save preferences if detected\n",
    "        print(f\"üîç Checking for preferences in user message...\")\n",
    "        if user_message:\n",
    "            user_text = user_message.content.lower()\n",
    "            if any(kw in user_text for kw in ['favorite', 'like', 'love', 'prefer', 'enjoy']):\n",
    "                preferences_namespace = ('preferences', actor_id)\n",
    "                store.put(\n",
    "                    preferences_namespace,\n",
    "                    f'pref_{uuid.uuid4()}',\n",
    "                    value={\n",
    "                        'content': user_message.content[:500],\n",
    "                        'text': user_message.content[:500],\n",
    "                        'extracted_from': thread_id,\n",
    "                        'type': 'preference'\n",
    "                    },\n",
    "                    index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "                )\n",
    "                print(f\"üîñ Extracted and saved user preference\")\n",
    "\n",
    "print(\"‚úÖ Memory helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Configure Session\n",
    "\n",
    "Set up the session configuration with both `actor_id` and `thread_id`:\n",
    "\n",
    "### LangGraph RuntimeConfig\n",
    "\n",
    "The `config` dictionary is crucial for ValkeyStore's namespace organization:\n",
    "\n",
    "- **`actor_id`**: Identifies the user/agent (e.g., `user-123`, `agent-abc`)\n",
    "  - Used as the root namespace for long-term memories\n",
    "  - Enables multi-tenancy (isolate users)\n",
    "  - Compatible with AgentCore's actor concept\n",
    "\n",
    "- **`thread_id`**: Identifies the conversation session (e.g., `session-001`)\n",
    "  - Used for conversation-specific data\n",
    "  - Enables multiple concurrent conversations per user\n",
    "  - Maps to AgentCore's session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for session management\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-1\",  # Session identifier\n",
    "        \"actor_id\": \"user-1\",         # User identifier\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Session configuration:\")\n",
    "for key, value in config[\"configurable\"].items():\n",
    "    print(f\"   - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ First Conversation\n",
    "\n",
    "Let's start a conversation where the user shares their cooking preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üí¨ Starting first conversation...\")\n",
    "print(\"=\"*80)\n",
    "print(\"FIRST CONVERSATION - Session 1\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and veggies (healthy). It has\n",
    "great macros for my weightlifting competition that is coming up. What can I add to this dish to make it taste better\n",
    "and also improve the protein and vitamins I get?\n",
    "\"\"\"\n",
    "\n",
    "run_agent(prompt, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Verify Storage\n",
    "\n",
    "Let's verify what was stored in ValkeyStore:\n",
    "\n",
    "### What Was Stored?\n",
    "\n",
    "1. **User message** ‚Üí `(\"user-1\", \"session-id-1\")` namespace\n",
    "2. **Assistant message** ‚Üí `(\"user-1\", \"session-id-1\")` namespace\n",
    "3. **User preferences** ‚Üí `(\"preferences\", \"user-1\")` namespace (extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Storage Information:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check message keys\n",
    "message_keys = store_client.keys('*user-1*/session-id-1*')\n",
    "print(f\"\\nüìù Session messages: {len(message_keys)} keys\")\n",
    "if message_keys:\n",
    "    print(f\"   Sample: {message_keys[0].decode()}\")\n",
    "\n",
    "# Check preference keys\n",
    "preference_keys = store_client.keys('*preferences/user-1*')\n",
    "print(f\"\\n‚≠ê User preferences: {len(preference_keys)} keys\")\n",
    "if preference_keys:\n",
    "    print(f\"   Sample: {preference_keys[0].decode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Second Conversation (New Session)\n",
    "\n",
    "Start a new session to demonstrate cross-session memory retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New session configuration\n",
    "config2 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-2\",  # New session\n",
    "        \"actor_id\": \"user-1\",         # Same user\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECOND CONVERSATION - Session 2 (Same User)\")\n",
    "print(\"=\"*80)\n",
    "print(\"üîç This will demonstrate cross-session memory retrieval\\n\")\n",
    "\n",
    "prompt2 = \"What are some good dinner ideas for tonight?\"\n",
    "\n",
    "run_agent(prompt2, config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Semantic Search Examples\n",
    "\n",
    "Demonstrate semantic search capabilities by querying related concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEMANTIC SEARCH EXAMPLES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Search by related concept (not exact keyword)\n",
    "test_queries = [\n",
    "    (\"protein-rich foods\", \"Should find salmon/weightlifting context\"),\n",
    "    (\"athletic nutrition\", \"Should find healthy eating preferences\"),\n",
    "    (\"dinner ideas\", \"Should find cooking-related memories\")\n",
    "]\n",
    "\n",
    "for query, description in test_queries:\n",
    "    print(f\"üîç Query: '{query}'\")\n",
    "    print(f\"   Expected: {description}\")\n",
    "    \n",
    "    results = store.search((\"preferences\", \"user-1\"), query=query, limit=3)\n",
    "    print(f\"   ‚úÖ Found {len(results)} results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        content = result.value.get(\"content\", \"\")[:80]\n",
    "        print(f\"      {i}. {content}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Async Semantic Search\n",
    "\n",
    "Demonstrate async search capabilities and verify parity with sync results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ASYNC SEMANTIC SEARCH DEMONSTRATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test async search and compare with sync\n",
    "test_query = \"protein-rich foods\"\n",
    "print(f\"üîç Test Query: '{test_query}'\\n\")\n",
    "\n",
    "# Sync search\n",
    "sync_results = store.search((\"preferences\", \"user-1\"), query=test_query, limit=3)\n",
    "print(f\"üîµ Sync Search Results: {len(sync_results)} found\")\n",
    "for i, result in enumerate(sync_results, 1):\n",
    "    content = result.value.get(\"content\", \"\")[:60]\n",
    "    print(f\"   {i}. Score: {result.score:.4f} - {content}...\")\n",
    "\n",
    "# Async search\n",
    "async_results = await async_store.asearch((\"preferences\", \"user-1\"), query=test_query, limit=3)\n",
    "print(f\"\\nüü¢ Async Search Results: {len(async_results)} found\")\n",
    "for i, result in enumerate(async_results, 1):\n",
    "    content = result.value.get(\"content\", \"\")[:60]\n",
    "    print(f\"   {i}. Score: {result.score:.4f} - {content}...\")\n",
    "\n",
    "# Verify parity\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYNC/ASYNC PARITY VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(sync_results) == len(async_results):\n",
    "    print(f\"‚úÖ Result count matches: {len(sync_results)} results from both\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Result count differs: sync={len(sync_results)}, async={len(async_results)}\")\n",
    "\n",
    "# Compare scores and content\n",
    "for i, (sync_res, async_res) in enumerate(zip(sync_results, async_results), 1):\n",
    "    score_diff = abs(sync_res.score - async_res.score)\n",
    "    if score_diff < 0.0001:\n",
    "        print(f\"   Result {i}: ‚úÖ Scores match ({sync_res.score:.4f})\")\n",
    "    else:\n",
    "        print(f\"   Result {i}: ‚ö†Ô∏è  Score diff: {score_diff:.6f}\")\n",
    "    \n",
    "    if sync_res.key == async_res.key:\n",
    "        print(f\"             ‚úÖ Keys match: {sync_res.key}\")\n",
    "    else:\n",
    "        print(f\"             ‚ö†Ô∏è  Keys differ: {sync_res.key} vs {async_res.key}\")\n",
    "\n",
    "print(\"\\nüéâ Async search demonstration complete!\")\n",
    "print(\"   Both sync and async search return identical results with same scores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Demonstrate cleanup functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üßπ Cleanup Options\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è  The following code is commented out to prevent accidental data deletion.\")\n",
    "print(\"Uncomment to clean up demo data:\\n\")\n",
    "\n",
    "# WARNING: This deletes all data for user-1\n",
    "# Uncomment to run:\n",
    "\n",
    "# print(\"Deleting preferences...\")\n",
    "# preferences = store.search((\"preferences\", \"user-1\"), query=\"*\", limit=100)\n",
    "# for pref in preferences:\n",
    "#     store.delete((\"preferences\", \"user-1\"), pref.key)\n",
    "# print(f\"‚úÖ Deleted {len(preferences)} preferences\")\n",
    "\n",
    "# print(\"\\nDeleting session 1 messages...\")\n",
    "# session1 = store.search((\"user-1\", \"session-id-1\"), query=\"*\", limit=100)\n",
    "# for msg in session1:\n",
    "#     store.delete((\"user-1\", \"session-id-1\"), msg.key)\n",
    "# print(f\"‚úÖ Deleted {len(session1)} session 1 messages\")\n",
    "\n",
    "# print(\"\\nDeleting session 2 messages...\")\n",
    "# session2 = store.search((\"user-1\", \"session-id-2\"), query=\"*\", limit=100)\n",
    "# for msg in session2:\n",
    "#     store.delete((\"user-1\", \"session-id-2\"), msg.key)\n",
    "# print(f\"‚úÖ Deleted {len(session2)} session 2 messages\")\n",
    "\n",
    "# print(\"\\n‚úÖ All data deleted for user-1\")\n",
    "\n",
    "print(\"To clean up, uncomment the code above and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Summary\n",
    "\n",
    "Congratulations! You've successfully demonstrated the **ValkeyStore/AsyncValkeyStore** with semantic search capabilities combined with **AgentCoreValkeySaver** for checkpoint persistence.\n",
    "\n",
    "### Key Benefits Demonstrated:\n",
    "\n",
    "- üß† **Long-term memory storage** with ValkeyStore\n",
    "- üîç **Semantic search** using vector embeddings\n",
    "- üóÇÔ∏è **Namespace organization** for data isolation\n",
    "- üöÄ **AgentCore-compatible** session management\n",
    "- üìä **Cross-session memory** retrieval\n",
    "- üéØ **Preference extraction** and storage\n",
    "- üîÑ **TTL support** for data lifecycle management\n",
    "- üèä **Connection pooling** for scalability\n",
    "\n",
    "### What We Covered:\n",
    "\n",
    "1. **Basic Setup**: Created ValkeyStore with vector search index\n",
    "2. **Agent Integration**: Used with LangGraph agents and checkpointer\n",
    "3. **Session Management**: AgentCore-compatible actor_id and thread_id patterns\n",
    "4. **Memory Storage**: Manual message and preference storage\n",
    "5. **Cross-Session Retrieval**: Demonstrated long-term memory access\n",
    "6. **Semantic Search**: Vector-based similarity search\n",
    "8. **Cleanup**: Proper resource management\n",
    "\n",
    "### üéØ Namespace Organization Best Practices:\n",
    "\n",
    "| Namespace | Purpose | Scope | TTL |\n",
    "|-----------|---------|-------|-----|\n",
    "| `(actor_id, session_id)` | Conversation messages | Session | 24h |\n",
    "| `(\"preferences\", actor_id)` | User preferences | Cross-session | None |\n",
    "| `(\"facts\", actor_id)` | Extracted facts | Cross-session | None |\n",
    "| `(\"knowledge\", \"global\")` | Shared knowledge | Global | None |\n",
    "\n",
    "### üîó Architecture:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ           LangGraph Agent                   ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                             ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ AgentCoreValkey  ‚îÇ  ‚îÇ ValkeyStore/    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ     Saver        ‚îÇ  ‚îÇ AsyncValkeyStore‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (Short-term)    ‚îÇ  ‚îÇ  (Long-term)    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ           ‚îÇ                     ‚îÇ           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                     ‚îÇ\n",
    "            ‚ñº                     ‚ñº\n",
    "      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "      ‚îÇ   Valkey / ElastiCache       ‚îÇ\n",
    "      ‚îÇ  (with Search module)        ‚îÇ\n",
    "      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "The **ValkeyStore/AsyncValkeyStore** provides a powerful, scalable solution for long-term memory storage with semantic search that works seamlessly with AgentCore session management patterns! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
