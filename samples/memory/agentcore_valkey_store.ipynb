{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ§  AgentCore Valkey Store Usage Example\n",
    "\n",
    "This notebook demonstrates how to use the **ValkeyStore** for long-term memory storage with semantic search capabilities, combined with **AgentCoreValkeySaver** for short-term conversation state management.\n",
    "\n",
    "## ğŸ“‹ Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Valkey server** with Search module support:\n",
    "   - **Local testing**: `docker run -d -p 6379:6379 valkey/valkey-bundle:latest`\n",
    "   - âš ï¸ Standard `valkey/valkey:latest` does NOT include Search module\n",
    "   - **Production**: Amazon ElastiCache Valkey with Self-Designed cluster (includes Search module)\n",
    "2. **AWS credentials** configured for Bedrock access\n",
    "3. **Required packages** installed:\n",
    "   ```bash\n",
    "   pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\n",
    "   ```\n",
    "   Note: Use quotes around `'langgraph-checkpoint-aws[valkey]'` for zsh shell\n",
    "   ```\n",
    "\n",
    "## ğŸ¯ Key Features\n",
    "\n",
    "- ğŸ§  **Long-term memory** storage with ValkeyStore\n",
    "- ğŸ” **Semantic search** using vector embeddings\n",
    "- ğŸ—‚ï¸ **Namespace organization** for data isolation\n",
    "- ğŸš€ **AgentCore-compatible** session management\n",
    "- ğŸ”„ **TTL support** for automatic cleanup\n",
    "- ğŸŠ **Connection pooling** for scalability\n",
    "- ğŸ“Š **Cross-session memory** for personalized interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Verify Package Installation\n",
    "\n",
    "Let's first verify that all required packages are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Checking installed packages...\n",
      "\n",
      "âœ… langchain\n",
      "âœ… langchain_aws\n",
      "âœ… langchain_core\n",
      "âœ… langgraph\n",
      "âœ… langgraph_checkpoint_aws\n",
      "âœ… valkey\n",
      "\n",
      "âœ… All required packages are installed!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "required_packages = [\n",
    "    'langchain',\n",
    "    'langchain_aws',\n",
    "    'langchain_core',\n",
    "    'langgraph',\n",
    "    'langgraph_checkpoint_aws',\n",
    "    'valkey'\n",
    "]\n",
    "\n",
    "print(\"ğŸ” Checking installed packages...\\n\")\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"âœ… {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package} - NOT INSTALLED\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"\\nPlease install them using:\")\n",
    "    print(\"pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\")\n",
    "else:\n",
    "    print(\"\\nâœ… All required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Import Dependencies\n",
    "\n",
    "First, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Any\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# Note: If you see a Pylance import error below, it's a false positive.\n",
    "# The import works correctly at runtime - the package is properly installed.\n",
    "from langgraph_checkpoint_aws.store.valkey import ValkeyStore\n",
    "from langgraph_checkpoint_aws.agentcore.valkey import AgentCoreValkeySaver\n",
    "from valkey import Valkey\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"âœ… All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Configuration\n",
    "\n",
    "Set up the configuration for Valkey connection, embeddings, and language model:\n",
    "\n",
    "### ValkeyStore Configuration\n",
    "\n",
    "- `VALKEY_ENDPOINT`: Use `localhost:6379` for local testing, or `my-cluster.cache.amazonaws.com:6379` for ElastiCache\n",
    "- `REGION`: AWS region where your resources are located\n",
    "- `MODEL_ID`: Bedrock model ID for the agent\n",
    "- `EMBEDDING_MODEL_ID`: Bedrock embeddings model for semantic search\n",
    "\n",
    "### Namespaces for Memory Organization\n",
    "\n",
    "ValkeyStore uses hierarchical namespaces to organize data:\n",
    "\n",
    "- `(actor_id, session_id)`: Conversation messages (session-specific)\n",
    "- `(\"facts\", actor_id)`: Extracted facts (cross-session)\n",
    "- `(\"preferences\", actor_id)`: User preferences (cross-session)\n",
    "\n",
    "This mirrors AgentCore Memory's namespace structure for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Configuration:\n",
      "   - Valkey URL: valkey://localhost:6379\n",
      "   - Model ID: us.amazon.nova-premier-v1:0\n",
      "   - Embedding Model: amazon.titan-embed-text-v2:0\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "VALKEY_ENDPOINT = \"localhost:6379\"  # Use localhost for local testing\n",
    "REGION = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-premier-v1:0\"\n",
    "EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "print(\"ğŸ“‹ Configuration:\")\n",
    "print(f\"   - Valkey URL: valkey://{VALKEY_ENDPOINT}\")\n",
    "print(f\"   - Model ID: {MODEL_ID}\")\n",
    "print(f\"   - Embedding Model: {EMBEDDING_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”— Initialize Valkey Clients\n",
    "\n",
    "Create separate Valkey clients for checkpointing and memory storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— Creating Valkey clients...\n",
      "âœ… Valkey clients created successfully!\n",
      "   - Checkpoint client: max_connections=20\n",
      "   - Store client: max_connections=20\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”— Creating Valkey clients...\")\n",
    "\n",
    "# Create separate clients for checkpoint and store\n",
    "checkpoint_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "store_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "print(\"âœ… Valkey clients created successfully!\")\n",
    "print(f\"   - Checkpoint client: max_connections=20\")\n",
    "print(f\"   - Store client: max_connections=20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Initialize Embeddings\n",
    "\n",
    "Initialize Bedrock embeddings for semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Initializing Bedrock embeddings...\n",
      "âœ… Bedrock embeddings initialized successfully!\n",
      "   - Model: amazon.titan-embed-text-v2:0\n",
      "   - Dimensions: 1024 (Titan Embed Text v2)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ” Initializing Bedrock embeddings...\")\n",
    "\n",
    "try:\n",
    "    embeddings = BedrockEmbeddings(\n",
    "        model_id=EMBEDDING_MODEL_ID,\n",
    "        region_name=REGION\n",
    "    )\n",
    "    print(\"âœ… Bedrock embeddings initialized successfully!\")\n",
    "    print(f\"   - Model: {EMBEDDING_MODEL_ID}\")\n",
    "    print(f\"   - Dimensions: 1024 (Titan Embed Text v2)\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to initialize embeddings: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Create ValkeyStore with Semantic Search\n",
    "\n",
    "Create the ValkeyStore with vector search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Creating ValkeyStore with semantic search...\n",
      "âœ… ValkeyStore created and configured!\n",
      "   - Index name: long_term_memory\n",
      "   - Vector dimensions: 1024\n",
      "   - Index type: HNSW (High-performance)\n",
      "   - Distance metric: COSINE\n",
      "   - TTL: None (persistent storage)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§  Creating ValkeyStore with semantic search...\")\n",
    "\n",
    "try:\n",
    "    store = ValkeyStore(\n",
    "        client=store_client,\n",
    "        index={\n",
    "            \"collection_name\": \"long_term_memory\",\n",
    "            \"dims\": 1024,  # Titan Embed Text v2 dimensions\n",
    "            \"embed\": embeddings,\n",
    "            \"fields\": [\"text\", \"content\"],  # Fields to embed for search\n",
    "            \"timezone\": \"UTC\",\n",
    "            \"index_type\": \"hnsw\",  # High-performance approximate search\n",
    "            \"distance_metric\": \"COSINE\"\n",
    "        },\n",
    "        ttl={\"default_ttl\": None}  # No expiration for long-term memory\n",
    "    )\n",
    "    \n",
    "    # Setup the index\n",
    "    store.setup()\n",
    "    \n",
    "    print(\"âœ… ValkeyStore created and configured!\")\n",
    "    print(f\"   - Index name: long_term_memory\")\n",
    "    print(f\"   - Vector dimensions: 1024\")\n",
    "    print(f\"   - Index type: HNSW (High-performance)\")\n",
    "    print(f\"   - Distance metric: COSINE\")\n",
    "    print(f\"   - TTL: None (persistent storage)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create ValkeyStore: {e}\")\n",
    "    print(\"Please ensure Valkey server with Search module is running.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Create AgentCore Valkey Checkpointer\n",
    "\n",
    "Create the checkpointer for short-term conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”„ Creating AgentCore Valkey checkpointer...\n",
      "âœ… AgentCore Valkey checkpointer created successfully!\n",
      "   - TTL: 86400 seconds (24 hours)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ”„ Creating AgentCore Valkey checkpointer...\")\n",
    "\n",
    "try:\n",
    "    checkpointer = AgentCoreValkeySaver(\n",
    "        client=checkpoint_client,\n",
    "        ttl=86400  # 24 hour checkpoint retention\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… AgentCore Valkey checkpointer created successfully!\")\n",
    "    print(f\"   - TTL: 86400 seconds (24 hours)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to create checkpointer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¤– Initialize Language Model\n",
    "\n",
    "Initialize the Bedrock language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¤– Initializing language model...\n",
      "âœ… Language model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¤– Initializing language model...\")\n",
    "\n",
    "try:\n",
    "    model = init_chat_model(\n",
    "        MODEL_ID,\n",
    "        model_provider=\"bedrock_converse\",\n",
    "        region_name=REGION\n",
    "    )\n",
    "    print(\"âœ… Language model initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to initialize model: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¨ Create Agent with Store Integration\n",
    "\n",
    "Create the agent graph with both checkpointer and store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ Creating agent graph...\n",
      "âœ… Agent graph created successfully!\n",
      "   - Checkpointer: AgentCoreValkeySaver (short-term state)\n",
      "   - Store: ValkeyStore (long-term memory)\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ¨ Creating agent graph...\")\n",
    "\n",
    "# Create agent with checkpointer and store\n",
    "graph = create_agent(\n",
    "    model,\n",
    "    tools=[],  # No tools for this example, just conversation\n",
    "    checkpointer=checkpointer,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "print(\"âœ… Agent graph created successfully!\")\n",
    "print(\"   - Checkpointer: AgentCoreValkeySaver (short-term state)\")\n",
    "print(\"   - Store: ValkeyStore (long-term memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ› ï¸ Memory Helper Functions\n",
    "\n",
    "Define helper functions for manual memory management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Memory helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def save_message_to_store(store, actor_id, thread_id, message, role):\n",
    "    \"\"\"Save a message to ValkeyStore with proper namespace.\"\"\"\n",
    "    namespace = (actor_id, thread_id)\n",
    "    \n",
    "    # Extract serializable content from message\n",
    "    text_content = message.content if hasattr(message, 'content') else str(message)\n",
    "    \n",
    "    store.put(\n",
    "        namespace,\n",
    "        str(uuid.uuid4()),\n",
    "        value={\n",
    "            'text': text_content,  # Required for vector embedding\n",
    "            'content': text_content,  # For retrieval\n",
    "            'role': role,\n",
    "            'actor_id': actor_id,\n",
    "            'session_id': thread_id,\n",
    "            'message_type': type(message).__name__  # Store type as string\n",
    "        },\n",
    "        index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "    )\n",
    "\n",
    "def get_relevant_context(store, actor_id, query, limit=5):\n",
    "    \"\"\"Search ValkeyStore for relevant user preferences.\"\"\"\n",
    "    preferences_namespace = ('preferences', actor_id)\n",
    "    results = store.search(preferences_namespace, query=query, limit=limit)\n",
    "    return [r.value.get('content', r.value) for r in results]\n",
    "\n",
    "def run_agent(query: str, config: RunnableConfig):\n",
    "    \"\"\"Run agent, print output, and save messages to ValkeyStore.\"\"\"\n",
    "    actor_id = config.get('configurable', {}).get('actor_id', 'default')\n",
    "    thread_id = config.get('configurable', {}).get('thread_id', 'default')\n",
    "    \n",
    "    # Before running agent: search for relevant context\n",
    "    context = get_relevant_context(store, actor_id, query)\n",
    "    if context:\n",
    "        print(f\"ğŸ“š Found {len(context)} relevant preferences from past conversations\")\n",
    "    \n",
    "    printed_ids = set()\n",
    "    user_message = None\n",
    "    ai_message = None\n",
    "    \n",
    "    events = graph.stream(\n",
    "        {'messages': [{'role': 'user', 'content': query}]},\n",
    "        config,\n",
    "        stream_mode='values',\n",
    "    )\n",
    "    \n",
    "    for event in events:\n",
    "        if 'messages' in event:\n",
    "            for msg in event['messages']:\n",
    "                if id(msg) not in printed_ids:\n",
    "                    msg.pretty_print()\n",
    "                    printed_ids.add(id(msg))\n",
    "                    \n",
    "                    # Capture messages for saving\n",
    "                    if isinstance(msg, HumanMessage):\n",
    "                        user_message = msg\n",
    "                    elif isinstance(msg, AIMessage):\n",
    "                        ai_message = msg\n",
    "    \n",
    "    # After agent runs: save messages to ValkeyStore\n",
    "    if user_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, user_message, 'user')\n",
    "        print(f\"ğŸ’¾ Saved user message to ValkeyStore\")\n",
    "    \n",
    "    if ai_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, ai_message, 'assistant')\n",
    "        print(f\"ğŸ’¾ Saved assistant message to ValkeyStore\")\n",
    "        \n",
    "        # Extract and save preferences if detected\n",
    "        print(f\"ğŸ” Checking for preferences in user message...\")\n",
    "        if user_message:\n",
    "            user_text = user_message.content.lower()\n",
    "            if any(kw in user_text for kw in ['favorite', 'like', 'love', 'prefer', 'enjoy']):\n",
    "                preferences_namespace = ('preferences', actor_id)\n",
    "                store.put(\n",
    "                    preferences_namespace,\n",
    "                    f'pref_{uuid.uuid4()}',\n",
    "                    value={\n",
    "                        'content': user_message.content[:500],\n",
    "                        'text': user_message.content[:500],\n",
    "                        'extracted_from': thread_id,\n",
    "                        'type': 'preference'\n",
    "                    },\n",
    "                    index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "                )\n",
    "                print(f\"ğŸ”– Extracted and saved user preference\")\n",
    "\n",
    "print(\"âœ… Memory helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ¯ Configure Session\n",
    "\n",
    "Set up the session configuration with both `actor_id` and `thread_id`:\n",
    "\n",
    "### LangGraph RuntimeConfig\n",
    "\n",
    "The `config` dictionary is crucial for ValkeyStore's namespace organization:\n",
    "\n",
    "- **`actor_id`**: Identifies the user/agent (e.g., `user-123`, `agent-abc`)\n",
    "  - Used as the root namespace for long-term memories\n",
    "  - Enables multi-tenancy (isolate users)\n",
    "  - Compatible with AgentCore's actor concept\n",
    "\n",
    "- **`thread_id`**: Identifies the conversation session (e.g., `session-001`)\n",
    "  - Used for conversation-specific data\n",
    "  - Enables multiple concurrent conversations per user\n",
    "  - Maps to AgentCore's session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ Session configuration:\n",
      "   - thread_id: session-id-1\n",
      "   - actor_id: user-1\n"
     ]
    }
   ],
   "source": [
    "# Configuration for session management\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-1\",  # Session identifier\n",
    "        \"actor_id\": \"user-1\",         # User identifier\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"ğŸ“‹ Session configuration:\")\n",
    "for key, value in config[\"configurable\"].items():\n",
    "    print(f\"   - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¬ First Conversation\n",
    "\n",
    "Let's start a conversation where the user shares their cooking preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¬ Starting first conversation...\n",
      "================================================================================\n",
      "FIRST CONVERSATION - Session 1\n",
      "================================================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and veggies (healthy). It has\n",
      "great macros for my weightlifting competition that is coming up. What can I add to this dish to make it taste better\n",
      "and also improve the protein and vitamins I get?\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a delicious and nutritious meal already! To enhance the flavor while boosting the protein and vitamin content, consider the following additions:\n",
      "\n",
      "1. **Avocado**: Slice or dice some avocado and add it on top of your salmon. It will add a creamy texture, healthy fats, and a good dose of vitamins E and B.\n",
      "\n",
      "2. **Lemon or Lime Juice**: Squeezing fresh lemon or lime juice over your salmon and veggies can brighten the flavors and add vitamin C.\n",
      "\n",
      "3. **Greek Yogurt or Tzatziki Sauce**: A dollop of Greek yogurt or tzatziki can add a tangy flavor and extra protein.\n",
      "\n",
      "4. **Nuts and Seeds**: Sprinkle some sliced almonds, chia seeds, or sesame seeds on top for added crunch, protein, and healthy fats.\n",
      "\n",
      "5. **Steamed or SautÃ©ed Spinach**: Adding spinach to your veggies will boost your iron, calcium, and vitamin K intake.\n",
      "\n",
      "6. **Beans or Lentils**: Mix in some chickpeas, black beans, or lentils to your rice for additional protein and fiber.\n",
      "\n",
      "7. **Fresh Herbs**: Garnish with fresh herbs like dill, parsley, or cilantro for added flavor and a touch of extra vitamins.\n",
      "\n",
      "8. **Nutritional Yeast**: Sprinkling some nutritional yeast can give a cheesy flavor and add B vitamins, particularly B12.\n",
      "\n",
      "9. **Broccoli or Asparagus**: Adding these veggies to your dish will increase the fiber content and provide vitamins A, C, and K.\n",
      "\n",
      "10. **Olive Oil**: Drizzle a bit of high-quality extra virgin olive oil for healthy fats and to enhance the overall flavor.\n",
      "\n",
      "These additions will not only make your meal more flavorful but also nutritionally dense, supporting your goals for the weightlifting competition. Enjoy your meal!\n",
      "ğŸ’¾ Saved user message to ValkeyStore\n",
      "ğŸ’¾ Saved assistant message to ValkeyStore\n",
      "ğŸ” Checking for preferences in user message...\n",
      "ğŸ”– Extracted and saved user preference\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ’¬ Starting first conversation...\")\n",
    "print(\"=\"*80)\n",
    "print(\"FIRST CONVERSATION - Session 1\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and veggies (healthy). It has\n",
    "great macros for my weightlifting competition that is coming up. What can I add to this dish to make it taste better\n",
    "and also improve the protein and vitamins I get?\n",
    "\"\"\"\n",
    "\n",
    "run_agent(prompt, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Verify Storage\n",
    "\n",
    "Let's verify what was stored in ValkeyStore:\n",
    "\n",
    "### What Was Stored?\n",
    "\n",
    "1. **User message** â†’ `(\"user-1\", \"session-id-1\")` namespace\n",
    "2. **Assistant message** â†’ `(\"user-1\", \"session-id-1\")` namespace\n",
    "3. **User preferences** â†’ `(\"preferences\", \"user-1\")` namespace (extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Storage Information:\n",
      "================================================================================\n",
      "\n",
      "ğŸ“ Session messages: 2 keys\n",
      "   Sample: langgraph:user-1/session-id-1/04e43b6c-2d87-4f9b-a7f5-de7f6de24fe8\n",
      "\n",
      "â­ User preferences: 1 keys\n",
      "   Sample: langgraph:preferences/user-1/pref_9ff29132-253f-4825-9b7e-bd418a2bf6d7\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ“Š Storage Information:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check message keys\n",
    "message_keys = store_client.keys('*user-1*/session-id-1*')\n",
    "print(f\"\\nğŸ“ Session messages: {len(message_keys)} keys\")\n",
    "if message_keys:\n",
    "    print(f\"   Sample: {message_keys[0].decode()}\")\n",
    "\n",
    "# Check preference keys\n",
    "preference_keys = store_client.keys('*preferences/user-1*')\n",
    "print(f\"\\nâ­ User preferences: {len(preference_keys)} keys\")\n",
    "if preference_keys:\n",
    "    print(f\"   Sample: {preference_keys[0].decode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”„ Second Conversation (New Session)\n",
    "\n",
    "Start a new session to demonstrate cross-session memory retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECOND CONVERSATION - Session 2 (Same User)\n",
      "================================================================================\n",
      "ğŸ” This will demonstrate cross-session memory retrieval\n",
      "\n",
      "ğŸ“š Found 1 relevant preferences from past conversations\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good dinner ideas for tonight?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are a few dinner ideas for tonight:\n",
      "\n",
      "1. **Grilled Chicken and Vegetable Skewers**: Marinate chicken pieces in olive oil, lemon juice, and herbs, then grill with bell peppers, onions, and zucchini.\n",
      "\n",
      "2. **Spaghetti Bolognese**: Simmer ground beef or turkey with tomatoes, garlic, onions, and Italian herbs. Serve over whole grain pasta.\n",
      "\n",
      "3. **Stir-Fried Tofu and Veggies**: SautÃ© tofu with a mix of colorful vegetables like broccoli, carrots, and snap peas in a light soy sauce.\n",
      "\n",
      "4. **Baked Salmon with Quinoa and Asparagus**: Season salmon with dill and lemon, bake with asparagus, and serve over a bed of quinoa.\n",
      "\n",
      "5. **Vegetarian Tacos**: Fill tortillas with black beans, corn, diced tomatoes, avocado, and a sprinkle of cheese. Top with fresh cilantro and lime.\n",
      "\n",
      "6. **Chicken and Vegetable Stir-Fry**: Cook sliced chicken with mixed vegetables in a savory sauce and serve over rice or noodles.\n",
      "\n",
      "7. **Homemade Pizza**: Use a pre-made crust or make your own, then top with your favorite sauce, cheese, and toppings.\n",
      "\n",
      "Choose one that fits your taste and the ingredients you have on hand! Enjoy your meal.\n",
      "ğŸ’¾ Saved user message to ValkeyStore\n",
      "ğŸ’¾ Saved assistant message to ValkeyStore\n",
      "ğŸ” Checking for preferences in user message...\n"
     ]
    }
   ],
   "source": [
    "# New session configuration\n",
    "config2 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-2\",  # New session\n",
    "        \"actor_id\": \"user-1\",         # Same user\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECOND CONVERSATION - Session 2 (Same User)\")\n",
    "print(\"=\"*80)\n",
    "print(\"ğŸ” This will demonstrate cross-session memory retrieval\\n\")\n",
    "\n",
    "prompt2 = \"What are some good dinner ideas for tonight?\"\n",
    "\n",
    "run_agent(prompt2, config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Semantic Search Examples\n",
    "\n",
    "Demonstrate semantic search capabilities by querying related concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SEMANTIC SEARCH EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "ğŸ” Query: 'protein-rich foods'\n",
      "   Expected: Should find salmon/weightlifting context\n",
      "   âœ… Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n",
      "ğŸ” Query: 'athletic nutrition'\n",
      "   Expected: Should find healthy eating preferences\n",
      "   âœ… Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n",
      "ğŸ” Query: 'dinner ideas'\n",
      "   Expected: Should find cooking-related memories\n",
      "   âœ… Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEMANTIC SEARCH EXAMPLES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Search by related concept (not exact keyword)\n",
    "test_queries = [\n",
    "    (\"protein-rich foods\", \"Should find salmon/weightlifting context\"),\n",
    "    (\"athletic nutrition\", \"Should find healthy eating preferences\"),\n",
    "    (\"dinner ideas\", \"Should find cooking-related memories\")\n",
    "]\n",
    "\n",
    "for query, description in test_queries:\n",
    "    print(f\"ğŸ” Query: '{query}'\")\n",
    "    print(f\"   Expected: {description}\")\n",
    "    \n",
    "    results = store.search((\"preferences\", \"user-1\"), query=query, limit=3)\n",
    "    print(f\"   âœ… Found {len(results)} results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        content = result.value.get(\"content\", \"\")[:80]\n",
    "        print(f\"      {i}. {content}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§¹ Cleanup (Optional)\n",
    "\n",
    "Demonstrate cleanup functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§¹ Cleanup Options\n",
      "================================================================================\n",
      "\n",
      "âš ï¸  The following code is commented out to prevent accidental data deletion.\n",
      "Uncomment to clean up demo data:\n",
      "\n",
      "To clean up, uncomment the code above and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸ§¹ Cleanup Options\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nâš ï¸  The following code is commented out to prevent accidental data deletion.\")\n",
    "print(\"Uncomment to clean up demo data:\\n\")\n",
    "\n",
    "# WARNING: This deletes all data for user-1\n",
    "# Uncomment to run:\n",
    "\n",
    "# print(\"Deleting preferences...\")\n",
    "# preferences = store.search((\"preferences\", \"user-1\"), query=\"*\", limit=100)\n",
    "# for pref in preferences:\n",
    "#     store.delete((\"preferences\", \"user-1\"), pref.key)\n",
    "# print(f\"âœ… Deleted {len(preferences)} preferences\")\n",
    "\n",
    "# print(\"\\nDeleting session 1 messages...\")\n",
    "# session1 = store.search((\"user-1\", \"session-id-1\"), query=\"*\", limit=100)\n",
    "# for msg in session1:\n",
    "#     store.delete((\"user-1\", \"session-id-1\"), msg.key)\n",
    "# print(f\"âœ… Deleted {len(session1)} session 1 messages\")\n",
    "\n",
    "# print(\"\\nDeleting session 2 messages...\")\n",
    "# session2 = store.search((\"user-1\", \"session-id-2\"), query=\"*\", limit=100)\n",
    "# for msg in session2:\n",
    "#     store.delete((\"user-1\", \"session-id-2\"), msg.key)\n",
    "# print(f\"âœ… Deleted {len(session2)} session 2 messages\")\n",
    "\n",
    "# print(\"\\nâœ… All data deleted for user-1\")\n",
    "\n",
    "print(\"To clean up, uncomment the code above and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‰ Summary\n",
    "\n",
    "Congratulations! You've successfully demonstrated the **ValkeyStore** with semantic search capabilities combined with **AgentCoreValkeySaver** for checkpoint persistence.\n",
    "\n",
    "### Key Benefits Demonstrated:\n",
    "\n",
    "- ğŸ§  **Long-term memory storage** with ValkeyStore\n",
    "- ğŸ” **Semantic search** using vector embeddings\n",
    "- ğŸ—‚ï¸ **Namespace organization** for data isolation\n",
    "- ğŸš€ **AgentCore-compatible** session management\n",
    "- ğŸ“Š **Cross-session memory** retrieval\n",
    "- ğŸ¯ **Preference extraction** and storage\n",
    "- ğŸ”„ **TTL support** for data lifecycle management\n",
    "- ğŸŠ **Connection pooling** for scalability\n",
    "\n",
    "### What We Covered:\n",
    "\n",
    "1. **Basic Setup**: Created ValkeyStore with vector search index\n",
    "2. **Agent Integration**: Used with LangGraph agents and checkpointer\n",
    "3. **Session Management**: AgentCore-compatible actor_id and thread_id patterns\n",
    "4. **Memory Storage**: Manual message and preference storage\n",
    "5. **Cross-Session Retrieval**: Demonstrated long-term memory access\n",
    "6. **Semantic Search**: Vector-based similarity search\n",
    "8. **Cleanup**: Proper resource management\n",
    "\n",
    "### ğŸ¯ Namespace Organization Best Practices:\n",
    "\n",
    "| Namespace | Purpose | Scope | TTL |\n",
    "|-----------|---------|-------|-----|\n",
    "| `(actor_id, session_id)` | Conversation messages | Session | 24h |\n",
    "| `(\"preferences\", actor_id)` | User preferences | Cross-session | None |\n",
    "| `(\"facts\", actor_id)` | Extracted facts | Cross-session | None |\n",
    "| `(\"knowledge\", \"global\")` | Shared knowledge | Global | None |\n",
    "\n",
    "### ğŸ”— Architecture:\n",
    "\n",
    "```\n",
    "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "â”‚           LangGraph Agent                   â”‚\n",
    "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
    "â”‚                                             â”‚\n",
    "â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚\n",
    "â”‚  â”‚ AgentCoreValkey  â”‚  â”‚  ValkeyStore    â”‚â”‚\n",
    "â”‚  â”‚     Saver        â”‚  â”‚  (Long-term)    â”‚â”‚\n",
    "â”‚  â”‚  (Short-term)    â”‚  â”‚                 â”‚â”‚\n",
    "â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚\n",
    "â”‚           â”‚                     â”‚          â”‚\n",
    "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "            â”‚                     â”‚\n",
    "            â–¼                     â–¼\n",
    "      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
    "      â”‚   Valkey / ElastiCache       â”‚\n",
    "      â”‚  (with Search module)        â”‚\n",
    "      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
    "```\n",
    "\n",
    "The **ValkeyStore** provides a powerful, scalable solution for long-term memory storage with semantic search that works seamlessly with AgentCore session management patterns! ğŸš€"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
