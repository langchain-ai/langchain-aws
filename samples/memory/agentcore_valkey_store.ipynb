{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† AgentCore Valkey Store Usage Example\n",
    "\n",
    "This notebook demonstrates how to use the **ValkeyStore** for long-term memory storage with semantic search capabilities, combined with **AgentCoreValkeySaver** for short-term conversation state management.\n",
    "\n",
    "## üìã Prerequisites\n",
    "\n",
    "Before running this notebook, ensure you have:\n",
    "\n",
    "1. **Valkey server** with Search module support:\n",
    "   - **Local testing**: `docker run -d -p 6379:6379 valkey/valkey-bundle:latest`\n",
    "   - ‚ö†Ô∏è Standard `valkey/valkey:latest` does NOT include Search module\n",
    "   - **Production**: Amazon ElastiCache Valkey with Self-Designed cluster (includes Search module)\n",
    "2. **AWS credentials** configured for Bedrock access\n",
    "3. **Required packages** installed:\n",
    "   ```bash\n",
    "   pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\n",
    "   ```\n",
    "   Note: Use quotes around `'langgraph-checkpoint-aws[valkey]'` for zsh shell\n",
    "   ```\n",
    "\n",
    "## üéØ Key Features\n",
    "\n",
    "- üß† **Long-term memory** storage with ValkeyStore\n",
    "- üîç **Semantic search** using vector embeddings\n",
    "- üóÇÔ∏è **Namespace organization** for data isolation\n",
    "- üöÄ **AgentCore-compatible** session management\n",
    "- üîÑ **TTL support** for automatic cleanup\n",
    "- üèä **Connection pooling** for scalability\n",
    "- üìä **Cross-session memory** for personalized interactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Verify Package Installation\n",
    "\n",
    "Let's first verify that all required packages are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking installed packages...\n",
      "\n",
      "‚úÖ langchain\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/workplace/github/langchain-aws/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ langchain_aws\n",
      "‚úÖ langchain_core\n",
      "‚úÖ langgraph\n",
      "‚úÖ langgraph_checkpoint_aws\n",
      "‚úÖ valkey\n",
      "\n",
      "‚úÖ All required packages are installed!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "required_packages = [\n",
    "    'langchain',\n",
    "    'langchain_aws',\n",
    "    'langchain_core',\n",
    "    'langgraph',\n",
    "    'langgraph_checkpoint_aws',\n",
    "    'valkey'\n",
    "]\n",
    "\n",
    "print(\"üîç Checking installed packages...\\n\")\n",
    "missing_packages = []\n",
    "for package in required_packages:\n",
    "    try:\n",
    "        __import__(package)\n",
    "        print(f\"‚úÖ {package}\")\n",
    "    except ImportError:\n",
    "        print(f\"‚ùå {package} - NOT INSTALLED\")\n",
    "        missing_packages.append(package)\n",
    "\n",
    "if missing_packages:\n",
    "    print(f\"\\n‚ö†Ô∏è  Missing packages: {', '.join(missing_packages)}\")\n",
    "    print(\"\\nPlease install them using:\")\n",
    "    print(\"pip install valkey langchain-aws langchain langgraph 'langgraph-checkpoint-aws[valkey]' langchain-community\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ All required packages are installed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ Import Dependencies\n",
    "\n",
    "First, let's import all the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ All dependencies imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import uuid\n",
    "import logging\n",
    "from typing import Any\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# Note: If you see a Pylance import error below, it's a false positive.\n",
    "# The import works correctly at runtime - the package is properly installed.\n",
    "from langgraph_checkpoint_aws.store.valkey import ValkeyStore, AsyncValkeyStore\n",
    "from langgraph_checkpoint_aws.agentcore.valkey import AgentCoreValkeySaver\n",
    "from valkey import Valkey\n",
    "\n",
    "logging.getLogger().setLevel(logging.INFO)\n",
    "\n",
    "print(\"‚úÖ All dependencies imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configuration\n",
    "\n",
    "Set up the configuration for Valkey connection, embeddings, and language model:\n",
    "\n",
    "### ValkeyStore Configuration\n",
    "\n",
    "- `VALKEY_ENDPOINT`: Use `localhost:6379` for local testing, or `my-cluster.cache.amazonaws.com:6379` for ElastiCache\n",
    "- `REGION`: AWS region where your resources are located\n",
    "- `MODEL_ID`: Bedrock model ID for the agent\n",
    "- `EMBEDDING_MODEL_ID`: Bedrock embeddings model for semantic search\n",
    "\n",
    "### Namespaces for Memory Organization\n",
    "\n",
    "ValkeyStore uses hierarchical namespaces to organize data:\n",
    "\n",
    "- `(actor_id, session_id)`: Conversation messages (session-specific)\n",
    "- `(\"facts\", actor_id)`: Extracted facts (cross-session)\n",
    "- `(\"preferences\", actor_id)`: User preferences (cross-session)\n",
    "\n",
    "This mirrors AgentCore Memory's namespace structure for compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Configuration:\n",
      "   - Valkey URL: valkey://localhost:6379\n",
      "   - Model ID: us.amazon.nova-premier-v1:0\n",
      "   - Embedding Model: amazon.titan-embed-text-v2:0\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "VALKEY_ENDPOINT = \"localhost:6379\"  # Use localhost for local testing\n",
    "REGION = \"us-west-2\"\n",
    "MODEL_ID = \"us.amazon.nova-premier-v1:0\"\n",
    "EMBEDDING_MODEL_ID = \"amazon.titan-embed-text-v2:0\"\n",
    "\n",
    "print(\"üìã Configuration:\")\n",
    "print(f\"   - Valkey URL: valkey://{VALKEY_ENDPOINT}\")\n",
    "print(f\"   - Model ID: {MODEL_ID}\")\n",
    "print(f\"   - Embedding Model: {EMBEDDING_MODEL_ID}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîó Initialize Valkey Clients\n",
    "\n",
    "Create separate Valkey clients for checkpointing and memory storage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîó Creating Valkey clients...\n",
      "‚úÖ Valkey clients created successfully!\n",
      "   - Checkpoint client: max_connections=20\n",
      "   - Store client: max_connections=20\n"
     ]
    }
   ],
   "source": [
    "print(\"üîó Creating Valkey clients...\")\n",
    "\n",
    "# Create separate clients for checkpoint and store\n",
    "checkpoint_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "store_client = Valkey.from_url(\n",
    "    f\"valkey://{VALKEY_ENDPOINT}\",\n",
    "    decode_responses=False,\n",
    "    max_connections=20\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Valkey clients created successfully!\")\n",
    "print(f\"   - Checkpoint client: max_connections=20\")\n",
    "print(f\"   - Store client: max_connections=20\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Initialize Embeddings\n",
    "\n",
    "Initialize Bedrock embeddings for semantic search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Initializing Bedrock embeddings...\n",
      "‚úÖ Bedrock embeddings initialized successfully!\n",
      "   - Model: amazon.titan-embed-text-v2:0\n",
      "   - Dimensions: 1024 (Titan Embed Text v2)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîç Initializing Bedrock embeddings...\")\n",
    "import boto3\n",
    "from botocore.config import Config\n",
    "try:\n",
    "    # Configure boto3 for async concurrency\n",
    "    bedrock_config = Config(\n",
    "        max_pool_connections=50,\n",
    "        retries={'max_attempts': 3, 'mode': 'adaptive'}\n",
    "    )\n",
    "    \n",
    "    embeddings = BedrockEmbeddings(\n",
    "        model_id=EMBEDDING_MODEL_ID,\n",
    "        region_name=REGION\n",
    "    ,\n",
    "        client=boto3.client(\n",
    "            \"bedrock-runtime\",\n",
    "            config=bedrock_config\n",
    "        )\n",
    "    )\n",
    "    print(\"‚úÖ Bedrock embeddings initialized successfully!\")\n",
    "    print(f\"   - Model: {EMBEDDING_MODEL_ID}\")\n",
    "    print(f\"   - Dimensions: 1024 (Titan Embed Text v2)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize embeddings: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üß† Create ValkeyStore with Semantic Search\n",
    "\n",
    "Create the ValkeyStore with vector search capabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß† Creating ValkeyStore with semantic search...\n",
      "‚úÖ ValkeyStore created and configured!\n",
      "   - Index name: long_term_memory\n",
      "   - Vector dimensions: 1024\n",
      "   - Index type: HNSW (High-performance)\n",
      "   - Distance metric: COSINE\n",
      "   - TTL: None (persistent storage)\n",
      "‚úÖ AsyncValkeyStore created with same configuration as sync store\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"üß† Creating ValkeyStore with semantic search...\")\n",
    "# Define shared ValkeyIndexConfig to avoid duplication\n",
    "valkey_index_config = {\n",
    "    \"collection_name\": \"long_term_memory\",\n",
    "    \"dims\": 1024,  # Titan Embed Text v2 dimensions\n",
    "    \"embed\": embeddings,\n",
    "    \"fields\": [\"text\", \"content\"],  # Fields to embed for search\n",
    "    \"timezone\": \"UTC\",\n",
    "    \"index_type\": \"hnsw\",  # High-performance approximate search\n",
    "    \"distance_metric\": \"COSINE\"\n",
    "}\n",
    "\n",
    "valkey_ttl_config = {\"default_ttl\": None}  # No expiration for long-term memory\n",
    "\n",
    "try:\n",
    "    store = ValkeyStore(\n",
    "        client=store_client,\n",
    "        index=valkey_index_config,\n",
    "        ttl=valkey_ttl_config\n",
    "    )\n",
    "    \n",
    "    # Setup the index\n",
    "    store.setup()\n",
    "    \n",
    "    print(\"‚úÖ ValkeyStore created and configured!\")\n",
    "    print(f\"   - Index name: long_term_memory\")\n",
    "    print(f\"   - Vector dimensions: 1024\")\n",
    "    print(f\"   - Index type: HNSW (High-performance)\")\n",
    "    print(f\"   - Distance metric: COSINE\")\n",
    "    print(f\"   - TTL: None (persistent storage)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create ValkeyStore: {e}\")\n",
    "    print(\"Please ensure Valkey server with Search module is running.\")\n",
    "    raise\n",
    "# Create AsyncValkeyStore with same configuration\n",
    "async_store = AsyncValkeyStore(\n",
    "    client=store_client,\n",
    "    index=valkey_index_config,\n",
    "    ttl=valkey_ttl_config\n",
    ")\n",
    "\n",
    "print(\"‚úÖ AsyncValkeyStore created with same configuration as sync store\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Create AgentCore Valkey Checkpointer\n",
    "\n",
    "Create the checkpointer for short-term conversation state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Creating AgentCore Valkey checkpointer...\n",
      "‚úÖ AgentCore Valkey checkpointer created successfully!\n",
      "   - TTL: 86400 seconds (24 hours)\n"
     ]
    }
   ],
   "source": [
    "print(\"üîÑ Creating AgentCore Valkey checkpointer...\")\n",
    "\n",
    "try:\n",
    "    checkpointer = AgentCoreValkeySaver(\n",
    "        client=checkpoint_client,\n",
    "        ttl=86400  # 24 hour checkpoint retention\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ AgentCore Valkey checkpointer created successfully!\")\n",
    "    print(f\"   - TTL: 86400 seconds (24 hours)\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to create checkpointer: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü§ñ Initialize Language Model\n",
    "\n",
    "Initialize the Bedrock language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Initializing language model...\n",
      "‚úÖ Language model initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "print(\"ü§ñ Initializing language model...\")\n",
    "\n",
    "try:\n",
    "    model = init_chat_model(\n",
    "        MODEL_ID,\n",
    "        model_provider=\"bedrock_converse\",\n",
    "        region_name=REGION\n",
    "    )\n",
    "    print(\"‚úÖ Language model initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to initialize model: {e}\")\n",
    "    print(\"Please check your AWS credentials and region configuration.\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üé® Create Agent with Store Integration\n",
    "\n",
    "Create the agent graph with both checkpointer and store:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé® Creating agent graph...\n",
      "‚úÖ Agent graph created successfully!\n",
      "   - Checkpointer: AgentCoreValkeySaver (short-term state)\n",
      "   - Store: ValkeyStore (long-term memory)\n"
     ]
    }
   ],
   "source": [
    "print(\"üé® Creating agent graph...\")\n",
    "\n",
    "# Create agent with checkpointer and store\n",
    "graph = create_agent(\n",
    "    model,\n",
    "    tools=[],  # No tools for this example, just conversation\n",
    "    checkpointer=checkpointer,\n",
    "    store=store,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent graph created successfully!\")\n",
    "print(\"   - Checkpointer: AgentCoreValkeySaver (short-term state)\")\n",
    "print(\"   - Store: ValkeyStore (long-term memory)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üõ†Ô∏è Memory Helper Functions\n",
    "\n",
    "Define helper functions for manual memory management:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Memory helper functions defined!\n"
     ]
    }
   ],
   "source": [
    "def save_message_to_store(store, actor_id, thread_id, message, role):\n",
    "    \"\"\"Save a message to ValkeyStore with proper namespace.\"\"\"\n",
    "    namespace = (actor_id, thread_id)\n",
    "    \n",
    "    # Extract serializable content from message\n",
    "    text_content = message.content if hasattr(message, 'content') else str(message)\n",
    "    \n",
    "    store.put(\n",
    "        namespace,\n",
    "        str(uuid.uuid4()),\n",
    "        value={\n",
    "            'text': text_content,  # Required for vector embedding\n",
    "            'content': text_content,  # For retrieval\n",
    "            'role': role,\n",
    "            'actor_id': actor_id,\n",
    "            'session_id': thread_id,\n",
    "            'message_type': type(message).__name__  # Store type as string\n",
    "        },\n",
    "        index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "    )\n",
    "\n",
    "def get_relevant_context(store, actor_id, query, limit=5):\n",
    "    \"\"\"Search ValkeyStore for relevant user preferences.\"\"\"\n",
    "    preferences_namespace = ('preferences', actor_id)\n",
    "    results = store.search(preferences_namespace, query=query, limit=limit)\n",
    "    return [r.value.get('content', r.value) for r in results]\n",
    "\n",
    "def run_agent(query: str, config: RunnableConfig):\n",
    "    \"\"\"Run agent, print output, and save messages to ValkeyStore.\"\"\"\n",
    "    actor_id = config.get('configurable', {}).get('actor_id', 'default')\n",
    "    thread_id = config.get('configurable', {}).get('thread_id', 'default')\n",
    "    \n",
    "    # Before running agent: search for relevant context\n",
    "    context = get_relevant_context(store, actor_id, query)\n",
    "    if context:\n",
    "        print(f\"üìö Found {len(context)} relevant preferences from past conversations\")\n",
    "    \n",
    "    printed_ids = set()\n",
    "    user_message = None\n",
    "    ai_message = None\n",
    "    \n",
    "    events = graph.stream(\n",
    "        {'messages': [{'role': 'user', 'content': query}]},\n",
    "        config,\n",
    "        stream_mode='values',\n",
    "    )\n",
    "    \n",
    "    for event in events:\n",
    "        if 'messages' in event:\n",
    "            for msg in event['messages']:\n",
    "                if id(msg) not in printed_ids:\n",
    "                    msg.pretty_print()\n",
    "                    printed_ids.add(id(msg))\n",
    "                    \n",
    "                    # Capture messages for saving\n",
    "                    if isinstance(msg, HumanMessage):\n",
    "                        user_message = msg\n",
    "                    elif isinstance(msg, AIMessage):\n",
    "                        ai_message = msg\n",
    "    \n",
    "    # After agent runs: save messages to ValkeyStore\n",
    "    if user_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, user_message, 'user')\n",
    "        print(f\"üíæ Saved user message to ValkeyStore\")\n",
    "    \n",
    "    if ai_message:\n",
    "        save_message_to_store(store, actor_id, thread_id, ai_message, 'assistant')\n",
    "        print(f\"üíæ Saved assistant message to ValkeyStore\")\n",
    "        \n",
    "        # Extract and save preferences if detected\n",
    "        print(f\"üîç Checking for preferences in user message...\")\n",
    "        if user_message:\n",
    "            user_text = user_message.content.lower()\n",
    "            if any(kw in user_text for kw in ['favorite', 'like', 'love', 'prefer', 'enjoy']):\n",
    "                preferences_namespace = ('preferences', actor_id)\n",
    "                store.put(\n",
    "                    preferences_namespace,\n",
    "                    f'pref_{uuid.uuid4()}',\n",
    "                    value={\n",
    "                        'content': user_message.content[:500],\n",
    "                        'text': user_message.content[:500],\n",
    "                        'extracted_from': thread_id,\n",
    "                        'type': 'preference'\n",
    "                    },\n",
    "                    index=[\"text\", \"content\"]  # Explicitly enable vector indexing\n",
    "                )\n",
    "                print(f\"üîñ Extracted and saved user preference\")\n",
    "\n",
    "print(\"‚úÖ Memory helper functions defined!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéØ Configure Session\n",
    "\n",
    "Set up the session configuration with both `actor_id` and `thread_id`:\n",
    "\n",
    "### LangGraph RuntimeConfig\n",
    "\n",
    "The `config` dictionary is crucial for ValkeyStore's namespace organization:\n",
    "\n",
    "- **`actor_id`**: Identifies the user/agent (e.g., `user-123`, `agent-abc`)\n",
    "  - Used as the root namespace for long-term memories\n",
    "  - Enables multi-tenancy (isolate users)\n",
    "  - Compatible with AgentCore's actor concept\n",
    "\n",
    "- **`thread_id`**: Identifies the conversation session (e.g., `session-001`)\n",
    "  - Used for conversation-specific data\n",
    "  - Enables multiple concurrent conversations per user\n",
    "  - Maps to AgentCore's session_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Session configuration:\n",
      "   - thread_id: session-id-1\n",
      "   - actor_id: user-1\n"
     ]
    }
   ],
   "source": [
    "# Configuration for session management\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-1\",  # Session identifier\n",
    "        \"actor_id\": \"user-1\",         # User identifier\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"üìã Session configuration:\")\n",
    "for key, value in config[\"configurable\"].items():\n",
    "    print(f\"   - {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí¨ First Conversation\n",
    "\n",
    "Let's start a conversation where the user shares their cooking preferences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí¨ Starting first conversation...\n",
      "================================================================================\n",
      "FIRST CONVERSATION - Session 1\n",
      "================================================================================\n",
      "\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "\n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and veggies (healthy). It has\n",
      "great macros for my weightlifting competition that is coming up. What can I add to this dish to make it taste better\n",
      "and also improve the protein and vitamins I get?\n",
      "\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a delicious and nutritious meal already! To enhance the flavor while also boosting the protein and vitamin content, here are some ideas:\n",
      "\n",
      "1. **Add a Lean Protein**:\n",
      "   - **Grilled Chicken or Tofu**: Either of these can complement the salmon nicely and add more protein.\n",
      "\n",
      "2. **Incorporate More Veggies**:\n",
      "   - **Broccoli or Spinach**: Both are packed with vitamins and can be steamed or saut√©ed with garlic for added flavor.\n",
      "   - **Bell Peppers and Zucchini**: These add color, crunch, and additional nutrients.\n",
      "\n",
      "3. **Healthy Fats**:\n",
      "   - **Avocado Slices**: They add creaminess and healthy fats, which are essential for nutrient absorption.\n",
      "   - **Olive Oil or Sesame Oil**: Drizzle a little for added flavor and healthy fats.\n",
      "\n",
      "4. **Nuts and Seeds**:\n",
      "   - **Almonds or Chia Seeds**: Sprinkle on top for crunch and an extra protein and omega-3 boost.\n",
      "\n",
      "5. **Fresh Herbs and Citrus**:\n",
      "   - **Dill or Cilantro**: Fresh herbs can elevate the dish‚Äôs flavor.\n",
      "   - **Lemon or Lime Juice**: A squeeze of citrus can brighten the flavors and add vitamin C.\n",
      "\n",
      "6. **Whole Grains**:\n",
      "   - **Quinoa**: Swap out some of the rice for quinoa to increase the protein content and add a different texture.\n",
      "\n",
      "7. **Fermented Foods**:\n",
      "   - **Kimchi or Sauerkraut**: These add a tangy flavor and provide probiotics for gut health.\n",
      "\n",
      "8. **Spices and Seasonings**:\n",
      "   - **Turmeric or Cumin**: These spices not only add flavor but also have anti-inflammatory properties.\n",
      "   - **Soy Sauce or Tamari**: For a salty umami flavor that can enhance the dish.\n",
      "\n",
      "By incorporating some of these suggestions, you can make your meal even tastier and nutritionally balanced for your competition prep. Enjoy your cooking!\n",
      "üíæ Saved user message to ValkeyStore\n",
      "üíæ Saved assistant message to ValkeyStore\n",
      "üîç Checking for preferences in user message...\n",
      "üîñ Extracted and saved user preference\n"
     ]
    }
   ],
   "source": [
    "print(\"üí¨ Starting first conversation...\")\n",
    "print(\"=\"*80)\n",
    "print(\"FIRST CONVERSATION - Session 1\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "prompt = \"\"\"\n",
    "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and veggies (healthy). It has\n",
    "great macros for my weightlifting competition that is coming up. What can I add to this dish to make it taste better\n",
    "and also improve the protein and vitamins I get?\n",
    "\"\"\"\n",
    "\n",
    "run_agent(prompt, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Verify Storage\n",
    "\n",
    "Let's verify what was stored in ValkeyStore:\n",
    "\n",
    "### What Was Stored?\n",
    "\n",
    "1. **User message** ‚Üí `(\"user-1\", \"session-id-1\")` namespace\n",
    "2. **Assistant message** ‚Üí `(\"user-1\", \"session-id-1\")` namespace\n",
    "3. **User preferences** ‚Üí `(\"preferences\", \"user-1\")` namespace (extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Storage Information:\n",
      "================================================================================\n",
      "\n",
      "üìù Session messages: 2 keys\n",
      "   Sample: langgraph:user-1/session-id-1/bd1cb7d2-d472-4fa0-9009-12427505a2b1\n",
      "\n",
      "‚≠ê User preferences: 1 keys\n",
      "   Sample: langgraph:preferences/user-1/pref_57c5fa67-d589-4bd1-95b2-1b54114ad38f\n"
     ]
    }
   ],
   "source": [
    "print(\"üìä Storage Information:\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Check message keys\n",
    "message_keys = store_client.keys('*user-1*/session-id-1*')\n",
    "print(f\"\\nüìù Session messages: {len(message_keys)} keys\")\n",
    "if message_keys:\n",
    "    print(f\"   Sample: {message_keys[0].decode()}\")\n",
    "\n",
    "# Check preference keys\n",
    "preference_keys = store_client.keys('*preferences/user-1*')\n",
    "print(f\"\\n‚≠ê User preferences: {len(preference_keys)} keys\")\n",
    "if preference_keys:\n",
    "    print(f\"   Sample: {preference_keys[0].decode()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Second Conversation (New Session)\n",
    "\n",
    "Start a new session to demonstrate cross-session memory retrieval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECOND CONVERSATION - Session 2 (Same User)\n",
      "================================================================================\n",
      "üîç This will demonstrate cross-session memory retrieval\n",
      "\n",
      "üìö Found 1 relevant preferences from past conversations\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What are some good dinner ideas for tonight?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Here are a few dinner ideas that you might enjoy:\n",
      "\n",
      "1. **Grilled Chicken and Vegetable Skewers**: Marinate chicken pieces in olive oil, lemon juice, garlic, and herbs. Thread onto skewers with bell peppers, onions, and zucchini. Grill until cooked through.\n",
      "\n",
      "2. **Spaghetti Aglio e Olio**: Saut√© minced garlic in olive oil with red pepper flakes. Toss with cooked spaghetti, parsley, and grated Parmesan cheese.\n",
      "\n",
      "3. **Vegetable Stir-Fry**: Stir-fry a mix of your favorite vegetables (like broccoli, carrots, and snap peas) in a bit of oil. Add soy sauce, ginger, and garlic for flavor, and serve over rice or noodles.\n",
      "\n",
      "4. **Baked Salmon with Asparagus**: Place salmon fillets on a baking sheet with asparagus spears. Drizzle with olive oil, season with salt, pepper, and dill, then bake until the salmon is flaky.\n",
      "\n",
      "5. **Tacos**: Prepare taco meat (beef, chicken, or even plant-based) with taco seasoning. Serve with warm tortillas, lettuce, cheese, tomatoes, and avocado.\n",
      "\n",
      "6. **Stuffed Bell Peppers**: Mix cooked quinoa or rice with ground meat or beans, diced tomatoes, and spices. Stuff into halved bell peppers and bake until tender.\n",
      "\n",
      "7. **Chicken Curry**: Saut√© onions, garlic, and ginger, then add diced chicken and curry paste. Simmer with coconut milk and serve with rice or naan bread.\n",
      "\n",
      "Choose one that suits your taste and the ingredients you have on hand! Enjoy your dinner.\n",
      "üíæ Saved user message to ValkeyStore\n",
      "üíæ Saved assistant message to ValkeyStore\n",
      "üîç Checking for preferences in user message...\n"
     ]
    }
   ],
   "source": [
    "# New session configuration\n",
    "config2 = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"session-id-2\",  # New session\n",
    "        \"actor_id\": \"user-1\",         # Same user\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SECOND CONVERSATION - Session 2 (Same User)\")\n",
    "print(\"=\"*80)\n",
    "print(\"üîç This will demonstrate cross-session memory retrieval\\n\")\n",
    "\n",
    "prompt2 = \"What are some good dinner ideas for tonight?\"\n",
    "\n",
    "run_agent(prompt2, config2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç Semantic Search Examples\n",
    "\n",
    "Demonstrate semantic search capabilities by querying related concepts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SEMANTIC SEARCH EXAMPLES\n",
      "================================================================================\n",
      "\n",
      "üîç Query: 'protein-rich foods'\n",
      "   Expected: Should find salmon/weightlifting context\n",
      "   ‚úÖ Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n",
      "üîç Query: 'athletic nutrition'\n",
      "   Expected: Should find healthy eating preferences\n",
      "   ‚úÖ Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n",
      "üîç Query: 'dinner ideas'\n",
      "   Expected: Should find cooking-related memories\n",
      "   ‚úÖ Found 1 results:\n",
      "      1. \n",
      "Hey there! I'm cooking one of my favorite meals tonight: salmon with rice and v...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEMANTIC SEARCH EXAMPLES\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Search by related concept (not exact keyword)\n",
    "test_queries = [\n",
    "    (\"protein-rich foods\", \"Should find salmon/weightlifting context\"),\n",
    "    (\"athletic nutrition\", \"Should find healthy eating preferences\"),\n",
    "    (\"dinner ideas\", \"Should find cooking-related memories\")\n",
    "]\n",
    "\n",
    "for query, description in test_queries:\n",
    "    print(f\"üîç Query: '{query}'\")\n",
    "    print(f\"   Expected: {description}\")\n",
    "    \n",
    "    results = store.search((\"preferences\", \"user-1\"), query=query, limit=3)\n",
    "    print(f\"   ‚úÖ Found {len(results)} results:\")\n",
    "    for i, result in enumerate(results, 1):\n",
    "        content = result.value.get(\"content\", \"\")[:80]\n",
    "        print(f\"      {i}. {content}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîÑ Async Semantic Search\n",
    "\n",
    "Demonstrate async search capabilities and verify parity with sync results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "ASYNC SEMANTIC SEARCH DEMONSTRATION\n",
      "================================================================================\n",
      "\n",
      "üîç Test Query: 'protein-rich foods'\n",
      "\n",
      "üîµ Sync Search Results: 1 found\n",
      "   1. Score: 0.7445 - \n",
      "Hey there! I'm cooking one of my favorite meals tonight: sa...\n",
      "\n",
      "üü¢ Async Search Results: 1 found\n",
      "   1. Score: 0.7445 - \n",
      "Hey there! I'm cooking one of my favorite meals tonight: sa...\n",
      "\n",
      "================================================================================\n",
      "SYNC/ASYNC PARITY VERIFICATION\n",
      "================================================================================\n",
      "‚úÖ Result count matches: 1 results from both\n",
      "   Result 1: ‚úÖ Scores match (0.7445)\n",
      "             ‚úÖ Keys match: pref_57c5fa67-d589-4bd1-95b2-1b54114ad38f\n",
      "\n",
      "üéâ Async search demonstration complete!\n",
      "   Both sync and async search return identical results with same scores.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ASYNC SEMANTIC SEARCH DEMONSTRATION\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "# Test async search and compare with sync\n",
    "test_query = \"protein-rich foods\"\n",
    "print(f\"üîç Test Query: '{test_query}'\\n\")\n",
    "\n",
    "# Sync search\n",
    "sync_results = store.search((\"preferences\", \"user-1\"), query=test_query, limit=3)\n",
    "print(f\"üîµ Sync Search Results: {len(sync_results)} found\")\n",
    "for i, result in enumerate(sync_results, 1):\n",
    "    content = result.value.get(\"content\", \"\")[:60]\n",
    "    print(f\"   {i}. Score: {result.score:.4f} - {content}...\")\n",
    "\n",
    "# Async search\n",
    "async_results = await async_store.asearch((\"preferences\", \"user-1\"), query=test_query, limit=3)\n",
    "print(f\"\\nüü¢ Async Search Results: {len(async_results)} found\")\n",
    "for i, result in enumerate(async_results, 1):\n",
    "    content = result.value.get(\"content\", \"\")[:60]\n",
    "    print(f\"   {i}. Score: {result.score:.4f} - {content}...\")\n",
    "\n",
    "# Verify parity\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYNC/ASYNC PARITY VERIFICATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if len(sync_results) == len(async_results):\n",
    "    print(f\"‚úÖ Result count matches: {len(sync_results)} results from both\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  Result count differs: sync={len(sync_results)}, async={len(async_results)}\")\n",
    "\n",
    "# Compare scores and content\n",
    "for i, (sync_res, async_res) in enumerate(zip(sync_results, async_results), 1):\n",
    "    score_diff = abs(sync_res.score - async_res.score)\n",
    "    if score_diff < 0.0001:\n",
    "        print(f\"   Result {i}: ‚úÖ Scores match ({sync_res.score:.4f})\")\n",
    "    else:\n",
    "        print(f\"   Result {i}: ‚ö†Ô∏è  Score diff: {score_diff:.6f}\")\n",
    "    \n",
    "    if sync_res.key == async_res.key:\n",
    "        print(f\"             ‚úÖ Keys match: {sync_res.key}\")\n",
    "    else:\n",
    "        print(f\"             ‚ö†Ô∏è  Keys differ: {sync_res.key} vs {async_res.key}\")\n",
    "\n",
    "print(\"\\nüéâ Async search demonstration complete!\")\n",
    "print(\"   Both sync and async search return identical results with same scores.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßπ Cleanup (Optional)\n",
    "\n",
    "Demonstrate cleanup functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üßπ Cleanup Options\n",
      "================================================================================\n",
      "\n",
      "‚ö†Ô∏è  The following code is commented out to prevent accidental data deletion.\n",
      "Uncomment to clean up demo data:\n",
      "\n",
      "To clean up, uncomment the code above and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "print(\"üßπ Cleanup Options\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n‚ö†Ô∏è  The following code is commented out to prevent accidental data deletion.\")\n",
    "print(\"Uncomment to clean up demo data:\\n\")\n",
    "\n",
    "# WARNING: This deletes all data for user-1\n",
    "# Uncomment to run:\n",
    "\n",
    "# print(\"Deleting preferences...\")\n",
    "# preferences = store.search((\"preferences\", \"user-1\"), query=\"*\", limit=100)\n",
    "# for pref in preferences:\n",
    "#     store.delete((\"preferences\", \"user-1\"), pref.key)\n",
    "# print(f\"‚úÖ Deleted {len(preferences)} preferences\")\n",
    "\n",
    "# print(\"\\nDeleting session 1 messages...\")\n",
    "# session1 = store.search((\"user-1\", \"session-id-1\"), query=\"*\", limit=100)\n",
    "# for msg in session1:\n",
    "#     store.delete((\"user-1\", \"session-id-1\"), msg.key)\n",
    "# print(f\"‚úÖ Deleted {len(session1)} session 1 messages\")\n",
    "\n",
    "# print(\"\\nDeleting session 2 messages...\")\n",
    "# session2 = store.search((\"user-1\", \"session-id-2\"), query=\"*\", limit=100)\n",
    "# for msg in session2:\n",
    "#     store.delete((\"user-1\", \"session-id-2\"), msg.key)\n",
    "# print(f\"‚úÖ Deleted {len(session2)} session 2 messages\")\n",
    "\n",
    "# print(\"\\n‚úÖ All data deleted for user-1\")\n",
    "\n",
    "print(\"To clean up, uncomment the code above and re-run this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Summary\n",
    "\n",
    "Congratulations! You've successfully demonstrated the **ValkeyStore/AsyncValkeyStore** with semantic search capabilities combined with **AgentCoreValkeySaver** for checkpoint persistence.\n",
    "\n",
    "### Key Benefits Demonstrated:\n",
    "\n",
    "- üß† **Long-term memory storage** with ValkeyStore\n",
    "- üîç **Semantic search** using vector embeddings\n",
    "- üóÇÔ∏è **Namespace organization** for data isolation\n",
    "- üöÄ **AgentCore-compatible** session management\n",
    "- üìä **Cross-session memory** retrieval\n",
    "- üéØ **Preference extraction** and storage\n",
    "- üîÑ **TTL support** for data lifecycle management\n",
    "- üèä **Connection pooling** for scalability\n",
    "\n",
    "### What We Covered:\n",
    "\n",
    "1. **Basic Setup**: Created ValkeyStore with vector search index\n",
    "2. **Agent Integration**: Used with LangGraph agents and checkpointer\n",
    "3. **Session Management**: AgentCore-compatible actor_id and thread_id patterns\n",
    "4. **Memory Storage**: Manual message and preference storage\n",
    "5. **Cross-Session Retrieval**: Demonstrated long-term memory access\n",
    "6. **Semantic Search**: Vector-based similarity search\n",
    "8. **Cleanup**: Proper resource management\n",
    "\n",
    "### üéØ Namespace Organization Best Practices:\n",
    "\n",
    "| Namespace | Purpose | Scope | TTL |\n",
    "|-----------|---------|-------|-----|\n",
    "| `(actor_id, session_id)` | Conversation messages | Session | 24h |\n",
    "| `(\"preferences\", actor_id)` | User preferences | Cross-session | None |\n",
    "| `(\"facts\", actor_id)` | Extracted facts | Cross-session | None |\n",
    "| `(\"knowledge\", \"global\")` | Shared knowledge | Global | None |\n",
    "\n",
    "### üîó Architecture:\n",
    "\n",
    "```\n",
    "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "‚îÇ           LangGraph Agent                   ‚îÇ\n",
    "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
    "‚îÇ                                             ‚îÇ\n",
    "‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ\n",
    "‚îÇ  ‚îÇ AgentCoreValkey  ‚îÇ  ‚îÇ ValkeyStore/    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ     Saver        ‚îÇ  ‚îÇ AsyncValkeyStore‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îÇ  (Short-term)    ‚îÇ  ‚îÇ  (Long-term)    ‚îÇ  ‚îÇ\n",
    "‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ\n",
    "‚îÇ           ‚îÇ                     ‚îÇ           ‚îÇ\n",
    "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "            ‚îÇ                     ‚îÇ\n",
    "            ‚ñº                     ‚ñº\n",
    "      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
    "      ‚îÇ   Valkey / ElastiCache       ‚îÇ\n",
    "      ‚îÇ  (with Search module)        ‚îÇ\n",
    "      ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
    "```\n",
    "\n",
    "The **ValkeyStore/AsyncValkeyStore** provides a powerful, scalable solution for long-term memory storage with semantic search that works seamlessly with AgentCore session management patterns! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
