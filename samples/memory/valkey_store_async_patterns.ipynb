{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u26a1 AsyncValkeyStore: Enterprise Async Patterns\n",
    "\n",
    "This notebook demonstrates **when and why** to use `AsyncValkeyStore` for production workloads.\n",
    "\n",
    "## \ud83c\udfaf What You'll Learn\n",
    "\n",
    "1. **\ud83d\ude80 Concurrent Search**: Handle multiple users simultaneously\n",
    "2. **\ud83d\udce6 Batch Processing**: Process hundreds of items efficiently\n",
    "3. **\ud83c\udf10 FastAPI Integration**: Real async web service patterns\n",
    "4. **\ud83d\udcca Performance Gains**: Measure actual speedup vs sync\n",
    "5. **\ud83c\udfd7\ufe0f Production Patterns**: Connection pooling, rate limiting, error handling\n",
    "\n",
    "## \ud83d\udcda Prerequisites\n",
    "\n",
    "This notebook builds on concepts from:\n",
    "- [`valkey_store.ipynb`](./valkey_store.ipynb) - Core ValkeyStore patterns (start here!)\n",
    "- [`agentcore_valkey_store.ipynb`](./agentcore_valkey_store.ipynb) - Basic sync/async parity\n",
    "\n",
    "## \u2696\ufe0f When to Use Async\n",
    "\n",
    "| Scenario | Use Async | Use Sync |\n",
    "|----------|-----------|----------|\n",
    "| Single user CLI/script | \u274c | \u2705 |\n",
    "| Web API (FastAPI, aiohttp) | \u2705 | \u274c |\n",
    "| Batch processing 100+ items | \u2705 | \u274c |\n",
    "| Concurrent multi-user access | \u2705 | \u274c |\n",
    "| Simple notebook exploration | \u274c | \u2705 |\n",
    "| High-throughput production | \u2705 | \u26a0\ufe0f |\n",
    "\n",
    "## \ud83d\udd27 Environment Setup\n",
    "\n",
    "**AWS Credentials**: Configure with `aws configure` or environment variables  \n",
    "**Valkey Server**: Local (`localhost:6379`) or AWS MemoryDB connection string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "# !pip install langgraph-checkpoint-aws langchain-aws boto3 valkey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Imports and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/workplace/github/langchain-aws/.venv/lib/python3.14/site-packages/langchain_core/_api/deprecation.py:26: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.\n",
      "  from pydantic.v1.fields import FieldInfo as FieldInfoV1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Imports complete\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import time\n",
    "from typing import List, Dict, Any, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from datetime import datetime\n",
    "import logging\n",
    "\n",
    "# LangChain and AWS imports\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "\n",
    "# ValkeyStore imports\n",
    "import valkey\n",
    "from langgraph_checkpoint_aws.store.valkey import AsyncValkeyStore, ValkeyIndexConfig\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Configuration\n",
    "VALKEY_CONN_STRING = \"valkey://localhost:6379\"  # Update for your environment\n",
    "VECTOR_DIMENSION = 1024  # Titan Text Embeddings v2: 1024, v1: 1536\n",
    "NAMESPACE = (\"async_demo\",)\n",
    "AWS_REGION = \"us-east-1\"\n",
    "\n",
    "# Embedding mode: 'mock' (default, no AWS credentials needed) or 'bedrock' (production)\n",
    "EMBEDDING_MODE = \"mock\"  # Change to \"bedrock\" for production with real embeddings\n",
    "\n",
    "print(\"\u2705 Imports complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Embeddings Setup\n",
    "\n",
    "This notebook supports two modes:\n",
    "\n",
    "### 1. Mock Embeddings (Default) - No AWS Credentials Required \u2705\n",
    "- **Instant setup**: Works locally without any configuration\n",
    "- **Realistic timing**: Simulates actual Bedrock API latency (80-120ms)\n",
    "- **Perfect for**: Development, testing, learning async patterns\n",
    "- **Limitations**: Not semantically meaningful, uses hash-based vectors\n",
    "\n",
    "### 2. Bedrock Embeddings (Production) - Real Semantic Search\n",
    "- **Production-ready**: Uses AWS Bedrock Titan embeddings\n",
    "- **Semantic search**: Real similarity scores based on meaning\n",
    "- **Requires**: AWS credentials configured (via AWS CLI or environment variables)\n",
    "\n",
    "**Current Mode: `EMBEDDING_MODE = \"mock\"`**\n",
    "\n",
    "### \ud83d\udd04 How to Switch to Bedrock\n",
    "\n",
    "1. **Configure AWS credentials** (one-time setup):\n",
    "   ```bash\n",
    "   aws configure\n",
    "   # OR set environment variables:\n",
    "   # export AWS_ACCESS_KEY_ID=your_key\n",
    "   # export AWS_SECRET_ACCESS_KEY=your_secret\n",
    "   # export AWS_DEFAULT_REGION=us-east-1\n",
    "   ```\n",
    "\n",
    "2. **Change mode in Cell 3**:\n",
    "   ```python\n",
    "   EMBEDDING_MODE = \"bedrock\"  # Change from \"mock\" to \"bedrock\"\n",
    "   ```\n",
    "\n",
    "3. **Re-run all cells** - that's it! \ud83c\udf89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Using MockEmbeddings (Development)\n",
      "   Simulated latency: 80-120ms (matches Bedrock)\n",
      "   Vector dimension: 1024\n",
      "   \ud83d\udca1 To use real Bedrock: Set EMBEDDING_MODE = 'bedrock' in Cell 3\n"
     ]
    }
   ],
   "source": [
    "class MockEmbeddings(Embeddings):\n",
    "    \"\"\"Mock embeddings with realistic Bedrock API timing.\n",
    "    \n",
    "    Simulates Bedrock Titan embed-text-v2 behavior:\n",
    "    - Latency: 80-120ms per request (matches real Bedrock)\n",
    "    - Vector dimension: 1024 (configurable)\n",
    "    - Deterministic: Same text always produces same vector\n",
    "    \"\"\"\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Generate mock embeddings based on text characteristics.\"\"\"\n",
    "        return [self._generate_embedding(text) for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Generate mock embedding for query.\"\"\"\n",
    "        return self._generate_embedding(text)\n",
    "    \n",
    "    async def aembed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Async version - simulates Bedrock API latency (80-120ms).\"\"\"\n",
    "        import random\n",
    "        # Simulate realistic Bedrock latency: 80-120ms\n",
    "        latency = random.uniform(0.08, 0.12)\n",
    "        await asyncio.sleep(latency)\n",
    "        return self.embed_documents(texts)\n",
    "    \n",
    "    async def aembed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Async query embedding with simulated latency.\"\"\"\n",
    "        import random\n",
    "        latency = random.uniform(0.08, 0.12)\n",
    "        await asyncio.sleep(latency)\n",
    "        return self.embed_query(text)\n",
    "    \n",
    "    def _generate_embedding(self, text: str) -> List[float]:\n",
    "        \"\"\"Create a deterministic vector based on text hash.\"\"\"\n",
    "        import hashlib\n",
    "        import struct\n",
    "        \n",
    "        # Use text hash for reproducible but varied embeddings\n",
    "        hash_obj = hashlib.sha256(text.encode())\n",
    "        hash_bytes = hash_obj.digest()\n",
    "        \n",
    "        # Generate VECTOR_DIMENSION floats from hash\n",
    "        vector = []\n",
    "        for i in range(0, VECTOR_DIMENSION * 4, 4):\n",
    "            byte_chunk = hash_bytes[(i % len(hash_bytes)):(i % len(hash_bytes)) + 4]\n",
    "            if len(byte_chunk) < 4:\n",
    "                byte_chunk = byte_chunk + b'\\x00' * (4 - len(byte_chunk))\n",
    "            value = struct.unpack('f', byte_chunk)[0]\n",
    "            # Normalize to [-1, 1] range\n",
    "            normalized = max(-1.0, min(1.0, value / 1e38))\n",
    "            vector.append(normalized)\n",
    "        \n",
    "        # Normalize to unit vector for cosine similarity\n",
    "        magnitude = sum(x * x for x in vector) ** 0.5\n",
    "        if magnitude > 0:\n",
    "            vector = [x / magnitude for x in vector]\n",
    "        \n",
    "        return vector\n",
    "\n",
    "\n",
    "# Initialize embeddings based on mode\n",
    "if EMBEDDING_MODE == \"bedrock\":\n",
    "    # Production mode: Real Bedrock embeddings\n",
    "    try:\n",
    "        import boto3\n",
    "        from botocore.config import Config\n",
    "        \n",
    "        # Configure boto3 for async concurrency\n",
    "        # Create dedicated boto3 session for isolated connection pool\n",
    "        boto_session = boto3.Session()\n",
    "\n",
    "        bedrock_config = Config(\n",
    "            max_pool_connections=50,  # Up from default 10 for concurrent operations\n",
    "            retries={'max_attempts': 3, 'mode': 'adaptive'}\n",
    "        )\n",
    "        \n",
    "        embeddings = BedrockEmbeddings(\n",
    "            model_id=\"amazon.titan-embed-text-v2:0\",\n",
    "            region_name=AWS_REGION,\n",
    "            client=boto_session.client(\n",
    "                \"bedrock-runtime\",\n",
    "                region_name=AWS_REGION,\n",
    "                config=bedrock_config\n",
    "            )\n",
    "        )\n",
    "        print(\"\u2705 Using BedrockEmbeddings (Production)\")\n",
    "        print(f\"   Model: amazon.titan-embed-text-v2:0\")\n",
    "        print(f\"   Region: {AWS_REGION}\")\n",
    "        print(f\"   Connection pool: 50\")\n",
    "    except Exception as e:\n",
    "        print(f\"\u274c Bedrock initialization failed: {e}\")\n",
    "        print(\"\ud83d\udca1 Falling back to MockEmbeddings\")\n",
    "        print(\"   Tip: Check AWS credentials with 'aws sts get-caller-identity'\")\n",
    "        embeddings = MockEmbeddings()\n",
    "        EMBEDDING_MODE = \"mock\"\n",
    "else:\n",
    "    # Development mode: Mock embeddings (default)\n",
    "    embeddings = MockEmbeddings()\n",
    "    print(\"\u2705 Using MockEmbeddings (Development)\")\n",
    "    print(\"   Simulated latency: 80-120ms (matches Bedrock)\")\n",
    "    print(f\"   Vector dimension: {VECTOR_DIMENSION}\")\n",
    "    print(\"   \ud83d\udca1 To use real Bedrock: Set EMBEDDING_MODE = 'bedrock' in Cell 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f AsyncValkeyStore Setup\n",
    "\n",
    "Create store with vector search configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 22:32:57,045 - __main__ - INFO - \u2705 Valkey connection established\n",
      "2025-12-04 22:32:57,050 - langgraph_checkpoint_aws.store.valkey.async_store - INFO - Created search index enterprise_memory_vectors with TAG fields\n",
      "2025-12-04 22:32:57,051 - __main__ - INFO - \u2705 AsyncValkeyStore configured with vector search: enterprise_memory_vectors\n",
      "2025-12-04 22:32:57,051 - __main__ - INFO -    Connection: valkey://localhost:6379\n",
      "2025-12-04 22:32:57,051 - __main__ - INFO - \ud83d\udcd0 Dimension: 1024, Algorithm: HNSW\n"
     ]
    }
   ],
   "source": [
    "valkey_client = None\n",
    "async_store = None\n",
    "    \n",
    "try:\n",
    "    # Initialize Valkey client with enterprise configuration\n",
    "    valkey_client = valkey.from_url(\n",
    "        VALKEY_CONN_STRING,\n",
    "        # Enterprise connection settings\n",
    "        socket_connect_timeout=10,\n",
    "        socket_timeout=10,\n",
    "        retry_on_timeout=True,\n",
    "        health_check_interval=30\n",
    "    )\n",
    "    \n",
    "    # Test connection\n",
    "    valkey_client.ping()\n",
    "    logger.info(\"\u2705 Valkey connection established\")\n",
    "    # Create index configuration for vector search\n",
    "    index_config : ValkeyIndexConfig = {\n",
    "        \"collection_name\": \"enterprise_memory_vectors\",\n",
    "        \"dims\": VECTOR_DIMENSION,  # Match embedding dimensions\n",
    "        \"embed\":embeddings,\n",
    "        \"distance_metric\": \"COSINE\",\n",
    "        \"index_type\": \"HNSW\",\n",
    "        # Searchable fields for hybrid queries\n",
    "        \"fields\": [\"user_id\", \"category\", \"priority\"],\n",
    "    }\n",
    "\n",
    "    # Initialize AsyncValkeyStore\n",
    "    async_store = AsyncValkeyStore(\n",
    "        valkey_client,\n",
    "        index=index_config,\n",
    "    )\n",
    "    await async_store.setup()\n",
    "    logger.info(f\"\u2705 AsyncValkeyStore configured with vector search: {index_config[\"collection_name\"]}\")\n",
    "    logger.info(f\"   Connection: {VALKEY_CONN_STRING}\")\n",
    "    logger.info(f\"\ud83d\udcd0 Dimension: {index_config[\"dims\"]}, Algorithm: {index_config[\"index_type\"]}\")\n",
    "except Exception as e:\n",
    "    logger.error(f\"\u274c Valkey Client initialization failed: {e}\")\n",
    "    logger.info(\"\ud83d\udca1 Ensure Valkey is running: docker run -p 6379:6379 -d valkey/valkey\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Data Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Data models defined\n"
     ]
    }
   ],
   "source": [
    "@dataclass\n",
    "class UserQuery:\n",
    "    \"\"\"Represents a user search query.\"\"\"\n",
    "    user_id: str\n",
    "    query_text: str\n",
    "    filters: Dict[str, Any] = field(default_factory=dict)\n",
    "    timestamp: datetime = field(default_factory=datetime.now)\n",
    "\n",
    "@dataclass\n",
    "class SearchResult:\n",
    "    \"\"\"Enhanced search result with timing info.\"\"\"\n",
    "    user_id: str\n",
    "    query: str\n",
    "    results_count: int\n",
    "    duration_ms: float\n",
    "    top_result: Optional[Dict[str, Any]] = None\n",
    "    \n",
    "    def __str__(self):\n",
    "        return f\"User {self.user_id}: {self.results_count} results in {self.duration_ms:.1f}ms\"\n",
    "\n",
    "print(\"\u2705 Data models defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udd04 Pattern 1: Concurrent Multi-User Search\n",
    "\n",
    "**Use Case**: Web application serving multiple users simultaneously.\n",
    "\n",
    "**Why Async Wins**: Handles 10+ concurrent users without blocking, maximizing I/O parallelism."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 22:32:57,171 - __main__ - INFO - \u2705 Stored 5 demo items\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83c\udfaa Demo data ready!\n"
     ]
    }
   ],
   "source": [
    "async def setup_demo_data():\n",
    "    \"\"\"Populate store with sample user preferences.\"\"\"\n",
    "    demo_data = [\n",
    "        # User 1 - Tech enthusiast\n",
    "        {\n",
    "            \"namespace\": (\"preferences\", \"user-1\"),\n",
    "            \"key\": \"pref-tech\",\n",
    "            \"value\": {\n",
    "                \"content\": \"I love machine learning, AI, and cloud computing. Especially interested in AWS services and vector databases.\",\n",
    "                \"user_id\": \"user-1\",\n",
    "                \"category\": \"technology\",\n",
    "                \"priority\": \"high\"\n",
    "            }\n",
    "        },\n",
    "        # User 2 - Fitness focused\n",
    "        {\n",
    "            \"namespace\": (\"preferences\", \"user-2\"),\n",
    "            \"key\": \"pref-fitness\",\n",
    "            \"value\": {\n",
    "                \"content\": \"Passionate about running, yoga, and healthy eating. Training for a marathon and exploring plant-based nutrition.\",\n",
    "                \"user_id\": \"user-2\",\n",
    "                \"category\": \"health\",\n",
    "                \"priority\": \"high\"\n",
    "            }\n",
    "        },\n",
    "        # User 3 - Travel lover\n",
    "        {\n",
    "            \"namespace\": (\"preferences\", \"user-3\"),\n",
    "            \"key\": \"pref-travel\",\n",
    "            \"value\": {\n",
    "                \"content\": \"Love exploring new countries, trying local cuisines, and photography. Favorite destinations include Japan and Iceland.\",\n",
    "                \"user_id\": \"user-3\",\n",
    "                \"category\": \"lifestyle\",\n",
    "                \"priority\": \"medium\"\n",
    "            }\n",
    "        },\n",
    "        # User 4 - Finance professional\n",
    "        {\n",
    "            \"namespace\": (\"preferences\", \"user-4\"),\n",
    "            \"key\": \"pref-finance\",\n",
    "            \"value\": {\n",
    "                \"content\": \"Interested in stock markets, cryptocurrency, and investment strategies. Following market trends and economic indicators.\",\n",
    "                \"user_id\": \"user-4\",\n",
    "                \"category\": \"finance\",\n",
    "                \"priority\": \"high\"\n",
    "            }\n",
    "        },\n",
    "        # User 5 - Book reader\n",
    "        {\n",
    "            \"namespace\": (\"preferences\", \"user-5\"),\n",
    "            \"key\": \"pref-reading\",\n",
    "            \"value\": {\n",
    "                \"content\": \"Avid reader of science fiction, fantasy novels, and historical biographies. Current favorite authors include Brandon Sanderson.\",\n",
    "                \"user_id\": \"user-5\",\n",
    "                \"category\": \"entertainment\",\n",
    "                \"priority\": \"medium\"\n",
    "            }\n",
    "        },\n",
    "    ]\n",
    "    \n",
    "    # Store all items concurrently\n",
    "    tasks = [\n",
    "        async_store.aput(\n",
    "            namespace=item[\"namespace\"],\n",
    "            key=item[\"key\"],\n",
    "            value=item[\"value\"]\n",
    "        )\n",
    "        for item in demo_data\n",
    "    ]\n",
    "    await asyncio.gather(*tasks)\n",
    "    logger.info(f\"\u2705 Stored {len(demo_data)} demo items\")\n",
    "\n",
    "# Run setup\n",
    "await setup_demo_data()\n",
    "print(\"\\n\ud83c\udfaa Demo data ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\ude80 Launching 10 concurrent searches...\n",
      "\n",
      "\ud83d\udcca Results:\n",
      "  User user-1: 1 results in 101.2ms\n",
      "    \u21b3 Top: I love machine learning, AI, and cloud computing. Especially interested in AWS s... (score: 0.600)\n",
      "  User user-2: 1 results in 120.8ms\n",
      "    \u21b3 Top: Passionate about running, yoga, and healthy eating. Training for a marathon and ... (score: 0.600)\n",
      "  User user-3: 1 results in 102.2ms\n",
      "    \u21b3 Top: Love exploring new countries, trying local cuisines, and photography. Favorite d... (score: 0.100)\n",
      "  User user-4: 1 results in 113.6ms\n",
      "    \u21b3 Top: Interested in stock markets, cryptocurrency, and investment strategies. Followin... (score: 0.600)\n",
      "  User user-5: 1 results in 110.6ms\n",
      "    \u21b3 Top: Avid reader of science fiction, fantasy novels, and historical biographies. Curr... (score: 0.600)\n",
      "  User user-1: 1 results in 115.7ms\n",
      "    \u21b3 Top: I love machine learning, AI, and cloud computing. Especially interested in AWS s... (score: 0.600)\n",
      "  User user-2: 1 results in 96.5ms\n",
      "    \u21b3 Top: Passionate about running, yoga, and healthy eating. Training for a marathon and ... (score: 0.600)\n",
      "  User user-3: 1 results in 112.4ms\n",
      "    \u21b3 Top: Love exploring new countries, trying local cuisines, and photography. Favorite d... (score: 0.600)\n",
      "  User user-4: 1 results in 96.8ms\n",
      "    \u21b3 Top: Interested in stock markets, cryptocurrency, and investment strategies. Followin... (score: 0.600)\n",
      "  User user-5: 1 results in 120.8ms\n",
      "    \u21b3 Top: Avid reader of science fiction, fantasy novels, and historical biographies. Curr... (score: 0.600)\n",
      "\n",
      "\u23f1\ufe0f  Total wall time: 121.2ms\n",
      "\ud83d\udcc8 Average per search: 12.1ms\n",
      "\ud83c\udfaf Throughput: 82.5 searches/sec\n",
      "\n",
      "\u26a1 Async speedup: 9.0x faster than sequential\n"
     ]
    }
   ],
   "source": [
    "async def search_for_user(query: UserQuery) -> SearchResult:\n",
    "    \"\"\"Execute search for a single user with timing.\"\"\"\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Perform vector search\n",
    "    results = await async_store.asearch(\n",
    "        namespace_prefix=(\"preferences\", query.user_id),\n",
    "        query=query.query_text,\n",
    "        limit=5,\n",
    "        filter=query.filters or None\n",
    "    )\n",
    "    \n",
    "    duration = (time.perf_counter() - start) * 1000  # Convert to ms\n",
    "    \n",
    "    top_result = None\n",
    "    if results:\n",
    "        top = results[0]\n",
    "        top_result = {\n",
    "            \"key\": top.key,\n",
    "            \"score\": top.score,\n",
    "            \"content\": top.value.get(\"content\", \"\")[:80] + \"...\"\n",
    "        }\n",
    "    \n",
    "    return SearchResult(\n",
    "        user_id=query.user_id,\n",
    "        query=query.query_text,\n",
    "        results_count=len(results),\n",
    "        duration_ms=duration,\n",
    "        top_result=top_result\n",
    "    )\n",
    "\n",
    "async def concurrent_search_demo():\n",
    "    \"\"\"Simulate 10 users searching simultaneously.\"\"\"\n",
    "    queries = [\n",
    "        UserQuery(\"user-1\", \"What are the latest developments in artificial intelligence?\"),\n",
    "        UserQuery(\"user-2\", \"How can I improve my marathon training?\"),\n",
    "        UserQuery(\"user-3\", \"Best photography spots in Iceland\"),\n",
    "        UserQuery(\"user-4\", \"Current trends in cryptocurrency markets\"),\n",
    "        UserQuery(\"user-5\", \"Recommend fantasy books similar to Brandon Sanderson\"),\n",
    "        UserQuery(\"user-1\", \"Explain vector databases and their use cases\"),\n",
    "        UserQuery(\"user-2\", \"Plant-based meal prep ideas for athletes\"),\n",
    "        UserQuery(\"user-3\", \"Travel tips for visiting Japan\"),\n",
    "        UserQuery(\"user-4\", \"Understanding stock market indicators\"),\n",
    "        UserQuery(\"user-5\", \"Historical biographies worth reading\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\ud83d\ude80 Launching 10 concurrent searches...\\n\")\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    # Execute all searches concurrently\n",
    "    results = await asyncio.gather(*[search_for_user(q) for q in queries])\n",
    "    \n",
    "    total_duration = (time.perf_counter() - start) * 1000\n",
    "    \n",
    "    # Display results\n",
    "    print(\"\ud83d\udcca Results:\")\n",
    "    for result in results:\n",
    "        print(f\"  {result}\")\n",
    "        if result.top_result:\n",
    "            print(f\"    \u21b3 Top: {result.top_result['content']} (score: {result.top_result['score']:.3f})\")\n",
    "    \n",
    "    print(f\"\\n\u23f1\ufe0f  Total wall time: {total_duration:.1f}ms\")\n",
    "    print(f\"\ud83d\udcc8 Average per search: {total_duration / len(queries):.1f}ms\")\n",
    "    print(f\"\ud83c\udfaf Throughput: {len(queries) / (total_duration / 1000):.1f} searches/sec\")\n",
    "    \n",
    "    # Compare with hypothetical sequential execution\n",
    "    sequential_estimate = sum(r.duration_ms for r in results)\n",
    "    speedup = sequential_estimate / total_duration\n",
    "    print(f\"\\n\u26a1 Async speedup: {speedup:.1f}x faster than sequential\")\n",
    "\n",
    "# Run the demo\n",
    "await concurrent_search_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udce6 Pattern 2: Batch Processing with Parallelism\n",
    "\n",
    "**Use Case**: Processing large volumes of data (ETL, migrations, bulk analysis).\n",
    "\n",
    "**Why Async Wins**: Process 100s of items with controlled parallelism, faster than sequential sync."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udce6 Batch Processing Demo: 100 items\n",
      "\n",
      "  Concurrency  1: 10.62s (9.4 items/sec)\n",
      "  Concurrency  5: 2.15s (46.5 items/sec)\n",
      "  Concurrency 10: 1.07s (93.7 items/sec)\n",
      "  Concurrency 20: 0.58s (172.7 items/sec)\n",
      "\n",
      "\u2705 Batch processing complete\n",
      "\ud83d\udca1 Tip: Tune max_concurrent based on your Valkey/MemoryDB capacity\n"
     ]
    }
   ],
   "source": [
    "async def batch_store_with_semaphore(items: List[Dict[str, Any]], max_concurrent: int = 20):\n",
    "    \"\"\"Store items in batches with controlled concurrency.\"\"\"\n",
    "    semaphore = asyncio.Semaphore(max_concurrent)\n",
    "    \n",
    "    async def store_with_limit(item):\n",
    "        async with semaphore:\n",
    "            await async_store.aput(\n",
    "                namespace=item[\"namespace\"],\n",
    "                key=item[\"key\"],\n",
    "                value=item[\"value\"]\n",
    "            )\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    await asyncio.gather(*[store_with_limit(item) for item in items])\n",
    "    duration = time.perf_counter() - start\n",
    "    \n",
    "    return duration\n",
    "\n",
    "async def batch_processing_demo():\n",
    "    \"\"\"Demonstrate batch processing efficiency.\"\"\"\n",
    "    # Generate 100 sample items\n",
    "    batch_items = [\n",
    "        {\n",
    "            \"namespace\": (\"batch\", f\"user-{i % 10}\"),\n",
    "            \"key\": f\"item-{i}\",\n",
    "            \"value\": {\n",
    "                \"content\": f\"Batch item {i}: Sample data for testing parallel processing patterns with AsyncValkeyStore\",\n",
    "                \"user_id\": f\"user-{i % 10}\",\n",
    "                \"category\": [\"tech\", \"health\", \"finance\"][i % 3],\n",
    "                \"batch_id\": i // 10,\n",
    "            }\n",
    "        }\n",
    "        for i in range(100)\n",
    "    ]\n",
    "    \n",
    "    print(\"\ud83d\udce6 Batch Processing Demo: 100 items\\n\")\n",
    "    \n",
    "    # Test different concurrency levels\n",
    "    for max_concurrent in [1, 5, 10, 20]:\n",
    "        duration = await batch_store_with_semaphore(batch_items, max_concurrent)\n",
    "        throughput = len(batch_items) / duration\n",
    "        print(f\"  Concurrency {max_concurrent:2d}: {duration:.2f}s ({throughput:.1f} items/sec)\")\n",
    "    \n",
    "    print(\"\\n\u2705 Batch processing complete\")\n",
    "    print(\"\ud83d\udca1 Tip: Tune max_concurrent based on your Valkey/MemoryDB capacity\")\n",
    "\n",
    "# Run the demo\n",
    "await batch_processing_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udf10 Pattern 3: FastAPI Integration\n",
    "\n",
    "**Use Case**: Building production REST APIs with async frameworks.\n",
    "\n",
    "**Example**: Search endpoint that serves multiple concurrent requests efficiently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83c\udf10 FastAPI Integration Demo\n",
      "\n",
      "Health Check: {'status': 'healthy', 'store': 'connected'}\n",
      "\n",
      "\ud83d\udcde Simulating 3 concurrent API requests...\n",
      "\n",
      "User user-1: 1 results in 113.7ms\n",
      "  \u21b3 Top result: I love machine learning, AI, and cloud computing. Especially... (score: 0.100)\n",
      "User user-2: 1 results in 86.7ms\n",
      "  \u21b3 Top result: Passionate about running, yoga, and healthy eating. Training... (score: 0.600)\n",
      "User user-3: 1 results in 109.3ms\n",
      "  \u21b3 Top result: Love exploring new countries, trying local cuisines, and pho... (score: 0.600)\n",
      "\n",
      "\u23f1\ufe0f  Total API response time: 113.8ms\n",
      "\ud83d\udca1 With sync, this would block other requests during I/O\n",
      "\n",
      "============================================================\n",
      "\ud83d\udcdd Production FastAPI Example:\n",
      "============================================================\n",
      "\n",
      "from fastapi import FastAPI, HTTPException\n",
      "from langgraph_checkpoint_aws.store.valkey import AsyncValkeyStore\n",
      "\n",
      "app = FastAPI()\n",
      "store = AsyncValkeyStore(conn_string=CONN_STRING, ...)\n",
      "\n",
      "@app.on_event(\"startup\")\n",
      "async def startup():\n",
      "    # Store is ready - async context handles connections\n",
      "    pass\n",
      "\n",
      "@app.get(\"/search/{user_id}\")\n",
      "async def search(user_id: str, query: str):\n",
      "    results = await store.asearch(\n",
      "        namespace_prefix=(\"prefs\", user_id),\n",
      "        query=query,\n",
      "        limit=10\n",
      "    )\n",
      "    return {\"results\": [asdict(r) for r in results]}\n",
      "\n",
      "@app.get(\"/health\")\n",
      "async def health():\n",
      "    # Quick connectivity check\n",
      "    await store.asearch((\"health\",), \"test\", limit=1)\n",
      "    return {\"status\": \"ok\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example FastAPI application (pseudo-code for demonstration)\n",
    "\n",
    "from typing import List, Optional\n",
    "from dataclasses import asdict\n",
    "\n",
    "# This demonstrates the pattern - actual FastAPI would be in separate service\n",
    "class SearchAPI:\n",
    "    \"\"\"Example FastAPI-style search service.\"\"\"\n",
    "    \n",
    "    def __init__(self, store: AsyncValkeyStore):\n",
    "        self.store = store\n",
    "    \n",
    "    async def search_endpoint(self, user_id: str, query: str, category: Optional[str] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Async search endpoint handler.\n",
    "        \n",
    "        Usage in FastAPI:\n",
    "            @app.get(\"/search/{user_id}\")\n",
    "            async def search(user_id: str, query: str, category: Optional[str] = None):\n",
    "                return await search_api.search_endpoint(user_id, query, category)\n",
    "        \"\"\"\n",
    "        filters = {\"category\": category} if category else None\n",
    "        \n",
    "        start = time.perf_counter()\n",
    "        \n",
    "        # Async search - doesn't block other requests\n",
    "        results = await self.store.asearch(\n",
    "            namespace_prefix=(\"preferences\", user_id),\n",
    "            query=query,\n",
    "            limit=10,\n",
    "            filter=filters\n",
    "        )\n",
    "        \n",
    "        duration_ms = (time.perf_counter() - start) * 1000\n",
    "        \n",
    "        return {\n",
    "            \"user_id\": user_id,\n",
    "            \"query\": query,\n",
    "            \"results\": [\n",
    "                {\n",
    "                    \"key\": r.key,\n",
    "                    \"score\": r.score,\n",
    "                    \"content\": r.value.get(\"content\", \"\"),\n",
    "                    \"category\": r.value.get(\"category\"),\n",
    "                }\n",
    "                for r in results\n",
    "            ],\n",
    "            \"count\": len(results),\n",
    "            \"duration_ms\": duration_ms\n",
    "        }\n",
    "    \n",
    "    async def health_check(self) -> Dict[str, str]:\n",
    "        \"\"\"Health check endpoint.\"\"\"\n",
    "        try:\n",
    "            # Quick connectivity check\n",
    "            await self.store.asearch(\n",
    "                namespace_prefix=(\"health\",),\n",
    "                query=\"test\",\n",
    "                limit=1\n",
    "            )\n",
    "            return {\"status\": \"healthy\", \"store\": \"connected\"}\n",
    "        except Exception as e:\n",
    "            return {\"status\": \"unhealthy\", \"error\": str(e)}\n",
    "\n",
    "# Simulate FastAPI usage\n",
    "async def fastapi_demo():\n",
    "    \"\"\"Demonstrate FastAPI integration patterns.\"\"\"\n",
    "    api = SearchAPI(async_store)\n",
    "    \n",
    "    print(\"\ud83c\udf10 FastAPI Integration Demo\\n\")\n",
    "    \n",
    "    # Simulate health check\n",
    "    health = await api.health_check()\n",
    "    print(f\"Health Check: {health}\\n\")\n",
    "    \n",
    "    # Simulate concurrent API requests\n",
    "    requests = [\n",
    "        (\"user-1\", \"artificial intelligence trends\", \"technology\"),\n",
    "        (\"user-2\", \"marathon training tips\", \"health\"),\n",
    "        (\"user-3\", \"best travel destinations\", \"lifestyle\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\ud83d\udcde Simulating 3 concurrent API requests...\\n\")\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    responses = await asyncio.gather(*[\n",
    "        api.search_endpoint(user_id, query, category)\n",
    "        for user_id, query, category in requests\n",
    "    ])\n",
    "    \n",
    "    total_time = (time.perf_counter() - start) * 1000\n",
    "    \n",
    "    for resp in responses:\n",
    "        print(f\"User {resp['user_id']}: {resp['count']} results in {resp['duration_ms']:.1f}ms\")\n",
    "        if resp['results']:\n",
    "            top = resp['results'][0]\n",
    "            print(f\"  \u21b3 Top result: {top['content'][:60]}... (score: {top['score']:.3f})\")\n",
    "    \n",
    "    print(f\"\\n\u23f1\ufe0f  Total API response time: {total_time:.1f}ms\")\n",
    "    print(f\"\ud83d\udca1 With sync, this would block other requests during I/O\")\n",
    "\n",
    "# Run the demo\n",
    "await fastapi_demo()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\ud83d\udcdd Production FastAPI Example:\")\n",
    "print(\"=\"*60)\n",
    "print(\"\"\"\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from langgraph_checkpoint_aws.store.valkey import AsyncValkeyStore\n",
    "\n",
    "app = FastAPI()\n",
    "store = AsyncValkeyStore(conn_string=CONN_STRING, ...)\n",
    "\n",
    "@app.on_event(\"startup\")\n",
    "async def startup():\n",
    "    # Store is ready - async context handles connections\n",
    "    pass\n",
    "\n",
    "@app.get(\"/search/{user_id}\")\n",
    "async def search(user_id: str, query: str):\n",
    "    results = await store.asearch(\n",
    "        namespace_prefix=(\"prefs\", user_id),\n",
    "        query=query,\n",
    "        limit=10\n",
    "    )\n",
    "    return {\"results\": [asdict(r) for r in results]}\n",
    "\n",
    "@app.get(\"/health\")\n",
    "async def health():\n",
    "    # Quick connectivity check\n",
    "    await store.asearch((\"health\",), \"test\", limit=1)\n",
    "    return {\"status\": \"ok\"}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \u2696\ufe0f Pattern 4: Sync vs Async Performance Comparison\n",
    "\n",
    "Direct measurement of async benefits in real-world scenarios."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2696\ufe0f  Sync vs Async Performance Comparison\n",
      "\n",
      "Testing 5 searches...\n",
      "\n",
      "\ud83d\udd35 Sync (Sequential):\n",
      "   Duration: 25.7ms\n",
      "   Throughput: 194.3 searches/sec\n",
      "\n",
      "\ud83d\udfe2 Async (Concurrent):\n",
      "   Duration: 122.6ms\n",
      "   Throughput: 40.8 searches/sec\n",
      "\n",
      "\ud83d\udcca Results:\n",
      "   Speedup: 0.21x\n",
      "   Time saved: -96.8ms\n",
      "   Efficiency gain: -79.0%\n",
      "\n",
      "\ud83d\udd0d Verification:\n",
      "   Query 1: \u2705 Both returned 1 results\n",
      "   Query 2: \u2705 Both returned 1 results\n",
      "   Query 3: \u2705 Both returned 1 results\n",
      "   Query 4: \u2705 Both returned 1 results\n",
      "   Query 5: \u2705 Both returned 1 results\n"
     ]
    }
   ],
   "source": [
    "from langgraph_checkpoint_aws.store.valkey import ValkeyStore\n",
    "\n",
    "# Create sync store for comparison\n",
    "sync_store = ValkeyStore(\n",
    "    valkey_client,\n",
    "    index=index_config\n",
    ")\n",
    "\n",
    "async def performance_comparison():\n",
    "    \"\"\"Compare sync vs async for multiple searches.\"\"\"\n",
    "    queries = [\n",
    "        ((\"preferences\", \"user-1\"), \"machine learning applications\"),\n",
    "        ((\"preferences\", \"user-2\"), \"fitness and nutrition\"),\n",
    "        ((\"preferences\", \"user-3\"), \"travel photography\"),\n",
    "        ((\"preferences\", \"user-4\"), \"investment strategies\"),\n",
    "        ((\"preferences\", \"user-5\"), \"fantasy literature\"),\n",
    "    ]\n",
    "    \n",
    "    print(\"\u2696\ufe0f  Sync vs Async Performance Comparison\\n\")\n",
    "    print(\"Testing 5 searches...\\n\")\n",
    "    \n",
    "    # Sync approach (sequential)\n",
    "    print(\"\ud83d\udd35 Sync (Sequential):\")\n",
    "    sync_start = time.perf_counter()\n",
    "    sync_results = []\n",
    "    for namespace, query in queries:\n",
    "        results = sync_store.search(namespace, query=query, limit=3)\n",
    "        sync_results.append(results)\n",
    "    sync_duration = time.perf_counter() - sync_start\n",
    "    print(f\"   Duration: {sync_duration * 1000:.1f}ms\")\n",
    "    print(f\"   Throughput: {len(queries) / sync_duration:.1f} searches/sec\\n\")\n",
    "    \n",
    "    # Async approach (concurrent)\n",
    "    print(\"\ud83d\udfe2 Async (Concurrent):\")\n",
    "    async_start = time.perf_counter()\n",
    "    async_results = await asyncio.gather(*[\n",
    "        async_store.asearch(namespace, query=query, limit=3)\n",
    "        for namespace, query in queries\n",
    "    ])\n",
    "    async_duration = time.perf_counter() - async_start\n",
    "    print(f\"   Duration: {async_duration * 1000:.1f}ms\")\n",
    "    print(f\"   Throughput: {len(queries) / async_duration:.1f} searches/sec\\n\")\n",
    "    \n",
    "    # Analysis\n",
    "    speedup = sync_duration / async_duration\n",
    "    print(f\"\ud83d\udcca Results:\")\n",
    "    print(f\"   Speedup: {speedup:.2f}x\")\n",
    "    print(f\"   Time saved: {(sync_duration - async_duration) * 1000:.1f}ms\")\n",
    "    print(f\"   Efficiency gain: {((speedup - 1) * 100):.1f}%\")\n",
    "    \n",
    "    # Verify results match\n",
    "    print(f\"\\n\ud83d\udd0d Verification:\")\n",
    "    for i, (sync_res, async_res) in enumerate(zip(sync_results, async_results)):\n",
    "        if len(sync_res) == len(async_res):\n",
    "            print(f\"   Query {i+1}: \u2705 Both returned {len(sync_res)} results\")\n",
    "        else:\n",
    "            print(f\"   Query {i+1}: \u26a0\ufe0f  Count mismatch: sync={len(sync_res)}, async={len(async_res)}\")\n",
    "\n",
    "# Run comparison\n",
    "await performance_comparison()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfd7\ufe0f Pattern 5: Production-Ready Patterns\n",
    "\n",
    "### Connection Pooling & Resource Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 22:33:12,128 - __main__ - INFO - \u2705 AsyncValkeyStore initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83c\udfd7\ufe0f  Production Patterns Demo\n",
      "\n",
      "1\ufe0f\u20e3  Context Manager Pattern:\n",
      "   Found 3 results\n",
      "\n",
      "2\ufe0f\u20e3  Error Handling Pattern:\n",
      "   Search completed: 0 results\n",
      "\n",
      "3\ufe0f\u20e3  Rate Limiting Pattern:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-04 22:33:12,741 - __main__ - INFO - \ud83d\uded1 AsyncValkeyStore shutdown\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Processed 10 queries in 269.1ms\n",
      "   (Max 5 concurrent due to rate limiting)\n",
      "\n",
      "4\ufe0f\u20e3  Retry Pattern:\n",
      "   Search with retry: 3 results\n",
      "\n",
      "\u2705 Production patterns demonstration complete\n"
     ]
    }
   ],
   "source": [
    "from contextlib import asynccontextmanager\n",
    "from typing import AsyncGenerator\n",
    "\n",
    "class ProductionValkeyManager:\n",
    "    \"\"\"Production-grade async ValkeyStore manager.\"\"\"\n",
    "    \n",
    "    def __init__(self, valkey_client: Any, index_config: ValkeyIndexConfig):\n",
    "        self.client = valkey_client\n",
    "        self.index_config = index_config\n",
    "        self._store: Optional[AsyncValkeyStore] = None\n",
    "    \n",
    "    async def initialize(self):\n",
    "        \"\"\"Initialize store with connection validation.\"\"\"\n",
    "        self._store = AsyncValkeyStore(\n",
    "            self.client,\n",
    "            index=self.index_config\n",
    "        )\n",
    "        await self._store.setup()\n",
    "        logger.info(\"\u2705 AsyncValkeyStore initialized\")\n",
    "    \n",
    "    async def shutdown(self):\n",
    "        \"\"\"Graceful shutdown.\"\"\"\n",
    "        if self._store:\n",
    "            # Cleanup if needed\n",
    "            logger.info(\"\ud83d\uded1 AsyncValkeyStore shutdown\")\n",
    "    \n",
    "    @asynccontextmanager\n",
    "    async def get_store(self) -> AsyncGenerator[AsyncValkeyStore, None]:\n",
    "        \"\"\"Get store with automatic resource management.\"\"\"\n",
    "        if not self._store:\n",
    "            raise RuntimeError(\"Manager not initialized\")\n",
    "        try:\n",
    "            yield self._store\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Store operation failed: {e}\")\n",
    "            raise\n",
    "\n",
    "async def production_patterns_demo():\n",
    "    \"\"\"Demonstrate production patterns.\"\"\"\n",
    "    print(\"\ud83c\udfd7\ufe0f  Production Patterns Demo\\n\")\n",
    "    \n",
    "    # Initialize manager\n",
    "    manager = ProductionValkeyManager(\n",
    "        valkey_client=valkey_client,\n",
    "        index_config=index_config\n",
    "    )\n",
    "    await manager.initialize()\n",
    "    \n",
    "    # Use with context manager\n",
    "    print(\"1\ufe0f\u20e3  Context Manager Pattern:\")\n",
    "    async with manager.get_store() as store:\n",
    "        results = await store.asearch(\n",
    "            namespace_prefix=(\"preferences\",),\n",
    "            query=\"technology interests\",\n",
    "            limit=3\n",
    "        )\n",
    "        print(f\"   Found {len(results)} results\\n\")\n",
    "    \n",
    "    # Error handling pattern\n",
    "    print(\"2\ufe0f\u20e3  Error Handling Pattern:\")\n",
    "    try:\n",
    "        async with manager.get_store() as store:\n",
    "            results = await store.asearch(\n",
    "                namespace_prefix=(\"nonexistent\",),\n",
    "                query=\"test\",\n",
    "                limit=3\n",
    "            )\n",
    "            print(f\"   Search completed: {len(results)} results\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"   \u26a0\ufe0f  Handled error: {type(e).__name__}\\n\")\n",
    "    \n",
    "    # Rate limiting pattern\n",
    "    print(\"3\ufe0f\u20e3  Rate Limiting Pattern:\")\n",
    "    rate_limit = asyncio.Semaphore(5)  # Max 5 concurrent ops\n",
    "    \n",
    "    async def rate_limited_search(query: str):\n",
    "        async with rate_limit:\n",
    "            async with manager.get_store() as store:\n",
    "                return await store.asearch(\n",
    "                    namespace_prefix=(\"preferences\",),\n",
    "                    query=query,\n",
    "                    limit=1\n",
    "                )\n",
    "    \n",
    "    queries = [f\"query-{i}\" for i in range(10)]\n",
    "    start = time.perf_counter()\n",
    "    results = await asyncio.gather(*[rate_limited_search(q) for q in queries])\n",
    "    duration = time.perf_counter() - start\n",
    "    print(f\"   Processed {len(queries)} queries in {duration*1000:.1f}ms\")\n",
    "    print(f\"   (Max 5 concurrent due to rate limiting)\\n\")\n",
    "    \n",
    "    # Retry pattern\n",
    "    print(\"4\ufe0f\u20e3  Retry Pattern:\")\n",
    "    async def search_with_retry(query: str, max_retries: int = 3):\n",
    "        for attempt in range(max_retries):\n",
    "            try:\n",
    "                async with manager.get_store() as store:\n",
    "                    return await store.asearch(\n",
    "                        namespace_prefix=(\"preferences\",),\n",
    "                        query=query,\n",
    "                        limit=3\n",
    "                    )\n",
    "            except Exception as e:\n",
    "                if attempt == max_retries - 1:\n",
    "                    raise\n",
    "                wait_time = 2 ** attempt  # Exponential backoff\n",
    "                logger.warning(f\"Attempt {attempt + 1} failed, retrying in {wait_time}s...\")\n",
    "                await asyncio.sleep(wait_time)\n",
    "    \n",
    "    results = await search_with_retry(\"resilient search\")\n",
    "    print(f\"   Search with retry: {len(results)} results\\n\")\n",
    "    \n",
    "    # Cleanup\n",
    "    await manager.shutdown()\n",
    "    print(\"\u2705 Production patterns demonstration complete\")\n",
    "\n",
    "# Run demo\n",
    "await production_patterns_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83c\udfaf Pattern 6: Timeout & Circuit Breaker\n",
    "\n",
    "Protect your application from slow or failing dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udee1\ufe0f  Resilience Patterns Demo\n",
      "\n",
      "1\ufe0f\u20e3  Timeout Protection:\n",
      "   Search completed: 5 results\n",
      "\n",
      "2\ufe0f\u20e3  Circuit Breaker Pattern:\n",
      "   Query 1: 3 results (breaker: closed)\n",
      "   Query 2: 3 results (breaker: closed)\n",
      "   Query 3: 3 results (breaker: closed)\n",
      "   Query 4: 3 results (breaker: closed)\n",
      "   Query 5: 3 results (breaker: closed)\n",
      "\n",
      "\u2705 Resilience patterns complete\n"
     ]
    }
   ],
   "source": [
    "async def search_with_timeout(store: AsyncValkeyStore, query: str, timeout_seconds: float = 2.0):\n",
    "    \"\"\"Search with timeout protection.\"\"\"\n",
    "    try:\n",
    "        return await asyncio.wait_for(\n",
    "            store.asearch(\n",
    "                namespace_prefix=(\"preferences\",),\n",
    "                query=query,\n",
    "                limit=5\n",
    "            ),\n",
    "            timeout=timeout_seconds\n",
    "        )\n",
    "    except asyncio.TimeoutError:\n",
    "        logger.warning(f\"Search timed out after {timeout_seconds}s\")\n",
    "        return []  # Return empty results\n",
    "\n",
    "class CircuitBreaker:\n",
    "    \"\"\"Simple circuit breaker for fault tolerance.\"\"\"\n",
    "    \n",
    "    def __init__(self, failure_threshold: int = 5, timeout: float = 60.0):\n",
    "        self.failure_threshold = failure_threshold\n",
    "        self.timeout = timeout\n",
    "        self.failures = 0\n",
    "        self.last_failure_time = None\n",
    "        self.state = \"closed\"  # closed, open, half-open\n",
    "    \n",
    "    def is_open(self) -> bool:\n",
    "        if self.state == \"open\":\n",
    "            if time.time() - self.last_failure_time > self.timeout:\n",
    "                self.state = \"half-open\"\n",
    "                return False\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def record_success(self):\n",
    "        self.failures = 0\n",
    "        self.state = \"closed\"\n",
    "    \n",
    "    def record_failure(self):\n",
    "        self.failures += 1\n",
    "        self.last_failure_time = time.time()\n",
    "        if self.failures >= self.failure_threshold:\n",
    "            self.state = \"open\"\n",
    "            logger.warning(f\"Circuit breaker opened after {self.failures} failures\")\n",
    "\n",
    "async def resilience_demo():\n",
    "    \"\"\"Demonstrate timeout and circuit breaker patterns.\"\"\"\n",
    "    print(\"\ud83d\udee1\ufe0f  Resilience Patterns Demo\\n\")\n",
    "    \n",
    "    # Timeout demo\n",
    "    print(\"1\ufe0f\u20e3  Timeout Protection:\")\n",
    "    results = await search_with_timeout(async_store, \"test query\", timeout_seconds=5.0)\n",
    "    print(f\"   Search completed: {len(results)} results\\n\")\n",
    "    \n",
    "    # Circuit breaker demo\n",
    "    print(\"2\ufe0f\u20e3  Circuit Breaker Pattern:\")\n",
    "    breaker = CircuitBreaker(failure_threshold=3, timeout=10.0)\n",
    "    \n",
    "    async def protected_search(query: str):\n",
    "        if breaker.is_open():\n",
    "            logger.warning(\"Circuit breaker is open, skipping request\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            results = await async_store.asearch(\n",
    "                namespace_prefix=(\"preferences\",),\n",
    "                query=query,\n",
    "                limit=3\n",
    "            )\n",
    "            breaker.record_success()\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            breaker.record_failure()\n",
    "            logger.error(f\"Search failed: {e}\")\n",
    "            return []\n",
    "    \n",
    "    # Simulate searches\n",
    "    for i in range(5):\n",
    "        results = await protected_search(f\"query-{i}\")\n",
    "        print(f\"   Query {i+1}: {len(results)} results (breaker: {breaker.state})\")\n",
    "    \n",
    "    print(\"\\n\u2705 Resilience patterns complete\")\n",
    "\n",
    "# Run demo\n",
    "await resilience_demo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \ud83d\udcca Summary & Best Practices\n",
    "\n",
    "### When to Use AsyncValkeyStore\n",
    "\n",
    "\u2705 **Use Async When:**\n",
    "- Building web APIs (FastAPI, aiohttp, etc.)\n",
    "- Handling concurrent users\n",
    "- Processing large batches (100+ items)\n",
    "- Integrating with other async services\n",
    "- Maximizing I/O throughput\n",
    "\n",
    "\u274c **Use Sync When:**\n",
    "- Simple CLI scripts\n",
    "- Single-user notebooks\n",
    "- Sequential processing is sufficient\n",
    "- Codebase is entirely synchronous\n",
    "\n",
    "### Performance Tips\n",
    "\n",
    "1. **Concurrency Control**: Use `asyncio.Semaphore` to limit concurrent operations\n",
    "2. **Batching**: Group operations with `asyncio.gather()` for parallelism\n",
    "3. **Timeouts**: Always set timeouts with `asyncio.wait_for()`\n",
    "4. **Circuit Breakers**: Protect against cascading failures\n",
    "5. **Connection Pooling**: Reuse store instances, avoid creating per-request\n",
    "\n",
    "### Production Checklist\n",
    "\n",
    "- [ ] Use `AsyncValkeyStore` in async web frameworks\n",
    "- [ ] Implement timeout protection (2-5s typical)\n",
    "- [ ] Add circuit breaker for fault tolerance\n",
    "- [ ] Monitor connection pool metrics\n",
    "- [ ] Set appropriate concurrency limits (10-50 typical)\n",
    "- [ ] Use exponential backoff for retries\n",
    "- [ ] Implement graceful shutdown\n",
    "- [ ] Add comprehensive error logging\n",
    "\n",
    "### Typical Speedup Ranges\n",
    "\n",
    "| Operation | Expected Speedup | Notes |\n",
    "|-----------|-----------------|-------|\n",
    "| Single search | 1.0x | No benefit |\n",
    "| 5 concurrent searches | 2-4x | Network latency dependent |\n",
    "| 10 concurrent searches | 3-6x | Ideal for web APIs |\n",
    "| 100 batch operations | 5-15x | With proper semaphore limits |\n",
    "| High-concurrency API | 10-20x+ | With connection pooling |\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. Review [`valkey_store.ipynb`](./valkey_store.ipynb) for core concepts\n",
    "2. Explore [`agentcore_valkey_store.ipynb`](./agentcore_valkey_store.ipynb) for state management\n",
    "3. Adapt patterns above to your production use case\n",
    "4. Monitor performance metrics in your environment\n",
    "5. Tune concurrency limits based on your infrastructure\n",
    "\n",
    "## \ud83c\udf93 Key Takeaways\n",
    "\n",
    "1. **Async shines with I/O-bound operations** - Network calls, database queries, API requests\n",
    "2. **Measure before optimizing** - Profile your specific workload\n",
    "3. **Production needs resilience** - Timeouts, retries, circuit breakers\n",
    "4. **Context managers are your friend** - Proper resource management\n",
    "5. **Tune concurrency for your setup** - Start conservative, measure, adjust\n",
    "\n",
    "---\n",
    "\n",
    "**Happy async coding with ValkeyStore! \ud83d\ude80**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}