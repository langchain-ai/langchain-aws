{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8208f7d6-391d-4054-9e67-ac0f85878dcd",
   "metadata": {},
   "source": [
    "# Bedrock AgentCore Memory Checkpointer Walkthrough\n",
    "\n",
    "This sample notebook walks through setup and usage of the Bedrock AgentCore Memory Checkpointer with LangGraph. This approach enables saving of conversations and state data to the Memory API for persistent storage, fault tolerance, and human-in-the-loop workflows.\n",
    "\n",
    "### Setup\n",
    "For this notebook you will need:\n",
    "1. An Amazon Web Services development account\n",
    "2. Bedrock Model Access (i.e. Claude 3.7 Sonnet)\n",
    "3. An AgentCore Memory Resource configured (see below section for details)\n",
    "\n",
    "### AgentCore Memory Resource\n",
    "\n",
    "Either in the AWS developer portal or using the boto3 library you must create an [AgentCore Memory Resource](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/bedrock-agentcore-control/client/create_memory.html). For just using the `AgentCoreMemorySaver` checkpointer in this notebook, you do not need to specify any specific long-term memory strategies. However, it may be beneficial to supplement this approach with the `AgentCoreMemoryStore` to save and extract conversational insights, so you may want to enable strategies for that use case.\n",
    "\n",
    "Once you have the Memory enabled and in a `ACTIVE` state, take note of the `memoryId`, we will need it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8eff8706-6715-4981-983b-934561ee0a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install general dependencies\n",
    "from typing import Annotated, Any, Dict, List\n",
    "\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.tools import tool\n",
    "\n",
    "# Import LangGraph and LangChain components\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langgraph.graph import END, START, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from typing_extensions import TypedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc12fd92-b84a-4d2f-b96d-83d3da08bf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the AgentCoreMemorySaver that we will use as a checkpointer\n",
    "# from langgraph_checkpoint_aws.checkpoint.agentcore_memory.saver import AgentCoreMemorySaver\n",
    "from agentcore_memory.saver import AgentCoreMemorySaver\n",
    "\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d91a14-541c-426c-a52c-5fdcf29f8953",
   "metadata": {},
   "source": [
    "## AgentCore Memory Configuration\n",
    "- `REGION` corresponds to the AWS region that your resources are present in, these are passed to the `AgentCoreMemorySaver`.\n",
    "- `MEMORY_ID` corresponds to your top level AgentCore Memory resource. Within this resource we will store checkpoints for multiple actors and sessions\n",
    "- `MODEL_ID` this is the bedrock model that will power our LangGraph agent through Bedrock Converse.\n",
    "\n",
    "We will use the `MEMORY_ID` and any additional boto3 client keyword args (in our case, `REGION`) to instantiate our checkpointer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "226d094c-a05d-4f88-851d-cc42ff63ef11",
   "metadata": {},
   "outputs": [],
   "source": [
    "REGION = \"ap-southeast-2\"\n",
    "MEMORY_ID = \"memory_tnpk0-AMDRU75vYn\"\n",
    "MODEL_ID = \"apac.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    "\n",
    "# Initialize checkpointer for state persistence\n",
    "checkpointer = AgentCoreMemorySaver(MEMORY_ID, region_name=REGION)\n",
    "\n",
    "# Initialize LLM\n",
    "llm = init_chat_model(MODEL_ID, model_provider=\"bedrock_converse\", region_name=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8a1e31f-137a-4bd6-b959-4dc7d8176949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define agent state and LangGraph graph builder\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56c77aa-4b19-49a5-af3c-db2b4798384b",
   "metadata": {},
   "source": [
    "## Define our tools\n",
    "\n",
    "For this demo notebook we will only give our agent access to two simple tools, adding and multiplying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd81ba1c-3fb8-474c-ae40-0ee7c62ca234",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def add(a: int, b: int):\n",
    "    \"\"\"Add two integers and return the result\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int):\n",
    "    \"\"\"Multiply two integers and return the result\"\"\"\n",
    "    return a * b\n",
    "\n",
    "\n",
    "tools = [add, multiply]\n",
    "\n",
    "# Bind the tools to our LLM so it can understand their structure\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "651b6e3f-8b41-4c07-8a32-680666b2661e",
   "metadata": {},
   "source": [
    "## Build our LangGraph agent graph\n",
    "\n",
    "Our agent will have a few simple nodes, mainly a chatbot node and a tool node. This will enable our chatbot to use the add and multiply tools as much as it needs and then return a response. We will visualize this graph below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e63decd-2e15-4f12-9e82-6a0aac3f1892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Agent with checkpointing compiled successfully\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x10b5e6e90>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our chatbot node will contain the LLM invocation\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "\n",
    "# Finish off the other edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile the graph with our AgentCoreMemorySaver as the checkpointer\n",
    "graph = graph_builder.compile(checkpointer=checkpointer)\n",
    "\n",
    "print(\"âœ… Agent with checkpointing compiled successfully\")\n",
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cbbb3a-f85c-42f5-bbfb-40f5f6b8b48c",
   "metadata": {},
   "source": [
    "## IMPORTANT: State and Config\n",
    "\n",
    "\n",
    "### LangGraph RuntimeConfig\n",
    "In LangGraph, config is a `RuntimeConfig` that contains attributes that are necessary at invocation time, for example user IDs or session IDs. For the `AgentCoreMemorySaver`, `thread_id` and `actor_id` must be set in the config. For instance, your AgentCore invocation endpoint could assign this based on the identity or user ID of the caller. Additional documentation here: [https://langchain-ai.github.io/langgraphjs/how-tos/configuration/](https://langchain-ai.github.io/langgraphjs/how-tos/configuration/)\n",
    "\n",
    "### LangGraph Invocation State\n",
    "The state that is passed to the `graph.invoke` method is an instance of our `State` we defined earlier: \n",
    "```\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "```\n",
    "As you can see, we have defined messages with the `add_messages` annotation. This means that each node (or invocation) state can return a `messages` key that will simply add the value to the latest value of the `State`. So for example, our chatbot node may return a response such as `messages=[\"Hi of course I can help you with that\"]` and it will be appended to our state messages below instead of overwriting it. For more information on State, see the docs here: [https://langchain-ai.github.io/langgraph/concepts/low_level/#working-with-messages-in-graph-state](https://langchain-ai.github.io/langgraph/concepts/low_level/#working-with-messages-in-graph-state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "859fee36-1eff-4713-9c3b-387b702c0301",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our demo we will have dummy thread and actor IDs\n",
    "config = {\n",
    "    \"configurable\": {\n",
    "        \"thread_id\": \"thread-0\",\n",
    "        \"actor_id\": \"user-0\",\n",
    "    }\n",
    "}\n",
    "\n",
    "# This invocation state is where you would fill in a query prompt from the user at /invocations\n",
    "invocation_state = {\n",
    "    \"messages\": [HumanMessage(\"What is 1337 times 200 + 17? Follow pemdas.\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96044de0-2d32-4811-ac30-43f4416f4303",
   "metadata": {},
   "source": [
    "### Run the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2bc4869-58cd-4914-9a7a-8d39ecd16226",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is 1337 times 200 + 17? Follow pemdas.', additional_kwargs={}, response_metadata={}, id='b48c5506-2d06-4ba8-8da5-e315ad5cc654'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"I'll solve this step by step following PEMDAS (Parentheses, Exponents, Multiplication/Division, Addition/Subtraction).\\n\\nAccording to PEMDAS, I should perform multiplication before addition. So I'll first multiply 1337 by 200, and then add 17 to that result.\\n\\nLet me calculate 1337 Ã— 200:\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 1337, 'b': 200}, 'id': 'tooluse_zZPvbVtOR2u2uxjQMtAq_A'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'e1c53591-ec66-4bcc-851e-74e43091ff2f', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:45:15 GMT', 'content-type': 'application/json', 'content-length': '691', 'connection': 'keep-alive', 'x-amzn-requestid': 'e1c53591-ec66-4bcc-851e-74e43091ff2f'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [3046]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--5727d585-bf6b-4ca8-9b15-9e9275e112e6-0', tool_calls=[{'name': 'multiply', 'args': {'a': 1337, 'b': 200}, 'id': 'tooluse_zZPvbVtOR2u2uxjQMtAq_A', 'type': 'tool_call'}], usage_metadata={'input_tokens': 472, 'output_tokens': 153, 'total_tokens': 625, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content='267400', name='multiply', id='25e90eed-b36e-474a-b9f6-74a6294814c6', tool_call_id='tooluse_zZPvbVtOR2u2uxjQMtAq_A'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"Now I'll add 17 to this result:\"}, {'type': 'tool_use', 'name': 'add', 'input': {'a': 267400, 'b': 17}, 'id': 'tooluse_RkwUNdsXT16Yh8dktOyMRQ'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'a9c3bb70-784b-4550-a162-d0380023e801', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:45:17 GMT', 'content-type': 'application/json', 'content-length': '425', 'connection': 'keep-alive', 'x-amzn-requestid': 'a9c3bb70-784b-4550-a162-d0380023e801'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1589]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--5b2347b4-54e9-4c72-b9ff-ca3b111688ac-0', tool_calls=[{'name': 'add', 'args': {'a': 267400, 'b': 17}, 'id': 'tooluse_RkwUNdsXT16Yh8dktOyMRQ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 638, 'output_tokens': 82, 'total_tokens': 720, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content='267417', name='add', id='b5a708d3-5f32-4f34-93c5-1383dcc11479', tool_call_id='tooluse_RkwUNdsXT16Yh8dktOyMRQ'),\n",
       "  AIMessage(content='Following PEMDAS, the answer to 1337 Ã— 200 + 17 is 267,417.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '079b938e-969a-44ad-a8b9-c9d936fcc238', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:45:19 GMT', 'content-type': 'application/json', 'content-length': '354', 'connection': 'keep-alive', 'x-amzn-requestid': '079b938e-969a-44ad-a8b9-c9d936fcc238'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1397]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--bdb9b4ac-1f5a-489a-a956-d879aac4d942-0', usage_metadata={'input_tokens': 733, 'output_tokens': 31, 'total_tokens': 764, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  HumanMessage(content='Create a LaTeX formula in markdown that shows the previous calculation and results', additional_kwargs={}, response_metadata={}, id='ad93df1b-1eac-4e08-8805-b42ae9f59462'),\n",
       "  AIMessage(content=\"Here's a LaTeX formula in markdown that shows the previous calculation and results:\\n\\n```math\\n1337 \\\\times 200 + 17 = 267400 + 17 = 267417\\n```\\n\\nThis displays the calculation step by step, showing the multiplication of 1337 by 200 first (following PEMDAS - order of operations), which equals 267400, then the addition of 17 to get the final result of 267417.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'baa5c348-5b8b-40e0-8b69-6465193ce041', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:45:44 GMT', 'content-type': 'application/json', 'content-length': '657', 'connection': 'keep-alive', 'x-amzn-requestid': 'baa5c348-5b8b-40e0-8b69-6465193ce041'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [2624]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--1faf142a-b246-4870-9552-09b5f6b9d05b-0', usage_metadata={'input_tokens': 781, 'output_tokens': 106, 'total_tokens': 887, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  HumanMessage(content='What is 1337 times 200 + 17? Follow pemdas.', additional_kwargs={}, response_metadata={}, id='e6f0b5e6-a8c6-4a7a-96cc-0a1b6f11931f'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"I'll solve this step by step following PEMDAS (Parentheses, Exponents, Multiplication/Division, Addition/Subtraction).\\n\\nAccording to PEMDAS, I should perform multiplication before addition. So I'll first multiply 1337 by 200, and then add 17 to that result.\\n\\nLet me calculate 1337 Ã— 200:\"}, {'type': 'tool_use', 'name': 'multiply', 'input': {'a': 1337, 'b': 200}, 'id': 'tooluse_20HotERoStqxI3CgbvcQMg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '51736bf1-9e9e-483a-8b60-a00b99c0a4ff', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:50:16 GMT', 'content-type': 'application/json', 'content-length': '692', 'connection': 'keep-alive', 'x-amzn-requestid': '51736bf1-9e9e-483a-8b60-a00b99c0a4ff'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [2453]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--0ca8262a-6d70-4a50-b13b-d6df5f478149-0', tool_calls=[{'name': 'multiply', 'args': {'a': 1337, 'b': 200}, 'id': 'tooluse_20HotERoStqxI3CgbvcQMg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 909, 'output_tokens': 153, 'total_tokens': 1062, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content='267400', name='multiply', id='a43f5f72-d03f-4953-b748-f882c3b98b95', tool_call_id='tooluse_20HotERoStqxI3CgbvcQMg'),\n",
       "  AIMessage(content=[{'type': 'text', 'text': \"Now I'll add 17 to this result:\"}, {'type': 'tool_use', 'name': 'add', 'input': {'a': 267400, 'b': 17}, 'id': 'tooluse_dXOCeJXhS1e-p3DGxhUeFg'}], additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '618612aa-4795-4e4b-9c4d-850d87ccd805', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:50:18 GMT', 'content-type': 'application/json', 'content-length': '427', 'connection': 'keep-alive', 'x-amzn-requestid': '618612aa-4795-4e4b-9c4d-850d87ccd805'}, 'RetryAttempts': 0}, 'stopReason': 'tool_use', 'metrics': {'latencyMs': [1722]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--755de27f-2d2d-4804-b8b8-2d2fddc2f86e-0', tool_calls=[{'name': 'add', 'args': {'a': 267400, 'b': 17}, 'id': 'tooluse_dXOCeJXhS1e-p3DGxhUeFg', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1075, 'output_tokens': 82, 'total_tokens': 1157, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}}),\n",
       "  ToolMessage(content='267417', name='add', id='118bff77-abcf-4517-96e4-f60b80d5604b', tool_call_id='tooluse_dXOCeJXhS1e-p3DGxhUeFg'),\n",
       "  AIMessage(content='Following PEMDAS, the answer to 1337 Ã— 200 + 17 is 267,417.', additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': '3abe3820-54cf-456f-95a0-61fcef15dcc4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:50:19 GMT', 'content-type': 'application/json', 'content-length': '356', 'connection': 'keep-alive', 'x-amzn-requestid': '3abe3820-54cf-456f-95a0-61fcef15dcc4'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1186]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--d653f490-c780-423a-ab5e-24130110daaf-0', usage_metadata={'input_tokens': 1170, 'output_tokens': 31, 'total_tokens': 1201, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.invoke(invocation_state, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d28db8-c9cc-4fa1-922d-89476e9f71c5",
   "metadata": {},
   "source": [
    "## Inspect the current state with AgentCoreMemory\n",
    "\n",
    "Under the hood when you call `graph.get_state(config)` it calls the checkpointer to retrieve the latest checkpoint saved for our actor and session. We can take a look at the values saved at this point in the conversation from `messages`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60042ec5-cd64-48f3-bd7d-cb7ca9e21b39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "human: What is 1337 times 200 + 17? Follow pemdas.\n",
      "=========================================\n",
      "ai: I'll solve this step by step following PEMDAS (Parentheses, Exponents, Multiplication/Division, Addition/Subtraction).\n",
      "\n",
      "According to PEMDAS, I should perform multiplication before addition. So I'll first multiply 1337 by 200, and then add 17 to that result.\n",
      "\n",
      "Let me calculate 1337 Ã— 200:\n",
      "=========================================\n",
      "tool: 267400\n",
      "=========================================\n",
      "ai: Now I'll add 17 to this result:\n",
      "=========================================\n",
      "tool: 267417\n",
      "=========================================\n",
      "ai: Following PEMDAS, the answer to 1337 Ã— 200 + 17 is 267,417.\n",
      "=========================================\n",
      "human: Create a LaTeX formula in markdown that shows the previous calculation and results\n",
      "=========================================\n",
      "ai: Here's a LaTeX formula in markdown that shows the previous calculation and results:\n",
      "\n",
      "```math\n",
      "1337 \\times 200 + 17 = 267400 + 17 = 267417\n",
      "```\n",
      "\n",
      "This displays the calculation step by step, showing the multiplication of 1337 by 200 first (following PEMDAS - order of operations), which equals 267400, then the addition of 17 to get the final result of 267417.\n",
      "=========================================\n",
      "human: What is 1337 times 200 + 17? Follow pemdas.\n",
      "=========================================\n",
      "ai: I'll solve this step by step following PEMDAS (Parentheses, Exponents, Multiplication/Division, Addition/Subtraction).\n",
      "\n",
      "According to PEMDAS, I should perform multiplication before addition. So I'll first multiply 1337 by 200, and then add 17 to that result.\n",
      "\n",
      "Let me calculate 1337 Ã— 200:\n",
      "=========================================\n",
      "tool: 267400\n",
      "=========================================\n",
      "ai: Now I'll add 17 to this result:\n",
      "=========================================\n",
      "tool: 267417\n",
      "=========================================\n",
      "ai: Following PEMDAS, the answer to 1337 Ã— 200 + 17 is 267,417.\n",
      "=========================================\n"
     ]
    }
   ],
   "source": [
    "for message in graph.get_state(config).values.get(\"messages\"):\n",
    "    print(f\"{message.type}: {message.text()}\")\n",
    "    print(\"=========================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aa0c9bd-6fb6-467d-b51a-84696238b4fa",
   "metadata": {},
   "source": [
    "## Look at a previous checkpoints during execution\n",
    "Using the `graph.get_state_history(config)` we will see the checkpoints that were saved, then inspect a previous checkpoint's values for `messages`. Checkpoints are listed so the most recent checkpoints appear first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2232c2b-154d-4b50-93b0-925eb88e67c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Checkpoint ID: 1f0923ae-b162-61aa-800f-bba4b057543e) # of messages in state: 14\n",
      "(Checkpoint ID: 1f0923ae-a40f-61e2-800e-bc65f256d255) # of messages in state: 13\n",
      "(Checkpoint ID: 1f0923ae-a3ff-6c38-800d-505d7ed13c25) # of messages in state: 12\n",
      "(Checkpoint ID: 1f0923ae-918a-6f26-800c-7b2ebf1316a2) # of messages in state: 11\n",
      "(Checkpoint ID: 1f0923ae-9173-629a-800b-b53ad08339fe) # of messages in state: 10\n",
      "(Checkpoint ID: 1f0923ae-72c7-6ab2-800a-5b5912be455a) # of messages in state: 9\n",
      "(Checkpoint ID: 1f0923ae-72bd-6e0e-8009-33e40701ee42) # of messages in state: 8\n",
      "(Checkpoint ID: 1f0923a4-6e20-6324-8008-16ed6f369bd9) # of messages in state: 8\n",
      "(Checkpoint ID: 1f0923a4-5323-6b48-8007-e1247fbfc0cb) # of messages in state: 7\n",
      "(Checkpoint ID: 1f0923a4-530f-6a62-8006-4b60a52adca0) # of messages in state: 6\n",
      "(Checkpoint ID: 1f0923a3-7efb-649c-8005-acd1eb738210) # of messages in state: 6\n",
      "(Checkpoint ID: 1f0923a3-6fa2-62a2-8004-a44cd9675857) # of messages in state: 5\n",
      "(Checkpoint ID: 1f0923a3-6f9b-69d4-8003-6100b95bc700) # of messages in state: 4\n",
      "(Checkpoint ID: 1f0923a3-5e70-6da8-8002-40a909cdb9bd) # of messages in state: 3\n",
      "(Checkpoint ID: 1f0923a3-5e61-6858-8001-256b044cf577) # of messages in state: 2\n",
      "(Checkpoint ID: 1f0923a3-3f5c-6f5c-8000-7ce3a145a6ed) # of messages in state: 1\n",
      "(Checkpoint ID: 1f0923a3-3f4f-646a-bfff-6d736ba7793a) # of messages in state: 0\n"
     ]
    }
   ],
   "source": [
    "for checkpoint in graph.get_state_history(config):\n",
    "    print(\n",
    "        f\"(Checkpoint ID: {checkpoint.config['configurable']['checkpoint_id']}) # of messages in state: {len(checkpoint.values.get('messages'))}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab07194f-49b4-4fb9-a74b-d86b970cace6",
   "metadata": {},
   "source": [
    "## Continue the conversation\n",
    "By using the same config with our session and actor from before, we can continue the conversation by invoking our LangGraph agent with a new invocation state. The checkpointer in the background will take care of loading in context so that all the previous messages from the first interaction are loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7117c6a-d1d5-4866-aee9-2b7229fd73fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's a LaTeX formula in markdown that shows the previous calculation and results:\\n\\n```math\\n1337 \\\\times 200 + 17 = 267400 + 17 = 267417\\n```\\n\\nThis displays the calculation step by step, showing the multiplication of 1337 by 200 first (following PEMDAS - order of operations), which equals 267400, then the addition of 17 to get the final result of 267417.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'cf97747e-d4d4-49bf-b801-56253cc788c2', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Mon, 15 Sep 2025 13:50:36 GMT', 'content-type': 'application/json', 'content-length': '659', 'connection': 'keep-alive', 'x-amzn-requestid': 'cf97747e-d4d4-49bf-b801-56253cc788c2'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [2207]}, 'model_name': 'apac.anthropic.claude-3-7-sonnet-20250219-v1:0'}, id='run--88043c79-6656-47e0-b489-ad0219b553f0-0', usage_metadata={'input_tokens': 1218, 'output_tokens': 106, 'total_tokens': 1324, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This invocation state is where you would fill in a query prompt from the user at /invocations\n",
    "invocation_state = {\n",
    "    \"messages\": [\n",
    "        HumanMessage(\n",
    "            \"Create a LaTeX formula in markdown that shows the previous calculation and results\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "graph.invoke(invocation_state, config=config)\n",
    "\n",
    "# Display the response\n",
    "graph.get_state(config).values.get(\"messages\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa7bd51-0ece-47d6-aae3-2a9041d98645",
   "metadata": {},
   "source": [
    "## Wrapping Up\n",
    "\n",
    "As you can see, the AgentCore checkpointer is very powerful for persisting conversational and graph state in the background. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda8649a-d48f-467c-94b9-99dd8fb2c078",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
