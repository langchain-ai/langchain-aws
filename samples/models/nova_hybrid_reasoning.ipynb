{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48959e3b",
   "metadata": {},
   "source": [
    "# Nova Hybrid Reasoning with LangChain\n",
    "\n",
    "This notebook demonstrates how to use Amazon Nova 2.0's hybrid reasoning capabilities with LangChain's ChatBedrockConverse.\n",
    "\n",
    "Nova 2.0 models support reasoning configuration that allows the model to think through problems step-by-step. The reasoning process is controlled by the `maxReasoningEffort` parameter with three options: \"low\", \"medium\", and \"high\".\n",
    "\n",
    "The reasoning budget sets a limit on how many tokens should be used in the reasoning process, controlling how deeply the model thinks through problems. Always start with \"low\" and increase if needed for better accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce565bb7",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aec1d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01796462",
   "metadata": {},
   "source": [
    "## Basic Reasoning Example\n",
    "\n",
    "When using reasoning, the inference call may take some time depending on the complexity and reasoning effort level. We configure extended timeouts to accommodate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a6e642",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "# Configure extended timeouts for reasoning\n",
    "config = Config(\n",
    "    connect_timeout=3600,  # 60 minutes\n",
    "    read_timeout=3600,     # 60 minutes\n",
    "    retries={'max_attempts': 1}\n",
    ")\n",
    "\n",
    "# Initialize model with reasoning configuration\n",
    "model = ChatBedrockConverse(\n",
    "    model=\"amazon.nova-2-lite-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=10000,  # Set large max tokens to accommodate reasoning\n",
    "    config=config,\n",
    "    additional_model_request_fields={\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e52ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the model with a reasoning task\n",
    "messages = [\n",
    "    (\"system\", \"You are a highly capable personal assistant\"),\n",
    "    (\"human\", \"Provide a meal plan for a gluten free family of 4.\")\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145db6d1",
   "metadata": {},
   "source": [
    "## Accessing Reasoning Content\n",
    "\n",
    "The reasoning process is included in the response content blocks. You can access both the reasoning and the final text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f52b6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract reasoning content\n",
    "for block in response.content:\n",
    "    if isinstance(block, dict):\n",
    "        if 'type' in block and block['type'] == 'reasoning_content':\n",
    "            print(\"\\n=== REASONING ===\")\n",
    "            print(block['reasoning_content']['text'])\n",
    "        elif 'type' in block and block['type'] == 'text':\n",
    "            print(\"\\n=== RESPONSE ===\")\n",
    "            print(block['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "734662e6",
   "metadata": {},
   "source": [
    "## Streaming with Reasoning\n",
    "\n",
    "You can also stream responses to see the reasoning and text as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941582a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Streaming response:\\n\")\n",
    "\n",
    "for chunk in model.stream(messages):\n",
    "    if chunk.content:\n",
    "        for block in chunk.content:\n",
    "            if isinstance(block, dict):\n",
    "                if 'type' in block and block['type'] == 'reasoning_content':\n",
    "                    print(block['reasoning_content'].get('text', ''), end='', flush=True)\n",
    "                elif 'type' in block and block['type'] == 'text':\n",
    "                    print(block.get('text', ''), end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5856930",
   "metadata": {},
   "source": [
    "## Tool Calling with Reasoning\n",
    "\n",
    "Reasoning works seamlessly with tool calling. The model will reason about which tools to use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a0db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Calculator(BaseModel):\n",
    "    \"\"\"A calculator tool that can execute a math equation\"\"\"\n",
    "    equation: str = Field(description=\"The full equation to evaluate\")\n",
    "\n",
    "# Bind tools to the model\n",
    "model_with_tools = model.bind_tools([Calculator])\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"For math equations you must always use the calculator tool and not your parametric knowledge\"),\n",
    "    (\"human\", \"What is 2+2\")\n",
    "]\n",
    "\n",
    "response = model_with_tools.invoke(messages)\n",
    "print(\"Tool calls:\", response.tool_calls)\n",
    "print(\"\\nFull response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40116eb7",
   "metadata": {},
   "source": [
    "## Multimodal with Reasoning\n",
    "\n",
    "Nova models support multimodal inputs including images with reasoning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6203f2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Load and encode image\n",
    "with open(\"path/to/your/image.jpeg\", \"rb\") as f:\n",
    "    image_data = base64.b64encode(f.read()).decode(\"utf-8\")\n",
    "\n",
    "# Create multimodal message\n",
    "message = HumanMessage(\n",
    "    content=[\n",
    "        {\"type\": \"image\", \"source\": {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": image_data}},\n",
    "        {\"type\": \"text\", \"text\": \"Describe the following image\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "response = model.invoke([message])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reasoning_levels",
   "metadata": {},
   "source": [
    "## Different Reasoning Effort Levels\n",
    "\n",
    "You can adjust the reasoning effort based on task complexity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reasoning_comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Low reasoning effort (faster, less deep thinking)\n",
    "model_low = ChatBedrockConverse(\n",
    "    model=\"amazon.nova-2-lite-v1:0\",\n",
    "    max_tokens=10000,\n",
    "    config=config,\n",
    "    additional_model_request_fields={\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Medium reasoning effort (balanced)\n",
    "model_medium = ChatBedrockConverse(\n",
    "    model=\"amazon.nova-2-lite-v1:0\",\n",
    "    max_tokens=10000,\n",
    "    config=config,\n",
    "    additional_model_request_fields={\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"medium\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# High reasoning effort (slower, deeper thinking)\n",
    "model_high = ChatBedrockConverse(\n",
    "    model=\"amazon.nova-2-lite-v1:0\",\n",
    "    max_tokens=10000,\n",
    "    config=config,\n",
    "    additional_model_request_fields={\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"high\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"Try different reasoning levels based on your task complexity!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
