{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38dbd9be",
   "metadata": {},
   "source": [
    "# Nova Grounding (Web Search) with LangChain\n",
    "\n",
    "This notebook demonstrates how to use Amazon Nova 2.0's web grounding system tool with LangChain's ChatBedrockConverse.\n",
    "\n",
    "System tools are different from standard tools - the model can utilize these tools throughout its reasoning process and actually invoke the tool itself. This is in contrast with standard tool workflows where the model returns a tool call and the developer is responsible for invocation.\n",
    "\n",
    "The Nova Grounding system tool enables the Nova 2.0 model to access the web and search for live information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3363f41",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install the required packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c596ea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -qU langchain-aws"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195874a7",
   "metadata": {},
   "source": [
    "## IAM Permissions\n",
    "\n",
    "**Important:** To invoke system tools, your IAM role must have the `bedrock:InvokeTool` permission in addition to `bedrock:InvokeModel`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a58e384",
   "metadata": {},
   "source": [
    "## Basic Web Search Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b47317",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.config import Config\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "from langchain_aws.tools import NovaGroundingTool\n",
    "\n",
    "# Configure extended timeouts\n",
    "config = Config(\n",
    "    connect_timeout=3600,  # 60 minutes\n",
    "    read_timeout=3600,     # 60 minutes\n",
    "    retries={'max_attempts': 1}\n",
    ")\n",
    "\n",
    "# Initialize model\n",
    "model = ChatBedrockConverse(\n",
    "    model=\"amazon.nova-2-lite-v1:0\",\n",
    "    region_name=\"us-east-1\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=10000,\n",
    "    config=config,\n",
    "    additional_model_request_fields={\n",
    "        \"reasoningConfig\": {\n",
    "            \"type\": \"enabled\",\n",
    "            \"maxReasoningEffort\": \"low\"\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "# Bind the web grounding tool\n",
    "model_with_search = model.bind_tools([NovaGroundingTool()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ad1b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a question that requires current information\n",
    "response = model_with_search.invoke(\"Who won the oscar for best actress?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternative_syntax",
   "metadata": {},
   "source": [
    "## Alternative: Using String Name\n",
    "\n",
    "You can also use the string name directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "string_name",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using string name instead of tool class\n",
    "model_with_search = model.bind_tools([\"nova_grounding\"])\n",
    "\n",
    "response = model_with_search.invoke(\"What are the latest developments in quantum computing?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a04a3c",
   "metadata": {},
   "source": [
    "## Understanding the Response\n",
    "\n",
    "Let's examine the different parts of the response:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec74e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The response contains multiple content blocks\n",
    "for i, block in enumerate(response.content):\n",
    "    if isinstance(block, dict):\n",
    "        print(f\"\\n=== Block {i} ===\")\n",
    "        if 'type' in block:\n",
    "            print(f\"Type: {block['type']}\")\n",
    "            \n",
    "            if block['type'] == 'reasoning_content':\n",
    "                print(\"Reasoning:\", block['reasoning_content']['text'][:200], \"...\")\n",
    "            elif block['type'] == 'tool_use':\n",
    "                print(\"Tool:\", block.get('name'))\n",
    "                print(\"Tool Use Type:\", block.get('type'))\n",
    "            elif block['type'] == 'tool_result':\n",
    "                print(\"Tool Result Status:\", block.get('status'))\n",
    "                # Note: content is redacted in the final response for privacy\n",
    "            elif block['type'] == 'text':\n",
    "                print(\"Final Answer:\", block['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24768310",
   "metadata": {},
   "source": [
    "## Streaming with Web Search\n",
    "\n",
    "You can also stream responses to see the reasoning, tool use, and final answer as they're generated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a129bea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Streaming response:\\n\")\n",
    "\n",
    "current_type = None\n",
    "for chunk in model_with_search.stream(\"Who is going to the 2025 MLB world series?\"):\n",
    "    if chunk.content:\n",
    "        for block in chunk.content:\n",
    "            if isinstance(block, dict) and 'type' in block:\n",
    "                # Print header when type changes\n",
    "                if block['type'] != current_type:\n",
    "                    current_type = block['type']\n",
    "                    print(f\"\\n\\n=== {current_type.upper()} ===\")\n",
    "                \n",
    "                # Stream the content\n",
    "                if block['type'] == 'reasoning_content':\n",
    "                    print(block['reasoning_content'].get('text', ''), end='', flush=True)\n",
    "                elif block['type'] == 'text':\n",
    "                    print(block.get('text', ''), end='', flush=True)\n",
    "                elif block['type'] == 'tool_use':\n",
    "                    if 'name' in block:\n",
    "                        print(f\"Tool: {block['name']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combining",
   "metadata": {},
   "source": [
    "## Combining with Other Features\n",
    "\n",
    "You can combine web search with other Nova features like structured output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "structured",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "class NewsUpdate(BaseModel):\n",
    "    \"\"\"Current news information\"\"\"\n",
    "    topic: str = Field(description=\"The main topic\")\n",
    "    key_points: List[str] = Field(description=\"Key points from the news\")\n",
    "    date_context: str = Field(description=\"When this information is relevant\")\n",
    "\n",
    "# Create a model with both web search and structured output\n",
    "structured_model = model_with_search.with_structured_output(NewsUpdate)\n",
    "\n",
    "result = structured_model.invoke(\"What are the latest AI breakthroughs this month?\")\n",
    "print(f\"Topic: {result.topic}\")\n",
    "print(f\"\\nKey Points:\")\n",
    "for point in result.key_points:\n",
    "    print(f\"  - {point}\")\n",
    "print(f\"\\nDate Context: {result.date_context}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multi_turn",
   "metadata": {},
   "source": [
    "## Multi-turn Conversations\n",
    "\n",
    "Web search works seamlessly in multi-turn conversations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# First turn\n",
    "messages = [HumanMessage(content=\"What's the weather like in San Francisco today?\")]\n",
    "response1 = model_with_search.invoke(messages)\n",
    "print(\"Assistant:\", response1.content)\n",
    "\n",
    "# Second turn - follow up question\n",
    "messages.append(response1)\n",
    "messages.append(HumanMessage(content=\"What about tomorrow?\"))\n",
    "response2 = model_with_search.invoke(messages)\n",
    "print(\"\\nAssistant:\", response2.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
