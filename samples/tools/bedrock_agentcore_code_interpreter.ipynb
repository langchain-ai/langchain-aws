{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock AgentCore Code Interpreter tools with LangGraph React Agent\n",
    "\n",
    "This notebook demonstrates how to use the [Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/) based code interpreter toolkit with a LangGraph React Agent to perform code execution tasks. This toolkit provides a set of tools for running code, executing shell commands, and managing files in a secure environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, make sure you have the required packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q langgraph langchain 'langchain-aws[tools]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_aws.tools import create_code_interpreter_toolkit\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Code Interpreter Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available code interpreter tools: ['execute_code', 'execute_command', 'read_files', 'list_files', 'delete_files', 'write_files', 'upload_file', 'install_packages', 'start_command_execution', 'get_task', 'stop_task']\n"
     ]
    }
   ],
   "source": [
    "# Create the code interpreter toolkit\n",
    "# This is an async function as it sets up the tools\n",
    "toolkit, code_tools = await create_code_interpreter_toolkit(region=\"us-west-2\")\n",
    "\n",
    "# Display available tools\n",
    "print(f\"Available code interpreter tools: {[tool.name for tool in code_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n",
    "\n",
    "Set up the language model that will power our agent. We'll use Claude 3.5 Haiku through Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model using bedrock_converse provider\n",
    "provider = \"bedrock_converse\"\n",
    "model_id = \"us.anthropic.claude-opus-4-5-20251101-v1:0\"\n",
    "model_with_provider = f\"{provider}:{model_id}\"\n",
    "\n",
    "# Create the model instance\n",
    "model = init_chat_model(model_with_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create React Agent\n",
    "\n",
    "Now we'll create a React agent using LangGraph's prebuilt agent. The React agent uses a reasoning and acting approach to solve tasks step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the React agent with code interpreter tools\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=code_tools,\n",
    "    # Customize the agent prompt for code execution tasks\n",
    "    system_prompt=\"\"\"You are a code execution assistant that can run Python code, execute shell commands, and manage files.\n",
    "    Use the available code interpreter tools to complete programming tasks.\n",
    "    \n",
    "    Available tools:\n",
    "    - execute_code: Run code in the environment (primarily Python)\n",
    "    - execute_command: Run shell commands\n",
    "    - read_files: Read content of files\n",
    "    - list_files: List files in directories\n",
    "    - delete_files: Remove files\n",
    "    - write_files: Create or update files\n",
    "    - upload_file: Upload files with semantic descriptions\n",
    "    - install_packages: Install Python packages\n",
    "    - start_command_execution: Start long-running commands asynchronously\n",
    "    - get_task: Check status of async tasks\n",
    "    - stop_task: Stop running tasks\n",
    "    \n",
    "    Follow these steps for each task:\n",
    "    1. Understand the problem requirements\n",
    "    2. Write code or commands to solve the problem\n",
    "    3. Execute the code and analyze results\n",
    "    4. Refine your approach based on results if needed\n",
    "    5. Provide a clear explanation of the solution\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Agent\n",
    "\n",
    "Now let's run the agent on a code execution task. We'll set up a function to execute tasks and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_code_interpreter_agent(query: str, session_id: str = \"code_session1\"):\n",
    "    \"\"\"\n",
    "    Run the code interpreter agent on a specific query with session tracking\n",
    "    \n",
    "    Args:\n",
    "        query: The task to perform\n",
    "        session_id: Unique identifier for the code interpreter session\n",
    "        \n",
    "    Returns:\n",
    "        Agent response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure the session ID for thread-aware tools\n",
    "        config = {\n",
    "            \"configurable\": {\n",
    "                \"thread_id\": session_id\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Invoke the agent with the query\n",
    "        result = await agent.ainvoke(\n",
    "            {\n",
    "                \"messages\": [{\n",
    "                    \"role\": \"human\",\n",
    "                    \"content\": query\n",
    "                }]\n",
    "            },\n",
    "            config=config\n",
    "        )\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running code interpreter agent: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Tasks\n",
    "\n",
    "Let's run some example code execution tasks to demonstrate the agent's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:langchain_aws.tools.local_code_interpreter_client:Starting code interpreter session...\n",
      "INFO:langchain_aws.tools.local_code_interpreter_client:✅ Session started: 01KE0743SD51BW00GCVDENESST\n",
      "INFO:langchain_aws.tools.code_interpreter_toolkit:Started code interpreter with session_id:01KE0743SD51BW00GCVDENESST for thread:code_session1\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Result:\n",
      "I've created a `factorial` function and tested it. Here's a summary:\n",
      "\n",
      "## The Factorial Function\n",
      "\n",
      "The function calculates n! (n factorial) using an iterative approach:\n",
      "\n",
      "```python\n",
      "def factorial(n):\n",
      "    if n < 0:\n",
      "        raise ValueError(\"Factorial is not defined for negative numbers\")\n",
      "    if n == 0 or n == 1:\n",
      "        return 1\n",
      "    else:\n",
      "        result = 1\n",
      "        for i in range(2, n + 1):\n",
      "            result *= i\n",
      "        return result\n",
      "```\n",
      "\n",
      "## Key Features:\n",
      "- **Input validation**: Raises an error for negative numbers\n",
      "- **Base cases**: Returns 1 for both 0! and 1!\n",
      "- **Iterative calculation**: Multiplies all integers from 2 to n\n",
      "\n",
      "## Test Result:\n",
      "- **factorial(5) = 120** ✓\n",
      "\n",
      "This is correct because: 5! = 5 × 4 × 3 × 2 × 1 = 120\n",
      "\n",
      "The additional tests show the function works correctly for values 0 through 7.\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Execute basic Python code\n",
    "task1 = \"Create a Python function that calculates the factorial of a number, then test it with n=5\"\n",
    "\n",
    "result1 = await run_code_interpreter_agent(task1)\n",
    "print(\"Task 1 Result:\")\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2 Result:\n",
      "I've completed both tasks:\n",
      "\n",
      "1. **Created `data.csv`** with the following content:\n",
      "   ```\n",
      "   Name,Age,City\n",
      "   John,30,New York\n",
      "   Alice,25,Boston\n",
      "   Bob,35,Chicago\n",
      "   Emma,28,Seattle\n",
      "   ```\n",
      "\n",
      "2. **Python script** that reads the CSV and calculates the average age:\n",
      "   - Used Python's built-in `csv` module with `DictReader` to read the file\n",
      "   - Extracted all ages: [30, 25, 35, 28]\n",
      "   - Calculated the sum: 118\n",
      "   - Divided by the number of people: 4\n",
      "   - **Average age: 29.50 years**\n"
     ]
    }
   ],
   "source": [
    "# Example 2: Create and manipulate files\n",
    "task2 = \"\"\"Create a CSV file named 'data.csv' with the following data:\n",
    "Name,Age,City\n",
    "John,30,New York\n",
    "Alice,25,Boston\n",
    "Bob,35,Chicago\n",
    "Emma,28,Seattle\n",
    "\n",
    "Then write a Python script to read this CSV file and calculate the average age.\"\"\"\n",
    "\n",
    "result2 = await run_code_interpreter_agent(task2)\n",
    "print(\"Task 2 Result:\")\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.tools.local_code_interpreter_client:Uploading file: config.json (Configuration file for the DataAnalyzer application. Contains app metadata (name, version) and a list of enabled features including CSV import, data visualization, and export capabilities.)\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upload File Result:\n",
      "I've created the `config.json` file with the specified content. The file contains:\n",
      "\n",
      "- **app_name**: \"DataAnalyzer\" - the name of the application\n",
      "- **version**: \"1.0\" - the current version\n",
      "- **features**: An array of three enabled features:\n",
      "  - `csv_import` - for importing CSV files\n",
      "  - `visualization` - for data visualization capabilities\n",
      "  - `export` - for exporting data\n",
      "\n",
      "The semantic description I included explains that this is a configuration file for the DataAnalyzer application, containing metadata and feature flags. This description helps document what the file is for and makes it easier to understand its purpose in the project.\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Upload file with semantic description\n",
    "task_upload = \"\"\"Use the upload_file tool to create a JSON configuration file called 'config.json' with the following content:\n",
    "{\n",
    "    \"app_name\": \"DataAnalyzer\",\n",
    "    \"version\": \"1.0\",\n",
    "    \"features\": [\"csv_import\", \"visualization\", \"export\"]\n",
    "}\n",
    "\n",
    "Include a description that explains what this config file is for.\"\"\"\n",
    "\n",
    "result_upload = await run_code_interpreter_agent(task_upload)\n",
    "print(\"Upload File Result:\")\n",
    "print(result_upload[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Install Packages Result:\n",
      "Here's a summary of the packages already installed in the environment:\n",
      "\n",
      "## Pre-installed Packages\n",
      "\n",
      "The environment comes with a comprehensive set of packages across various categories:\n",
      "\n",
      "### Data Science & Machine Learning\n",
      "- **pandas** (2.3.1), **numpy** (1.26.4), **scipy** (1.16.0)\n",
      "- **scikit-learn** (1.5.0), **xgboost** (2.0.3)\n",
      "- **torch** (2.3.0), **torchvision** (0.18.0), **torchaudio** (2.3.0)\n",
      "- **statsmodels** (0.14.5)\n",
      "\n",
      "### Visualization\n",
      "- **matplotlib** (3.9.0), **plotly** (5.22.0), **seaborn** (not listed but usually included)\n",
      "- **bokeh** (2.4.3)\n",
      "\n",
      "### Data Processing\n",
      "- **pyarrow** (17.0.0), **openpyxl** (3.1.3), **xlrd** (2.0.1)\n",
      "- **beautifulsoup4** (4.12.3), **lxml** (5.2.2)\n",
      "- **duckdb** (1.3.2)\n",
      "\n",
      "### Image/Video Processing\n",
      "- **opencv-python** (4.10.0.82), **pillow** (10.3.0)\n",
      "- **imageio** (2.34.1), **moviepy** (1.0.3), **scikit-image** (0.23.2)\n",
      "\n",
      "### PDF & Document Processing\n",
      "- **pypdf** (6.2.0), **PyPDF2** (3.0.1), **pdfplumber** (0.11.0)\n",
      "- **python-docx** (1.1.2), **python-pptx** (1.0.2)\n",
      "- **reportlab** (4.2.0)\n",
      "\n",
      "### Web Frameworks & HTTP\n",
      "- **Flask** (3.0.3), **Django** (5.1.12), **fastapi** (0.116.1)\n",
      "- **requests** (2.32.4), **httpx** (0.28.1)\n",
      "\n",
      "### NLP\n",
      "- **nltk** (3.9.1), **spacy** (3.7.4), **textblob** (0.18.0)\n",
      "\n",
      "### Optimization\n",
      "- **cvxpy** (1.5.3), **PuLP** (3.2.2), **ortools** (9.9.3963)\n",
      "\n",
      "### Cloud & Database\n",
      "- **boto3** (1.40.30), **pymongo** (4.7.2), **redis** (5.0.4)\n",
      "- **SQLAlchemy** (1.4.52), **psycopg2-binary** (2.9.9)\n",
      "\n",
      "### Other Utilities\n",
      "- **openai** (1.33.0), **sympy** (1.14.0), **networkx** (3.3)\n",
      "- **Faker** (19.13.0), **tqdm** (4.66.4)\n",
      "\n",
      "This is a very well-equipped environment for data analysis, machine learning, web development, and many other tasks! Let me know if you need any additional packages installed.\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Check what packages are available\n",
    "task_packages = \"\"\"Use execute_command to run 'pip list' and show me what packages \n",
    "are already installed in the environment.\"\"\"\n",
    "\n",
    "result_packages = await run_code_interpreter_agent(task_packages)\n",
    "print(\"Install Packages Result:\")\n",
    "print(result_packages[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:bedrock_agentcore.tools.code_interpreter_client:Starting code interpreter session...\n",
      "INFO:bedrock_agentcore.tools.code_interpreter_client:✅ Session started: 01KE2YWEMK410XEPYZQWKW9X9A\n",
      "INFO:langchain_aws.tools.code_interpreter_toolkit:Started code interpreter with session_id:01KE2YWEMK410XEPYZQWKW9X9A for thread:code_session1\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 Result:\n",
      "I've created both plots as requested:\n",
      "\n",
      "1. **`sine_wave.png`** - Shows a single sine wave over the range [0, 2π]:\n",
      "   - Blue line representing sin(x)\n",
      "   - X-axis labeled with radians (0, π/2, π, 3π/2, 2π)\n",
      "   - Grid lines for easier reading\n",
      "   - Proper title and labels\n",
      "\n",
      "2. **`trig_functions.png`** - Shows both sine and cosine waves on the same graph:\n",
      "   - Blue line for sin(x)\n",
      "   - Red line for cos(x)\n",
      "   - Legend to distinguish between the two functions\n",
      "   - Same x-axis range [0, 2π] with radian labels\n",
      "   - Grid lines and proper formatting\n",
      "\n",
      "Both plots have been saved at 150 DPI resolution with a figure size of 10x6 inches, making them suitable for presentations or documentation.\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Generate plots\n",
    "task5 = \"\"\"Generate a matplotlib plot showing a sine wave over the range [0, 2π] and save it as 'sine_wave.png'. \n",
    "Then create another plot showing both sine and cosine waves on the same graph and save it as 'trig_functions.png'.\"\"\"\n",
    "\n",
    "result3 = await run_code_interpreter_agent(task3)\n",
    "print(\"Task 3 Result:\")\n",
    "print(result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 Result:\n",
      "Great! Let me break down the files in the current directory:\n",
      "\n",
      "1. Directories:\n",
      "   - `.cache`\n",
      "   - `.config`\n",
      "   - `.ipython`\n",
      "   - `log`\n",
      "\n",
      "2. Files:\n",
      "   - `data.csv`\n",
      "   - `sine_wave.png`\n",
      "   - `trig_functions.png`\n",
      "\n",
      "There are a few interesting things to note:\n",
      "- There's a CSV file called `data.csv`\n",
      "- Two image files: `sine_wave.png` and `trig_functions.png`\n",
      "- Some hidden configuration directories\n",
      "\n",
      "Would you like me to show you the contents of any of these files or provide more details about them?\n"
     ]
    }
   ],
   "source": [
    "task6 = \"Show me all the files present in the code interpreter environment\"\n",
    "\n",
    "result4 = await run_code_interpreter_agent(task4)\n",
    "print(\"Task 4 Result:\")\n",
    "print(result4[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "Always clean up code interpreter resources when done to avoid unnecessary resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.tools.code_interpreter_toolkit:All code interpreter sessions cleaned up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code interpreter resources cleaned up successfully\n"
     ]
    }
   ],
   "source": [
    "# Clean up code interpreter resources\n",
    "await toolkit.cleanup()\n",
    "print(\"Code interpreter resources cleaned up successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
