{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bedrock AgentCore Browser toolkit with LangGraph React Agent\n",
    "\n",
    "This notebook demonstrates how to use the [Bedrock AgentCore](https://aws.amazon.com/bedrock/agentcore/) based browser toolkit with a LangGraph React Agent to perform automated web browsing tasks. This toolkit provides a set of tools for navigating websites, interacting with web elements, and extracting information."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, make sure you have the required packages installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q langgraph langchain 'langchain-aws[tools]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "from langchain.agents import create_agent\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_aws.tools import create_browser_toolkit\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Browser Toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available browser tools: ['navigate_browser', 'click_element', 'navigate_back', 'extract_text', 'extract_hyperlinks', 'get_elements', 'current_webpage', 'type_text', 'take_screenshot', 'scroll_page', 'wait_for_element']\n"
     ]
    }
   ],
   "source": [
    "# The toolkit handles browser session management based on thread IDs\n",
    "toolkit, browser_tools = create_browser_toolkit(region=\"us-west-2\")\n",
    "\n",
    "# Display available tools\n",
    "print(f\"Available browser tools: {[tool.name for tool in browser_tools]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM\n",
    "\n",
    "Set up the language model that will power our agent. We'll use Claude 3.5 Haiku through Bedrock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n"
     ]
    }
   ],
   "source": [
    "# Initialize the language model using bedrock_converse provider\n",
    "provider = \"bedrock_converse\"\n",
    "model_id = \"us.anthropic.claude-opus-4-5-20251101-v1:0\"\n",
    "model_with_provider = f\"{provider}:{model_id}\"\n",
    "\n",
    "# Create the model instance\n",
    "model = init_chat_model(model_with_provider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create React Agent\n",
    "\n",
    "Now we'll create a React agent using LangGraph's prebuilt agent. The React agent uses a reasoning and acting approach to solve tasks step by step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "\n",
    "agent = create_agent(\n",
    "    model,\n",
    "    tools=browser_tools,\n",
    "    system_prompt=\"\"\"You are a web browsing assistant that can navigate websites, interact with web elements, and extract information. \n",
    "Use the available browser tools to complete web browsing tasks. \n",
    "When navigating websites, first go to the URL, then explore the page content to understand its structure before performing actions.\n",
    "For any search tasks, find the search box, enter the query, and submit the form.\n",
    "When extracting information, be precise about what elements you want to extract.\n",
    "\n",
    "Follow these steps for each task:\n",
    "1. Navigate to the required website\n",
    "2. Analyze the page structure\n",
    "3. Interact with elements as needed (type, click, scroll)\n",
    "4. Wait for dynamic content if necessary\n",
    "5. Extract and report requested information\n",
    "6. Provide a clear, concise summary of findings\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute the Agent\n",
    "\n",
    "Now let's run the agent on a web browsing task. We'll set up a function to execute tasks and print the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_browser_agent(query: str, session_id: str = \"browser_session1\"):\n",
    "    \"\"\"\n",
    "    Run the browser agent on a specific query with session tracking\n",
    "\n",
    "    Args:\n",
    "        query: The task to perform\n",
    "        session_id: Unique identifier for the browser session\n",
    "\n",
    "    Returns:\n",
    "        Agent response\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Configure the session ID for thread-aware tools\n",
    "        config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "\n",
    "        # Invoke the agent with the query\n",
    "        result = await agent.ainvoke(\n",
    "            {\"messages\": [{\"role\": \"user\", \"content\": query}]}, config=config\n",
    "        )\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error running browser agent: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Tasks\n",
    "\n",
    "Let's run some example web browsing tasks to demonstrate the agent's capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:bedrock_agentcore.tools.browser_client:Starting browser session...\n",
      "INFO:bedrock_agentcore.tools.browser_client:✅ Session started: 01KEH8D2TBTKGRKA125F6A1VZG\n",
      "INFO:bedrock_agentcore.tools.browser_client:Generating websocket headers...\n",
      "INFO:botocore.credentials:Found credentials in shared credentials file: ~/.aws/credentials\n",
      "INFO:langchain_aws.tools.browser_session_manager:Connecting to async WebSocket endpoint for thread default: wss://bedrock-agentcore.us-west-2.amazonaws.com/browser-streams/aws.browser.v1/sessions/01KEH8D2TBTKGRKA125F6A1VZG/automation\n",
      "INFO:langchain_aws.tools.browser_session_manager:Successfully connected to async browser for thread default\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 Result:\n",
      "Here are the titles of the top 5 posts on Hacker News:\n",
      "\n",
      "1. **MCP is a fad** (tombedor.dev) - 56 points\n",
      "2. **Surveillance Watch – A map that shows connections between surveillance companies** (surveillancewatch.io) - 92 points\n",
      "3. **Mathematics for Computer Science (2018) [pdf]** (csail.mit.edu) - 114 points\n",
      "4. **What Happened to WebAssembly** (emnudge.dev) - 139 points\n",
      "5. **How to Code Claude Code in 200 Lines of Code** (mihaileric.com) - 539 points\n"
     ]
    }
   ],
   "source": [
    "# Example 1: Visit a website and extract information\n",
    "task1 = \"Go to https://news.ycombinator.com/ and tell me the titles of the top 5 posts\"\n",
    "\n",
    "result1 = await run_browser_agent(task1)\n",
    "print(\"Task 1 Result:\")\n",
    "print(result1[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Search for information\n",
    "task2 = \"Go to https://www.wikipedia.org, search for 'artificial intelligence', and summarize the first paragraph\"\n",
    "\n",
    "result2 = await run_browser_agent(task2)\n",
    "print(\"Task 2 Result:\")\n",
    "print(result2[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 3 Result:\n",
      "I've completed all the requested tasks. Here's a summary of what was done:\n",
      "\n",
      "1. **Navigated to Google.com** - Successfully loaded the Google homepage (status code 200)\n",
      "\n",
      "2. **Typed the search query** - Used the `type_text` tool to enter \"Amazon Bedrock AgentCore\" into the search box using the selector `textarea[name=\"q\"]`\n",
      "\n",
      "3. **Captured a screenshot** - The screenshot shows the Google homepage with \"Amazon Bedrock AgentCore\" typed into the search box, and Google's autocomplete suggestions are visible in a dropdown menu below the search field\n",
      "\n",
      "The screenshot displays the Google interface with:\n",
      "- The Google logo\n",
      "- The search box containing the text \"Amazon Bedrock AgentCore\"\n",
      "- Autocomplete suggestions showing related searches like \"amazon bedrock agentcore\", \"amazon bedrock agentcore pricing\", \"amazon bedrock agents\", etc.\n",
      "- The \"Google Search\" and \"I'm Feeling Lucky\" buttons below\n"
     ]
    }
   ],
   "source": [
    "# Example 3: Use type_text to fill a search form and take a screenshot\n",
    "task3 = \"\"\"Go to https://www.google.com, use the type_text tool to enter 'Amazon Bedrock AgentCore' \n",
    "in the search box (selector: 'textarea[name=\"q\"]'), then take a screenshot of the page.\"\"\"\n",
    "\n",
    "result3 = await run_browser_agent(task3)\n",
    "print(\"Task 3 Result:\")\n",
    "print(result3[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 4 Result:\n",
      "After scrolling down 1000 pixels total (500 pixels twice), I can now see the full list of posts on the Hacker News front page. Here are all the post titles visible after scrolling:\n",
      "\n",
      "## Hacker News Post Titles (30 posts visible)\n",
      "\n",
      "1. **MCP is a fad** (tombedor.dev)\n",
      "2. **Surveillance Watch – A map that shows connections between surveillance companies** (surveillancewatch.io)\n",
      "3. **Mathematics for Computer Science (2018) [pdf]** (csail.mit.edu)\n",
      "4. **How to Code Claude Code in 200 Lines of Code** (mihaileric.com)\n",
      "5. **What Happened to WebAssembly** (emnudge.dev)\n",
      "6. **European Commission issues call for evidence on open source** (lwn.net)\n",
      "7. **Sopro TTS: A 169M model with zero-shot voice cloning that runs on the CPU** (github.com)\n",
      "8. **Why I left iNaturalist** (kueda.net)\n",
      "9. **Hacking a Casio F-91W digital watch (2023)** (medium.com)\n",
      "10. **Embassy: Modern embedded framework, using Rust and async** (github.com)\n",
      "11. **Bose has released API docs and opened the API for its EoL SoundTouch speakers** (arstechnica.com) - 2333 points!\n",
      "12. **Linux Runs on Raspberry Pi RP2350's Hazard3 RISC-V Cores (2024)** (hackster.io)\n",
      "13. **1ML for non-specialists: introduction** (pithlessly.github.io)\n",
      "14. **Richard D. James aka Aphex Twin speaks to Tatsuya Takahashi (2017)** (archive.org)\n",
      "15. **Photographing the hidden world of slime mould** (bbc.com)\n",
      "16. **The Jeff Dean Facts** (github.com) - 475 points\n",
      "17. **The Unreasonable Effectiveness of the Fourier Transform** (joshuawise.com)\n",
      "18. **Samba Was Written (2003)** (samba.org)\n",
      "19. **Anthropic blocks third-party use of Claude Code subscriptions** (github.com)\n",
      "20. **AI coding assistants are getting worse?** (ieee.org)\n",
      "21. **Why Is There a Tiny Hole in the Airplane Window? (2023)** (afar.com)\n",
      "22. **He was called a 'terrorist sympathizer.' Now his AI company is valued at $3B** (sfstandard.com)\n",
      "23. **Mysterious Victorian-era shoes are washing up on a beach in wales** (smithsonianmag.com)\n",
      "24. **The No Fakes Act has a \"fingerprinting\" trap that kills open source?** (reddit.com)\n",
      "25. **Google AI Studio is now sponsoring Tailwind CSS** (twitter.com) - 663 points\n",
      "26. **Ushikuvirus: Newly discovered virus may offer clues to the origin of eukaryotes** (tus.ac.jp)\n",
      "27. **Fixing a Buffer Overflow in Unix v4 Like It's 1973** (sigma-star.at)\n",
      "28. **Show HN: macOS menu bar app to track Claude usage in real time** (github.com)\n",
      "29. **Systematically Improving Espresso: Mathematical Modeling and Experiment (2020)** (cell.com)\n",
      "30. **Mux (YC W16) is hiring a platform engineer that cares about (internal) DX** (mux.com) - Job posting\n",
      "\n",
      "After scrolling, I was able to see all 30 posts on the front page. The most popular posts by points are:\n",
      "- **Bose API docs release** with 2,333 points\n",
      "- **Google AI Studio sponsoring Tailwind CSS** with 663 points\n",
      "- **How to Code Claude Code in 200 Lines** with 542 points\n",
      "- **The Jeff Dean Facts** with 475 points\n"
     ]
    }
   ],
   "source": [
    "# Example 4: Scroll through a page to load more content\n",
    "task4 = \"\"\"Go to https://news.ycombinator.com/, scroll down by 500 pixels twice to load more content, \n",
    "then extract the titles of any additional posts you can see.\"\"\"\n",
    "\n",
    "result4 = await run_browser_agent(task4)\n",
    "print(\"Task 4 Result:\")\n",
    "print(result4[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n",
      "INFO:langchain_aws.chat_models.bedrock_converse:Using Bedrock Converse API to generate response\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5 Result:\n",
      "I have successfully completed the task. Here's a summary:\n",
      "\n",
      "## Summary\n",
      "\n",
      "I navigated to https://www.wikipedia.org, waited for the search input (`#searchInput`) to become visible, typed \"machine learning\", and extracted the search suggestions that appeared.\n",
      "\n",
      "### Search Suggestions Found:\n",
      "\n",
      "1. **Machine learning** - Study of algorithms that improve automatically through experience\n",
      "2. **Machine learning in bioinformatics** - Software for understanding biological data\n",
      "3. **Machine learning in earth sciences**\n",
      "4. **Machine learning in video games** - Overview of the use of machine learning in several video games\n",
      "5. **Machine learning in physics** - Applications of machine learning to quantum physics\n",
      "6. **Machine Learning (journal)** - Academic journal\n",
      "\n",
      "The Wikipedia search autocomplete feature successfully displayed 6 relevant suggestions related to \"machine learning\" as the user typed the query.\n"
     ]
    }
   ],
   "source": [
    "# Example 5: Wait for element before interacting\n",
    "task5 = \"\"\"Go to https://www.wikipedia.org, wait for the search input to be visible \n",
    "(selector: '#searchInput'), then type 'machine learning' and extract the search suggestions that appear.\"\"\"\n",
    "\n",
    "result5 = await run_browser_agent(task5)\n",
    "print(\"Task 5 Result:\")\n",
    "print(result5[\"messages\"][-1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean Up Resources\n",
    "\n",
    "Always clean up browser resources when done to avoid unnecessary resource usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up browser resources\n",
    "await toolkit.cleanup()\n",
    "print(\"Browser resources cleaned up successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
